{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9126f3f-0bc4-4374-bd2b-3846e2f71e16",
   "metadata": {},
   "source": [
    "# Target only specific tickers to get financial news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71dc0ff4-94ac-485f-891b-50149f5b677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing company 1/6: AAPL.US\n",
      "Using 100 max iterations for deep news collection\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AAPL.US from 2019-01-01\n",
      "Using max iterations: 100\n",
      "Company AAPL.US - Batch 1/100: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 1000\n",
      "Company AAPL.US - Batch 2/100: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 2000\n",
      "Company AAPL.US - Batch 3/100: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 3000\n",
      "Company AAPL.US - Batch 4/100: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 4000\n",
      "Company AAPL.US - Batch 5/100: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 5000\n",
      "Company AAPL.US - Batch 6/100: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 6000\n",
      "Company AAPL.US - Batch 7/100: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 7000\n",
      "Company AAPL.US - Batch 8/100: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 8000\n",
      "Company AAPL.US - Batch 9/100: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 9000\n",
      "Company AAPL.US - Batch 10/100: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 10000\n",
      "Company AAPL.US - Batch 11/100: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 11000\n",
      "Company AAPL.US - Batch 12/100: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 12000\n",
      "Company AAPL.US - Batch 13/100: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 13000\n",
      "Company AAPL.US - Batch 14/100: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 14000\n",
      "Company AAPL.US - Batch 15/100: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 15000\n",
      "Company AAPL.US - Batch 16/100: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 16000\n",
      "Company AAPL.US - Batch 17/100: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 17000\n",
      "Company AAPL.US - Batch 18/100: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 18000\n",
      "Company AAPL.US - Batch 19/100: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 19000\n",
      "Company AAPL.US - Batch 20/100: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 20000\n",
      "Company AAPL.US - Batch 21/100: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 21000\n",
      "Company AAPL.US - Batch 22/100: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 22000\n",
      "Company AAPL.US - Batch 23/100: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 23000\n",
      "Company AAPL.US - Batch 24/100: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 24000\n",
      "Company AAPL.US - Batch 25/100: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 25000\n",
      "Company AAPL.US - Batch 26/100: Fetching news with offset 25000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 26000\n",
      "Company AAPL.US - Batch 27/100: Fetching news with offset 26000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 27000\n",
      "Company AAPL.US - Batch 28/100: Fetching news with offset 27000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 28000\n",
      "Company AAPL.US - Batch 29/100: Fetching news with offset 28000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 29000\n",
      "Company AAPL.US - Batch 30/100: Fetching news with offset 29000...\n",
      "Retrieved 1000 news items for AAPL.US. Total for this company: 30000\n",
      "Company AAPL.US - Batch 31/100: Fetching news with offset 30000...\n",
      "Retrieved 876 news items for AAPL.US. Total for this company: 30876\n",
      "Reached the end of available news for AAPL.US at offset 30000.\n",
      "Saved 30876 news items for AAPL.US to sp500_news_data/AAPL_US_news_extended.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 2/6: TSLA.US\n",
      "Using 100 max iterations for deep news collection\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TSLA.US from 2019-01-01\n",
      "Using max iterations: 100\n",
      "Company TSLA.US - Batch 1/100: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 1000\n",
      "Company TSLA.US - Batch 2/100: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 2000\n",
      "Company TSLA.US - Batch 3/100: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 3000\n",
      "Company TSLA.US - Batch 4/100: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 4000\n",
      "Company TSLA.US - Batch 5/100: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 5000\n",
      "Company TSLA.US - Batch 6/100: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 6000\n",
      "Company TSLA.US - Batch 7/100: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 7000\n",
      "Company TSLA.US - Batch 8/100: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 8000\n",
      "Company TSLA.US - Batch 9/100: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 9000\n",
      "Company TSLA.US - Batch 10/100: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 10000\n",
      "Company TSLA.US - Batch 11/100: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 11000\n",
      "Company TSLA.US - Batch 12/100: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 12000\n",
      "Company TSLA.US - Batch 13/100: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 13000\n",
      "Company TSLA.US - Batch 14/100: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 14000\n",
      "Company TSLA.US - Batch 15/100: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 15000\n",
      "Company TSLA.US - Batch 16/100: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 16000\n",
      "Company TSLA.US - Batch 17/100: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 17000\n",
      "Company TSLA.US - Batch 18/100: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 18000\n",
      "Company TSLA.US - Batch 19/100: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 19000\n",
      "Company TSLA.US - Batch 20/100: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 20000\n",
      "Company TSLA.US - Batch 21/100: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 21000\n",
      "Company TSLA.US - Batch 22/100: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 22000\n",
      "Company TSLA.US - Batch 23/100: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 23000\n",
      "Company TSLA.US - Batch 24/100: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 24000\n",
      "Company TSLA.US - Batch 25/100: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 25000\n",
      "Company TSLA.US - Batch 26/100: Fetching news with offset 25000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 26000\n",
      "Company TSLA.US - Batch 27/100: Fetching news with offset 26000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 27000\n",
      "Company TSLA.US - Batch 28/100: Fetching news with offset 27000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 28000\n",
      "Company TSLA.US - Batch 29/100: Fetching news with offset 28000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 29000\n",
      "Company TSLA.US - Batch 30/100: Fetching news with offset 29000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 30000\n",
      "Company TSLA.US - Batch 31/100: Fetching news with offset 30000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 31000\n",
      "Company TSLA.US - Batch 32/100: Fetching news with offset 31000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 32000\n",
      "Company TSLA.US - Batch 33/100: Fetching news with offset 32000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 33000\n",
      "Company TSLA.US - Batch 34/100: Fetching news with offset 33000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 34000\n",
      "Company TSLA.US - Batch 35/100: Fetching news with offset 34000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 35000\n",
      "Company TSLA.US - Batch 36/100: Fetching news with offset 35000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 36000\n",
      "Company TSLA.US - Batch 37/100: Fetching news with offset 36000...\n",
      "Retrieved 1000 news items for TSLA.US. Total for this company: 37000\n",
      "Company TSLA.US - Batch 38/100: Fetching news with offset 37000...\n",
      "Retrieved 806 news items for TSLA.US. Total for this company: 37806\n",
      "Reached the end of available news for TSLA.US at offset 37000.\n",
      "Saved 37806 news items for TSLA.US to sp500_news_data/TSLA_US_news_extended.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 3/6: GOOGL.US\n",
      "Using 100 max iterations for deep news collection\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GOOGL.US from 2019-01-01\n",
      "Using max iterations: 100\n",
      "Company GOOGL.US - Batch 1/100: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 1000\n",
      "Company GOOGL.US - Batch 2/100: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 2000\n",
      "Company GOOGL.US - Batch 3/100: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 3000\n",
      "Company GOOGL.US - Batch 4/100: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 4000\n",
      "Company GOOGL.US - Batch 5/100: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 5000\n",
      "Company GOOGL.US - Batch 6/100: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 6000\n",
      "Company GOOGL.US - Batch 7/100: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 7000\n",
      "Company GOOGL.US - Batch 8/100: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 8000\n",
      "Company GOOGL.US - Batch 9/100: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 9000\n",
      "Company GOOGL.US - Batch 10/100: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 10000\n",
      "Company GOOGL.US - Batch 11/100: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 11000\n",
      "Company GOOGL.US - Batch 12/100: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 12000\n",
      "Company GOOGL.US - Batch 13/100: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 13000\n",
      "Company GOOGL.US - Batch 14/100: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 14000\n",
      "Company GOOGL.US - Batch 15/100: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 15000\n",
      "Company GOOGL.US - Batch 16/100: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 16000\n",
      "Company GOOGL.US - Batch 17/100: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 17000\n",
      "Company GOOGL.US - Batch 18/100: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 18000\n",
      "Company GOOGL.US - Batch 19/100: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 19000\n",
      "Company GOOGL.US - Batch 20/100: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 20000\n",
      "Company GOOGL.US - Batch 21/100: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 21000\n",
      "Company GOOGL.US - Batch 22/100: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 22000\n",
      "Company GOOGL.US - Batch 23/100: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 23000\n",
      "Company GOOGL.US - Batch 24/100: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 24000\n",
      "Company GOOGL.US - Batch 25/100: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for GOOGL.US. Total for this company: 25000\n",
      "Company GOOGL.US - Batch 26/100: Fetching news with offset 25000...\n",
      "Retrieved 681 news items for GOOGL.US. Total for this company: 25681\n",
      "Reached the end of available news for GOOGL.US at offset 25000.\n",
      "Saved 25681 news items for GOOGL.US to sp500_news_data/GOOGL_US_news_extended.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 4/6: NVDA.US\n",
      "Using 100 max iterations for deep news collection\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NVDA.US from 2019-01-01\n",
      "Using max iterations: 100\n",
      "Company NVDA.US - Batch 1/100: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 1000\n",
      "Company NVDA.US - Batch 2/100: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 2000\n",
      "Company NVDA.US - Batch 3/100: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 3000\n",
      "Company NVDA.US - Batch 4/100: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 4000\n",
      "Company NVDA.US - Batch 5/100: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 5000\n",
      "Company NVDA.US - Batch 6/100: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 6000\n",
      "Company NVDA.US - Batch 7/100: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 7000\n",
      "Company NVDA.US - Batch 8/100: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 8000\n",
      "Company NVDA.US - Batch 9/100: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 9000\n",
      "Company NVDA.US - Batch 10/100: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 10000\n",
      "Company NVDA.US - Batch 11/100: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 11000\n",
      "Company NVDA.US - Batch 12/100: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 12000\n",
      "Company NVDA.US - Batch 13/100: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 13000\n",
      "Company NVDA.US - Batch 14/100: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 14000\n",
      "Company NVDA.US - Batch 15/100: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 15000\n",
      "Company NVDA.US - Batch 16/100: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 16000\n",
      "Company NVDA.US - Batch 17/100: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 17000\n",
      "Company NVDA.US - Batch 18/100: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 18000\n",
      "Company NVDA.US - Batch 19/100: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 19000\n",
      "Company NVDA.US - Batch 20/100: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 20000\n",
      "Company NVDA.US - Batch 21/100: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 21000\n",
      "Company NVDA.US - Batch 22/100: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 22000\n",
      "Company NVDA.US - Batch 23/100: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 23000\n",
      "Company NVDA.US - Batch 24/100: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 24000\n",
      "Company NVDA.US - Batch 25/100: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for NVDA.US. Total for this company: 25000\n",
      "Company NVDA.US - Batch 26/100: Fetching news with offset 25000...\n",
      "Retrieved 974 news items for NVDA.US. Total for this company: 25974\n",
      "Reached the end of available news for NVDA.US at offset 25000.\n",
      "Saved 25974 news items for NVDA.US to sp500_news_data/NVDA_US_news_extended.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 5/6: AMZN.US\n",
      "Using 100 max iterations for deep news collection\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMZN.US from 2019-01-01\n",
      "Using max iterations: 100\n",
      "Company AMZN.US - Batch 1/100: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 1000\n",
      "Company AMZN.US - Batch 2/100: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 2000\n",
      "Company AMZN.US - Batch 3/100: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 3000\n",
      "Company AMZN.US - Batch 4/100: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 4000\n",
      "Company AMZN.US - Batch 5/100: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 5000\n",
      "Company AMZN.US - Batch 6/100: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 6000\n",
      "Company AMZN.US - Batch 7/100: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 7000\n",
      "Company AMZN.US - Batch 8/100: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 8000\n",
      "Company AMZN.US - Batch 9/100: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 9000\n",
      "Company AMZN.US - Batch 10/100: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 10000\n",
      "Company AMZN.US - Batch 11/100: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 11000\n",
      "Company AMZN.US - Batch 12/100: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 12000\n",
      "Company AMZN.US - Batch 13/100: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 13000\n",
      "Company AMZN.US - Batch 14/100: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 14000\n",
      "Company AMZN.US - Batch 15/100: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 15000\n",
      "Company AMZN.US - Batch 16/100: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 16000\n",
      "Company AMZN.US - Batch 17/100: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 17000\n",
      "Company AMZN.US - Batch 18/100: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 18000\n",
      "Company AMZN.US - Batch 19/100: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 19000\n",
      "Company AMZN.US - Batch 20/100: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 20000\n",
      "Company AMZN.US - Batch 21/100: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 21000\n",
      "Company AMZN.US - Batch 22/100: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 22000\n",
      "Company AMZN.US - Batch 23/100: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 23000\n",
      "Company AMZN.US - Batch 24/100: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 24000\n",
      "Company AMZN.US - Batch 25/100: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 25000\n",
      "Company AMZN.US - Batch 26/100: Fetching news with offset 25000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 26000\n",
      "Company AMZN.US - Batch 27/100: Fetching news with offset 26000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 27000\n",
      "Company AMZN.US - Batch 28/100: Fetching news with offset 27000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 28000\n",
      "Company AMZN.US - Batch 29/100: Fetching news with offset 28000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 29000\n",
      "Company AMZN.US - Batch 30/100: Fetching news with offset 29000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 30000\n",
      "Company AMZN.US - Batch 31/100: Fetching news with offset 30000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 31000\n",
      "Company AMZN.US - Batch 32/100: Fetching news with offset 31000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 32000\n",
      "Company AMZN.US - Batch 33/100: Fetching news with offset 32000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 33000\n",
      "Company AMZN.US - Batch 34/100: Fetching news with offset 33000...\n",
      "Retrieved 1000 news items for AMZN.US. Total for this company: 34000\n",
      "Company AMZN.US - Batch 35/100: Fetching news with offset 34000...\n",
      "Retrieved 338 news items for AMZN.US. Total for this company: 34338\n",
      "Reached the end of available news for AMZN.US at offset 34000.\n",
      "Saved 34338 news items for AMZN.US to sp500_news_data/AMZN_US_news_extended.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 6/6: MSFT.US\n",
      "Using 100 max iterations for deep news collection\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MSFT.US from 2019-01-01\n",
      "Using max iterations: 100\n",
      "Company MSFT.US - Batch 1/100: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 1000\n",
      "Company MSFT.US - Batch 2/100: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 2000\n",
      "Company MSFT.US - Batch 3/100: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 3000\n",
      "Company MSFT.US - Batch 4/100: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 4000\n",
      "Company MSFT.US - Batch 5/100: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 5000\n",
      "Company MSFT.US - Batch 6/100: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 6000\n",
      "Company MSFT.US - Batch 7/100: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 7000\n",
      "Company MSFT.US - Batch 8/100: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 8000\n",
      "Company MSFT.US - Batch 9/100: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 9000\n",
      "Company MSFT.US - Batch 10/100: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 10000\n",
      "Company MSFT.US - Batch 11/100: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 11000\n",
      "Company MSFT.US - Batch 12/100: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 12000\n",
      "Company MSFT.US - Batch 13/100: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 13000\n",
      "Company MSFT.US - Batch 14/100: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 14000\n",
      "Company MSFT.US - Batch 15/100: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 15000\n",
      "Company MSFT.US - Batch 16/100: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 16000\n",
      "Company MSFT.US - Batch 17/100: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 17000\n",
      "Company MSFT.US - Batch 18/100: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 18000\n",
      "Company MSFT.US - Batch 19/100: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 19000\n",
      "Company MSFT.US - Batch 20/100: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 20000\n",
      "Company MSFT.US - Batch 21/100: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 21000\n",
      "Company MSFT.US - Batch 22/100: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 22000\n",
      "Company MSFT.US - Batch 23/100: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 23000\n",
      "Company MSFT.US - Batch 24/100: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 24000\n",
      "Company MSFT.US - Batch 25/100: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 25000\n",
      "Company MSFT.US - Batch 26/100: Fetching news with offset 25000...\n",
      "Retrieved 1000 news items for MSFT.US. Total for this company: 26000\n",
      "Company MSFT.US - Batch 27/100: Fetching news with offset 26000...\n",
      "Retrieved 316 news items for MSFT.US. Total for this company: 26316\n",
      "Reached the end of available news for MSFT.US at offset 26000.\n",
      "Saved 26316 news items for MSFT.US to sp500_news_data/MSFT_US_news_extended.json\n",
      "\n",
      "================================================================================\n",
      "Data collection complete:\n",
      "- Made 183 API calls\n",
      "- Processed 6 of 6 high-interest companies\n",
      "- Collected 180991 total news items\n",
      "- Used 100 iterations per company for deep news collection\n",
      "- Total runtime: 724.24 seconds (0.20 hours)\n",
      "- Summary saved to sp500_news_data/high_interest_news_summary.json\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from eodhd import APIClient\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Initialize the API client with your API key\n",
    "api = APIClient(KEY)  # Assuming KEY is defined elsewhere in your code\n",
    "\n",
    "# Configuration\n",
    "FROM_DATE = \"2019-01-01\"\n",
    "LIMIT = 1000  # Maximum allowed per request\n",
    "MAX_ITERATIONS = 100  # Use 100 iterations for all specified tickers\n",
    "\n",
    "# List of specific tickers to process\n",
    "TARGET_TICKERS = [\n",
    "    \"AAPL.US\", \n",
    "    \"TSLA.US\", \n",
    "    \"GOOGL.US\", \n",
    "    \"NVDA.US\", \n",
    "    \"AMZN.US\", \n",
    "    \"MSFT.US\"\n",
    "]\n",
    "\n",
    "# API Limits\n",
    "CALLS_PER_MINUTE_LIMIT = 1000\n",
    "CALLS_PER_DAY_LIMIT = 100000\n",
    "OUTPUT_DIR = \"sp500_news_data\"  # Directory to store output files\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize tracking variables\n",
    "api_calls = 0\n",
    "start_time = time.time()\n",
    "minute_start_time = start_time\n",
    "minute_calls = 0\n",
    "processed_companies = 0\n",
    "total_news_items = 0\n",
    "\n",
    "# Function to enforce rate limits\n",
    "def check_rate_limits():\n",
    "    global minute_calls, minute_start_time, api_calls\n",
    "    \n",
    "    current_time = time.time()\n",
    "    elapsed_minute = current_time - minute_start_time\n",
    "    \n",
    "    # Reset minute counter if a minute has passed\n",
    "    if elapsed_minute >= 60:\n",
    "        minute_calls = 0\n",
    "        minute_start_time = current_time\n",
    "    \n",
    "    # If we're close to the per-minute limit, wait until the next minute\n",
    "    if minute_calls >= CALLS_PER_MINUTE_LIMIT - 5:  # Buffer of 5 calls\n",
    "        wait_time = 60 - elapsed_minute\n",
    "        print(f\"Approaching per-minute rate limit. Waiting {wait_time:.2f} seconds...\")\n",
    "        time.sleep(wait_time + 1)  # Add 1 second buffer\n",
    "        minute_calls = 0\n",
    "        minute_start_time = time.time()\n",
    "    \n",
    "    # Check if we're approaching the daily limit\n",
    "    if api_calls >= CALLS_PER_DAY_LIMIT - 100:  # Buffer of 100 calls\n",
    "        print(\"WARNING: Approaching daily API call limit!\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Function to fetch news for a single company\n",
    "def fetch_company_news(symbol):\n",
    "    global api_calls, minute_calls, total_news_items\n",
    "    \n",
    "    company_news = []\n",
    "    \n",
    "    print(f\"\\nStarting data collection for {symbol} from {FROM_DATE}\")\n",
    "    print(f\"Using max iterations: {MAX_ITERATIONS}\")\n",
    "    \n",
    "    # Main loop for pagination\n",
    "    for i in range(MAX_ITERATIONS):\n",
    "        offset = i * LIMIT\n",
    "        \n",
    "        # Check rate limits\n",
    "        if not check_rate_limits():\n",
    "            print(f\"Stopping further requests for {symbol} due to API limits.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            print(f\"Company {symbol} - Batch {i+1}/{MAX_ITERATIONS}: Fetching news with offset {offset}...\")\n",
    "            \n",
    "            # Make the API call\n",
    "            news_batch = api.financial_news(\n",
    "                s=symbol, \n",
    "                from_date=FROM_DATE, \n",
    "                offset=str(offset), \n",
    "                limit=str(LIMIT)\n",
    "            )\n",
    "            \n",
    "            # Update counters\n",
    "            api_calls += 1\n",
    "            minute_calls += 1\n",
    "            \n",
    "            # Check if we got any results\n",
    "            if not news_batch:\n",
    "                print(f\"No more news items found for {symbol} after offset {offset}.\")\n",
    "                break\n",
    "            \n",
    "            # Add the batch to our collection\n",
    "            company_news.extend(news_batch)\n",
    "            total_news_items += len(news_batch)\n",
    "            \n",
    "            # Display progress\n",
    "            print(f\"Retrieved {len(news_batch)} news items for {symbol}. Total for this company: {len(company_news)}\")\n",
    "            \n",
    "            # If we got fewer items than requested, we've reached the end\n",
    "            if len(news_batch) < LIMIT:\n",
    "                print(f\"Reached the end of available news for {symbol} at offset {offset}.\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error for {symbol} at offset {offset}: {str(e)}\")\n",
    "            \n",
    "            # If the error might be rate-limit related, pause\n",
    "            if \"rate\" in str(e).lower() or \"limit\" in str(e).lower():\n",
    "                print(\"Possible rate limit reached. Pausing for 60 seconds...\")\n",
    "                time.sleep(60)\n",
    "                minute_calls = 0\n",
    "                minute_start_time = time.time()\n",
    "            else:\n",
    "                # For other errors, add a small delay before continuing\n",
    "                print(\"Continuing to next batch after a short delay...\")\n",
    "                time.sleep(5)\n",
    "        \n",
    "        # Add a small delay between requests to be courteous\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return company_news\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    total_companies = len(TARGET_TICKERS)\n",
    "    \n",
    "    # Create a summary log file\n",
    "    summary_file = os.path.join(OUTPUT_DIR, f\"high_interest_news_summary.json\")\n",
    "    company_summaries = []\n",
    "    \n",
    "    # Process each of the specified tickers\n",
    "    for ticker in TARGET_TICKERS:\n",
    "        # Check if we're approaching API limits before starting a new company\n",
    "        if not check_rate_limits():\n",
    "            print(f\"Approaching API limits. Stopping after processing {processed_companies} companies.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing company {processed_companies+1}/{total_companies}: {ticker}\")\n",
    "        print(f\"Using {MAX_ITERATIONS} max iterations for deep news collection\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Fetch news for this company\n",
    "        company_news = fetch_company_news(ticker)\n",
    "        \n",
    "        # If we got news, save it to a file\n",
    "        if company_news:\n",
    "            company_filename = f\"{ticker.replace('.', '_')}_news_extended.json\"\n",
    "            company_filepath = os.path.join(OUTPUT_DIR, company_filename)\n",
    "            \n",
    "            with open(company_filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(company_news, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "            print(f\"Saved {len(company_news)} news items for {ticker} to {company_filepath}\")\n",
    "            \n",
    "            # Add to summary\n",
    "            company_summaries.append({\n",
    "                'symbol': ticker,\n",
    "                'news_count': len(company_news),\n",
    "                'file': company_filename\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No news found for {ticker}. Skipping file creation.\")\n",
    "            \n",
    "            # Add to summary\n",
    "            company_summaries.append({\n",
    "                'symbol': ticker,\n",
    "                'news_count': 0,\n",
    "                'file': None\n",
    "            })\n",
    "        \n",
    "        processed_companies += 1\n",
    "        \n",
    "        # Save the summary after each company to keep track of progress\n",
    "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "            summary_data = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'companies_processed': processed_companies,\n",
    "                'total_companies': total_companies,\n",
    "                'total_news_items': total_news_items,\n",
    "                'api_calls': api_calls,\n",
    "                'target_tickers': TARGET_TICKERS,\n",
    "                'max_iterations': MAX_ITERATIONS,\n",
    "                'company_summaries': company_summaries\n",
    "            }\n",
    "            json.dump(summary_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        # Brief pause between companies\n",
    "        time.sleep(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Critical error in main execution: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    # Final summary\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Data collection complete:\")\n",
    "    print(f\"- Made {api_calls} API calls\")\n",
    "    print(f\"- Processed {processed_companies} of {total_companies} high-interest companies\")\n",
    "    print(f\"- Collected {total_news_items} total news items\")\n",
    "    print(f\"- Used {MAX_ITERATIONS} iterations per company for deep news collection\")\n",
    "    print(f\"- Total runtime: {total_time:.2f} seconds ({total_time/3600:.2f} hours)\")\n",
    "    print(f\"- Summary saved to {summary_file}\")\n",
    "    print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDAS Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
