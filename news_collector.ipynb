{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d907cfd-f91e-4e95-8c92-3cfddd039de1",
   "metadata": {},
   "source": [
    "# S&P 500 Financial News Collector\n",
    "\n",
    "## Overview\n",
    "This Python tool retrieves historical financial news for all S&P 500 companies using the EODHD API. It first obtains the complete list of S&P 500 companies directly from EODHD, then systematically collects news articles for each company while carefully managing API rate limits.\n",
    "\n",
    "## Requirements\n",
    "- Python 3.6+\n",
    "- Required packages:\n",
    "  - `eodhd`: EODHD API client\n",
    "  - `json`: For data handling and storage\n",
    "  - `time`: For timing operations and delays\n",
    "  - `datetime`: For timestamp generation\n",
    "  - `os`: For file and directory operations\n",
    "\n",
    "## Installation\n",
    "```bash\n",
    "pip install eodhd\n",
    "```\n",
    "\n",
    "## Configuration\n",
    "The script uses the following configurable parameters:\n",
    "\n",
    "```python\n",
    "# API Configuration\n",
    "KEY = \"your_eodhd_api_key\"  # Replace with your actual API key\n",
    "\n",
    "# Data Collection Settings\n",
    "FROM_DATE = \"2019-01-01\"     # Start date for collecting news \n",
    "LIMIT = 1000                 # Maximum results per API call (API limit is 1000)\n",
    "MAX_ITERATIONS_PER_COMPANY = 25  # Maximum pagination iterations per company\n",
    "\n",
    "# API Limits\n",
    "CALLS_PER_MINUTE_LIMIT = 1000  # API rate limit per minute\n",
    "CALLS_PER_DAY_LIMIT = 100000   # API rate limit per day\n",
    "\n",
    "# Output Settings\n",
    "OUTPUT_DIR = \"sp500_news_data\"  # Directory for storing collected data\n",
    "```\n",
    "\n",
    "## Functionality\n",
    "\n",
    "### 1. S&P 500 Ticker Retrieval\n",
    "The script retrieves S&P 500 constituent companies through the EODHD API using the `get_fundamentals_data` method with the S&P 500 index symbol (`GSPC.INDX`). The retrieved data contains a 'Components' section listing all current S&P 500 companies.\n",
    "\n",
    "### 2. News Collection Process\n",
    "For each company in the S&P 500:\n",
    "- Retrieves news articles in batches of 1000 (maximum allowed by API)\n",
    "- Uses pagination with incremental offset values to retrieve all available articles\n",
    "- Collects news starting from the configured start date\n",
    "- Stops collection for a company when either:\n",
    "  - No more news articles are available\n",
    "  - The maximum number of iterations is reached\n",
    "  - API rate limits are approaching\n",
    "\n",
    "### 3. Rate Limit Management\n",
    "The script implements sophisticated rate limit management:\n",
    "- Tracks API calls per minute and total calls\n",
    "- Pauses execution when approaching the per-minute limit\n",
    "- Stops execution when approaching the daily limit\n",
    "- Implements appropriate delays between requests\n",
    "\n",
    "### 4. Data Storage\n",
    "News articles are stored in the following structure:\n",
    "- A dedicated output directory (`sp500_news_data` by default)\n",
    "- Individual JSON files for each company (e.g., `AAPL_US_news.json`)\n",
    "- A summary JSON file containing information about all processed companies\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Set your API key and desired configuration parameters at the top of the script\n",
    "2. Run the script:\n",
    "```bash\n",
    "python sp500_news_collector.py\n",
    "```\n",
    "\n",
    "3. Monitor the console output for progress updates\n",
    "4. Check the output directory for collected data\n",
    "\n",
    "## Output Files\n",
    "\n",
    "### Company News Files\n",
    "Each company's news is stored in a separate JSON file named after its ticker symbol:\n",
    "```\n",
    "sp500_news_data/AAPL_US_news.json\n",
    "sp500_news_data/MSFT_US_news.json\n",
    "sp500_news_data/AMZN_US_news.json\n",
    "...\n",
    "```\n",
    "\n",
    "Each news file contains an array of news article objects with fields like:\n",
    "- `date`: Publication timestamp\n",
    "- `title`: Article title\n",
    "- `content`: Full article text\n",
    "- `link`: URL to the original article\n",
    "- `symbols`: Related stock symbols\n",
    "- `sentiment`: Sentiment analysis data (if available)\n",
    "\n",
    "### Summary File\n",
    "A summary file is created with the naming pattern:\n",
    "```\n",
    "sp500_news_data/sp500_news_summary.json\n",
    "```\n",
    "\n",
    "The summary file contains:\n",
    "- Timestamp of the collection\n",
    "- Number of companies processed\n",
    "- Total companies in the S&P 500\n",
    "- Total news items collected\n",
    "- Total API calls made\n",
    "- Company-specific information:\n",
    "  - Symbol\n",
    "  - News count\n",
    "  - Output filename\n",
    "\n",
    "## Error Handling\n",
    "\n",
    "The script includes comprehensive error handling:\n",
    "\n",
    "1. **API Connection Issues**: Catches and logs API connection errors\n",
    "2. **Rate Limit Handling**: Detects rate limit errors and implements appropriate waiting periods\n",
    "3. **Data Structure Validation**: Validates received data before processing\n",
    "4. **Fallback Mechanisms**: Uses fallback ticker list if S&P 500 retrieval fails\n",
    "5. **Progress Preservation**: Saves summary after each company to preserve progress in case of interruption\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **API Key Invalid**\n",
    "   - Verify your API key is correct and has appropriate permissions\n",
    "\n",
    "2. **Rate Limit Exceeded**\n",
    "   - The script should automatically manage rate limits\n",
    "   - If you still encounter issues, consider decreasing `MAX_ITERATIONS_PER_COMPANY`\n",
    "\n",
    "3. **Memory Issues With Large Datasets**\n",
    "   - If processing all S&P 500 companies causes memory problems, consider running the script in batches\n",
    "   - Modify the script to process a subset of companies at a time\n",
    "\n",
    "4. **No News Found for Certain Companies**\n",
    "   - Some companies may have limited or no news coverage\n",
    "   - Verify the ticker symbol format is correct (should include `.US` suffix)\n",
    "\n",
    "## API Rate Limit Management\n",
    "\n",
    "The script implements two levels of rate limit protection:\n",
    "\n",
    "1. **Per-Minute Limit (1,000 calls/minute)**\n",
    "   - Tracks calls within rolling 60-second windows\n",
    "   - Pauses execution when approaching the limit\n",
    "\n",
    "2. **Daily Limit (100,000 calls/day)**\n",
    "   - Tracks total API calls \n",
    "   - Stops execution when approaching the daily limit\n",
    "\n",
    "This approach ensures responsible API usage while maximizing data collection efficiency.\n",
    "\n",
    "## Example Collection Statistics\n",
    "\n",
    "For a complete run of all S&P 500 companies with default settings:\n",
    "\n",
    "- **Total API Calls**: ~15,000-25,000 (varies based on news volume)\n",
    "- **Total Runtime**: 3-5 hours (depends on news volume and rate limit pauses)\n",
    "- **Total Data Collected**: ~5-15GB (depends on news volume)\n",
    "- **Average News per Company**: ~100-300 articles (highly variable)\n",
    "\n",
    "## Notes and Best Practices\n",
    "\n",
    "1. **Run During Off-Hours**: For uninterrupted execution, run the script during low-activity periods\n",
    "2. **Incremental Collection**: Consider implementing date-based incremental collection for regular updates\n",
    "3. **Data Backup**: Regularly back up collected data to prevent loss\n",
    "4. **Monitoring**: Monitor the console output to track progress and identify any issues\n",
    "5. **API Key Security**: Never share your API key or commit it to public repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b11555-87fd-4e75-8760-2fde5e26a58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching S&P 500 constituent companies via EODHD API...\n",
      "Successfully retrieved 503 S&P 500 tickers\n",
      "\n",
      "================================================================================\n",
      "Processing company 1/503: AIZ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AIZ from 2019-01-01\n",
      "Company AIZ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 743 news items for AIZ. Total for this company: 743\n",
      "Reached the end of available news for AIZ at offset 0.\n",
      "Saved 743 news items for AIZ to sp500_news_data/AIZ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 2/503: MNST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MNST from 2019-01-01\n",
      "Company MNST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MNST. Total for this company: 1000\n",
      "Company MNST - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 95 news items for MNST. Total for this company: 1095\n",
      "Reached the end of available news for MNST at offset 1000.\n",
      "Saved 1095 news items for MNST to sp500_news_data/MNST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 3/503: MTCH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MTCH from 2019-01-01\n",
      "Company MTCH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MTCH. Total for this company: 1000\n",
      "Company MTCH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 573 news items for MTCH. Total for this company: 1573\n",
      "Reached the end of available news for MTCH at offset 1000.\n",
      "Saved 1573 news items for MTCH to sp500_news_data/MTCH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 4/503: PGR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PGR from 2019-01-01\n",
      "Company PGR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PGR. Total for this company: 1000\n",
      "Company PGR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 240 news items for PGR. Total for this company: 1240\n",
      "Reached the end of available news for PGR at offset 1000.\n",
      "Saved 1240 news items for PGR to sp500_news_data/PGR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 5/503: CSX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CSX from 2019-01-01\n",
      "Company CSX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CSX. Total for this company: 1000\n",
      "Company CSX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 362 news items for CSX. Total for this company: 1362\n",
      "Reached the end of available news for CSX at offset 1000.\n",
      "Saved 1362 news items for CSX to sp500_news_data/CSX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 6/503: ADP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ADP from 2019-01-01\n",
      "Company ADP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 914 news items for ADP. Total for this company: 914\n",
      "Reached the end of available news for ADP at offset 0.\n",
      "Saved 914 news items for ADP to sp500_news_data/ADP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 7/503: ANSS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ANSS from 2019-01-01\n",
      "Company ANSS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 848 news items for ANSS. Total for this company: 848\n",
      "Reached the end of available news for ANSS at offset 0.\n",
      "Saved 848 news items for ANSS to sp500_news_data/ANSS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 8/503: AFL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AFL from 2019-01-01\n",
      "Company AFL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AFL. Total for this company: 1000\n",
      "Company AFL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 174 news items for AFL. Total for this company: 1174\n",
      "Reached the end of available news for AFL at offset 1000.\n",
      "Saved 1174 news items for AFL to sp500_news_data/AFL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 9/503: SO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SO from 2019-01-01\n",
      "Company SO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SO. Total for this company: 1000\n",
      "Company SO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for SO. Total for this company: 2000\n",
      "Company SO - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 757 news items for SO. Total for this company: 2757\n",
      "Reached the end of available news for SO at offset 2000.\n",
      "Saved 2757 news items for SO to sp500_news_data/SO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 10/503: REG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for REG from 2019-01-01\n",
      "Company REG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 479 news items for REG. Total for this company: 479\n",
      "Reached the end of available news for REG at offset 0.\n",
      "Saved 479 news items for REG to sp500_news_data/REG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 11/503: LMT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LMT from 2019-01-01\n",
      "Company LMT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LMT. Total for this company: 1000\n",
      "Company LMT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for LMT. Total for this company: 2000\n",
      "Company LMT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for LMT. Total for this company: 3000\n",
      "Company LMT - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for LMT. Total for this company: 4000\n",
      "Company LMT - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 154 news items for LMT. Total for this company: 4154\n",
      "Reached the end of available news for LMT at offset 4000.\n",
      "Saved 4154 news items for LMT to sp500_news_data/LMT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 12/503: BMY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BMY from 2019-01-01\n",
      "Company BMY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BMY. Total for this company: 1000\n",
      "Company BMY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BMY. Total for this company: 2000\n",
      "Company BMY - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for BMY. Total for this company: 3000\n",
      "Company BMY - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 224 news items for BMY. Total for this company: 3224\n",
      "Reached the end of available news for BMY at offset 3000.\n",
      "Saved 3224 news items for BMY to sp500_news_data/BMY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 13/503: EIX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EIX from 2019-01-01\n",
      "Company EIX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 944 news items for EIX. Total for this company: 944\n",
      "Reached the end of available news for EIX at offset 0.\n",
      "Saved 944 news items for EIX to sp500_news_data/EIX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 14/503: GWW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GWW from 2019-01-01\n",
      "Company GWW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 808 news items for GWW. Total for this company: 808\n",
      "Reached the end of available news for GWW at offset 0.\n",
      "Saved 808 news items for GWW to sp500_news_data/GWW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 15/503: FAST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FAST from 2019-01-01\n",
      "Company FAST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FAST. Total for this company: 1000\n",
      "Company FAST - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 27 news items for FAST. Total for this company: 1027\n",
      "Reached the end of available news for FAST at offset 1000.\n",
      "Saved 1027 news items for FAST to sp500_news_data/FAST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 16/503: PHM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PHM from 2019-01-01\n",
      "Company PHM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PHM. Total for this company: 1000\n",
      "Company PHM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 674 news items for PHM. Total for this company: 1674\n",
      "Reached the end of available news for PHM at offset 1000.\n",
      "Saved 1674 news items for PHM to sp500_news_data/PHM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 17/503: INTC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for INTC from 2019-01-01\n",
      "Company INTC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 1000\n",
      "Company INTC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 2000\n",
      "Company INTC - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 3000\n",
      "Company INTC - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 4000\n",
      "Company INTC - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 5000\n",
      "Company INTC - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 6000\n",
      "Company INTC - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 7000\n",
      "Company INTC - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 8000\n",
      "Company INTC - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 9000\n",
      "Company INTC - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for INTC. Total for this company: 10000\n",
      "Company INTC - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 366 news items for INTC. Total for this company: 10366\n",
      "Reached the end of available news for INTC at offset 10000.\n",
      "Saved 10366 news items for INTC to sp500_news_data/INTC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 18/503: NEM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NEM from 2019-01-01\n",
      "Company NEM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NEM. Total for this company: 1000\n",
      "Company NEM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 736 news items for NEM. Total for this company: 1736\n",
      "Reached the end of available news for NEM at offset 1000.\n",
      "Saved 1736 news items for NEM to sp500_news_data/NEM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 19/503: CTAS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CTAS from 2019-01-01\n",
      "Company CTAS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CTAS. Total for this company: 1000\n",
      "Company CTAS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 20 news items for CTAS. Total for this company: 1020\n",
      "Reached the end of available news for CTAS at offset 1000.\n",
      "Saved 1020 news items for CTAS to sp500_news_data/CTAS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 20/503: ALL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ALL from 2019-01-01\n",
      "Company ALL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ALL. Total for this company: 1000\n",
      "Company ALL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ALL. Total for this company: 2000\n",
      "Company ALL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 402 news items for ALL. Total for this company: 2402\n",
      "Reached the end of available news for ALL at offset 2000.\n",
      "Saved 2402 news items for ALL to sp500_news_data/ALL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 21/503: CBOE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CBOE from 2019-01-01\n",
      "Company CBOE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CBOE. Total for this company: 1000\n",
      "Company CBOE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 14 news items for CBOE. Total for this company: 1014\n",
      "Reached the end of available news for CBOE at offset 1000.\n",
      "Saved 1014 news items for CBOE to sp500_news_data/CBOE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 22/503: NDAQ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NDAQ from 2019-01-01\n",
      "Company NDAQ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NDAQ. Total for this company: 1000\n",
      "Company NDAQ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 922 news items for NDAQ. Total for this company: 1922\n",
      "Reached the end of available news for NDAQ at offset 1000.\n",
      "Saved 1922 news items for NDAQ to sp500_news_data/NDAQ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 23/503: NRG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NRG from 2019-01-01\n",
      "Company NRG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 946 news items for NRG. Total for this company: 946\n",
      "Reached the end of available news for NRG at offset 0.\n",
      "Saved 946 news items for NRG to sp500_news_data/NRG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 24/503: CSGP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CSGP from 2019-01-01\n",
      "Company CSGP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 739 news items for CSGP. Total for this company: 739\n",
      "Reached the end of available news for CSGP at offset 0.\n",
      "Saved 739 news items for CSGP to sp500_news_data/CSGP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 25/503: GIS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GIS from 2019-01-01\n",
      "Company GIS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GIS. Total for this company: 1000\n",
      "Company GIS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 976 news items for GIS. Total for this company: 1976\n",
      "Reached the end of available news for GIS at offset 1000.\n",
      "Saved 1976 news items for GIS to sp500_news_data/GIS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 26/503: CNC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CNC from 2019-01-01\n",
      "Company CNC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CNC. Total for this company: 1000\n",
      "Company CNC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 509 news items for CNC. Total for this company: 1509\n",
      "Reached the end of available news for CNC at offset 1000.\n",
      "Saved 1509 news items for CNC to sp500_news_data/CNC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 27/503: MLM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MLM from 2019-01-01\n",
      "Company MLM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 809 news items for MLM. Total for this company: 809\n",
      "Reached the end of available news for MLM at offset 0.\n",
      "Saved 809 news items for MLM to sp500_news_data/MLM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 28/503: QCOM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for QCOM from 2019-01-01\n",
      "Company QCOM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for QCOM. Total for this company: 1000\n",
      "Company QCOM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for QCOM. Total for this company: 2000\n",
      "Company QCOM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for QCOM. Total for this company: 3000\n",
      "Company QCOM - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for QCOM. Total for this company: 4000\n",
      "Company QCOM - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for QCOM. Total for this company: 5000\n",
      "Company QCOM - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 123 news items for QCOM. Total for this company: 5123\n",
      "Reached the end of available news for QCOM at offset 5000.\n",
      "Saved 5123 news items for QCOM to sp500_news_data/QCOM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 29/503: ACN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ACN from 2019-01-01\n",
      "Company ACN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ACN. Total for this company: 1000\n",
      "Company ACN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ACN. Total for this company: 2000\n",
      "Company ACN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 621 news items for ACN. Total for this company: 2621\n",
      "Reached the end of available news for ACN at offset 2000.\n",
      "Saved 2621 news items for ACN to sp500_news_data/ACN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 30/503: VMC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VMC from 2019-01-01\n",
      "Company VMC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 782 news items for VMC. Total for this company: 782\n",
      "Reached the end of available news for VMC at offset 0.\n",
      "Saved 782 news items for VMC to sp500_news_data/VMC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 31/503: AVGO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AVGO from 2019-01-01\n",
      "Company AVGO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AVGO. Total for this company: 1000\n",
      "Company AVGO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AVGO. Total for this company: 2000\n",
      "Company AVGO - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AVGO. Total for this company: 3000\n",
      "Company AVGO - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for AVGO. Total for this company: 4000\n",
      "Company AVGO - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for AVGO. Total for this company: 5000\n",
      "Company AVGO - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 369 news items for AVGO. Total for this company: 5369\n",
      "Reached the end of available news for AVGO at offset 5000.\n",
      "Saved 5369 news items for AVGO to sp500_news_data/AVGO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 32/503: AMT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMT from 2019-01-01\n",
      "Company AMT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AMT. Total for this company: 1000\n",
      "Company AMT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 491 news items for AMT. Total for this company: 1491\n",
      "Reached the end of available news for AMT at offset 1000.\n",
      "Saved 1491 news items for AMT to sp500_news_data/AMT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 33/503: PKG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PKG from 2019-01-01\n",
      "Company PKG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 585 news items for PKG. Total for this company: 585\n",
      "Reached the end of available news for PKG at offset 0.\n",
      "Saved 585 news items for PKG to sp500_news_data/PKG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 34/503: CPB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CPB from 2019-01-01\n",
      "Company CPB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CPB. Total for this company: 1000\n",
      "Company CPB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 234 news items for CPB. Total for this company: 1234\n",
      "Reached the end of available news for CPB at offset 1000.\n",
      "Saved 1234 news items for CPB to sp500_news_data/CPB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 35/503: FMC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FMC from 2019-01-01\n",
      "Company FMC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 859 news items for FMC. Total for this company: 859\n",
      "Reached the end of available news for FMC at offset 0.\n",
      "Saved 859 news items for FMC to sp500_news_data/FMC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 36/503: RCL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RCL from 2019-01-01\n",
      "Company RCL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for RCL. Total for this company: 1000\n",
      "Company RCL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for RCL. Total for this company: 2000\n",
      "Company RCL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for RCL. Total for this company: 3000\n",
      "Company RCL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 302 news items for RCL. Total for this company: 3302\n",
      "Reached the end of available news for RCL at offset 3000.\n",
      "Saved 3302 news items for RCL to sp500_news_data/RCL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 37/503: WAT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WAT from 2019-01-01\n",
      "Company WAT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 498 news items for WAT. Total for this company: 498\n",
      "Reached the end of available news for WAT at offset 0.\n",
      "Saved 498 news items for WAT to sp500_news_data/WAT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 38/503: PPL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PPL from 2019-01-01\n",
      "Company PPL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 590 news items for PPL. Total for this company: 590\n",
      "Reached the end of available news for PPL at offset 0.\n",
      "Saved 590 news items for PPL to sp500_news_data/PPL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 39/503: FITB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FITB from 2019-01-01\n",
      "Company FITB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FITB. Total for this company: 1000\n",
      "Company FITB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 113 news items for FITB. Total for this company: 1113\n",
      "Reached the end of available news for FITB at offset 1000.\n",
      "Saved 1113 news items for FITB to sp500_news_data/FITB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 40/503: DXCM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DXCM from 2019-01-01\n",
      "Company DXCM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DXCM. Total for this company: 1000\n",
      "Company DXCM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 385 news items for DXCM. Total for this company: 1385\n",
      "Reached the end of available news for DXCM at offset 1000.\n",
      "Saved 1385 news items for DXCM to sp500_news_data/DXCM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 41/503: SNPS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SNPS from 2019-01-01\n",
      "Company SNPS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SNPS. Total for this company: 1000\n",
      "Company SNPS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 389 news items for SNPS. Total for this company: 1389\n",
      "Reached the end of available news for SNPS at offset 1000.\n",
      "Saved 1389 news items for SNPS to sp500_news_data/SNPS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 42/503: HON\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HON from 2019-01-01\n",
      "Company HON - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HON. Total for this company: 1000\n",
      "Company HON - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for HON. Total for this company: 2000\n",
      "Company HON - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 46 news items for HON. Total for this company: 2046\n",
      "Reached the end of available news for HON at offset 2000.\n",
      "Saved 2046 news items for HON to sp500_news_data/HON_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 43/503: EW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EW from 2019-01-01\n",
      "Company EW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 930 news items for EW. Total for this company: 930\n",
      "Reached the end of available news for EW at offset 0.\n",
      "Saved 930 news items for EW to sp500_news_data/EW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 44/503: APD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for APD from 2019-01-01\n",
      "Company APD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for APD. Total for this company: 1000\n",
      "Company APD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 282 news items for APD. Total for this company: 1282\n",
      "Reached the end of available news for APD at offset 1000.\n",
      "Saved 1282 news items for APD to sp500_news_data/APD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 45/503: MCD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MCD from 2019-01-01\n",
      "Company MCD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MCD. Total for this company: 1000\n",
      "Company MCD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MCD. Total for this company: 2000\n",
      "Company MCD - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MCD. Total for this company: 3000\n",
      "Company MCD - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MCD. Total for this company: 4000\n",
      "Company MCD - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for MCD. Total for this company: 5000\n",
      "Company MCD - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 94 news items for MCD. Total for this company: 5094\n",
      "Reached the end of available news for MCD at offset 5000.\n",
      "Saved 5094 news items for MCD to sp500_news_data/MCD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 46/503: TDY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TDY from 2019-01-01\n",
      "Company TDY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 750 news items for TDY. Total for this company: 750\n",
      "Reached the end of available news for TDY at offset 0.\n",
      "Saved 750 news items for TDY to sp500_news_data/TDY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 47/503: NTAP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NTAP from 2019-01-01\n",
      "Company NTAP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 930 news items for NTAP. Total for this company: 930\n",
      "Reached the end of available news for NTAP at offset 0.\n",
      "Saved 930 news items for NTAP to sp500_news_data/NTAP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 48/503: KO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KO from 2019-01-01\n",
      "Company KO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KO. Total for this company: 1000\n",
      "Company KO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for KO. Total for this company: 2000\n",
      "Company KO - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for KO. Total for this company: 3000\n",
      "Company KO - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for KO. Total for this company: 4000\n",
      "Company KO - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for KO. Total for this company: 5000\n",
      "Company KO - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 278 news items for KO. Total for this company: 5278\n",
      "Reached the end of available news for KO at offset 5000.\n",
      "Saved 5278 news items for KO to sp500_news_data/KO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 49/503: GS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GS from 2019-01-01\n",
      "Company GS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GS. Total for this company: 1000\n",
      "Company GS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GS. Total for this company: 2000\n",
      "Company GS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for GS. Total for this company: 3000\n",
      "Company GS - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for GS. Total for this company: 4000\n",
      "Company GS - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for GS. Total for this company: 5000\n",
      "Company GS - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for GS. Total for this company: 6000\n",
      "Company GS - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 619 news items for GS. Total for this company: 6619\n",
      "Reached the end of available news for GS at offset 6000.\n",
      "Saved 6619 news items for GS to sp500_news_data/GS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 50/503: AJG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AJG from 2019-01-01\n",
      "Company AJG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 936 news items for AJG. Total for this company: 936\n",
      "Reached the end of available news for AJG at offset 0.\n",
      "Saved 936 news items for AJG to sp500_news_data/AJG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 51/503: NKE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NKE from 2019-01-01\n",
      "Company NKE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NKE. Total for this company: 1000\n",
      "Company NKE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NKE. Total for this company: 2000\n",
      "Company NKE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for NKE. Total for this company: 3000\n",
      "Company NKE - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for NKE. Total for this company: 4000\n",
      "Company NKE - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for NKE. Total for this company: 5000\n",
      "Company NKE - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 425 news items for NKE. Total for this company: 5425\n",
      "Reached the end of available news for NKE at offset 5000.\n",
      "Saved 5425 news items for NKE to sp500_news_data/NKE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 52/503: KMB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KMB from 2019-01-01\n",
      "Company KMB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KMB. Total for this company: 1000\n",
      "Company KMB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 375 news items for KMB. Total for this company: 1375\n",
      "Reached the end of available news for KMB at offset 1000.\n",
      "Saved 1375 news items for KMB to sp500_news_data/KMB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 53/503: ROL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ROL from 2019-01-01\n",
      "Company ROL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 641 news items for ROL. Total for this company: 641\n",
      "Reached the end of available news for ROL at offset 0.\n",
      "Saved 641 news items for ROL to sp500_news_data/ROL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 54/503: HES\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HES from 2019-01-01\n",
      "Company HES - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HES. Total for this company: 1000\n",
      "Company HES - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 173 news items for HES. Total for this company: 1173\n",
      "Reached the end of available news for HES at offset 1000.\n",
      "Saved 1173 news items for HES to sp500_news_data/HES_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 55/503: IT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IT from 2019-01-01\n",
      "Company IT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for IT. Total for this company: 1000\n",
      "Company IT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 986 news items for IT. Total for this company: 1986\n",
      "Reached the end of available news for IT at offset 1000.\n",
      "Saved 1986 news items for IT to sp500_news_data/IT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 56/503: CTSH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CTSH from 2019-01-01\n",
      "Company CTSH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 760 news items for CTSH. Total for this company: 760\n",
      "Reached the end of available news for CTSH at offset 0.\n",
      "Saved 760 news items for CTSH to sp500_news_data/CTSH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 57/503: WEC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WEC from 2019-01-01\n",
      "Company WEC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 641 news items for WEC. Total for this company: 641\n",
      "Reached the end of available news for WEC at offset 0.\n",
      "Saved 641 news items for WEC to sp500_news_data/WEC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 58/503: PG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PG from 2019-01-01\n",
      "Company PG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PG. Total for this company: 1000\n",
      "Company PG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PG. Total for this company: 2000\n",
      "Company PG - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for PG. Total for this company: 3000\n",
      "Company PG - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 999 news items for PG. Total for this company: 3999\n",
      "Reached the end of available news for PG at offset 3000.\n",
      "Saved 3999 news items for PG to sp500_news_data/PG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 59/503: SNA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SNA from 2019-01-01\n",
      "Company SNA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 566 news items for SNA. Total for this company: 566\n",
      "Reached the end of available news for SNA at offset 0.\n",
      "Saved 566 news items for SNA to sp500_news_data/SNA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 60/503: IRM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IRM from 2019-01-01\n",
      "Company IRM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 695 news items for IRM. Total for this company: 695\n",
      "Reached the end of available news for IRM at offset 0.\n",
      "Saved 695 news items for IRM to sp500_news_data/IRM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 61/503: EOG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EOG from 2019-01-01\n",
      "Company EOG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EOG. Total for this company: 1000\n",
      "Company EOG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 569 news items for EOG. Total for this company: 1569\n",
      "Reached the end of available news for EOG at offset 1000.\n",
      "Saved 1569 news items for EOG to sp500_news_data/EOG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 62/503: FCX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FCX from 2019-01-01\n",
      "Company FCX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FCX. Total for this company: 1000\n",
      "Company FCX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 555 news items for FCX. Total for this company: 1555\n",
      "Reached the end of available news for FCX at offset 1000.\n",
      "Saved 1555 news items for FCX to sp500_news_data/FCX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 63/503: TXN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TXN from 2019-01-01\n",
      "Company TXN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TXN. Total for this company: 1000\n",
      "Company TXN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for TXN. Total for this company: 2000\n",
      "Company TXN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 311 news items for TXN. Total for this company: 2311\n",
      "Reached the end of available news for TXN at offset 2000.\n",
      "Saved 2311 news items for TXN to sp500_news_data/TXN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 64/503: AON\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AON from 2019-01-01\n",
      "Company AON - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 846 news items for AON. Total for this company: 846\n",
      "Reached the end of available news for AON at offset 0.\n",
      "Saved 846 news items for AON to sp500_news_data/AON_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 65/503: CHRW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CHRW from 2019-01-01\n",
      "Company CHRW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CHRW. Total for this company: 1000\n",
      "Company CHRW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 17 news items for CHRW. Total for this company: 1017\n",
      "Reached the end of available news for CHRW at offset 1000.\n",
      "Saved 1017 news items for CHRW to sp500_news_data/CHRW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 66/503: FDS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FDS from 2019-01-01\n",
      "Company FDS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 746 news items for FDS. Total for this company: 746\n",
      "Reached the end of available news for FDS at offset 0.\n",
      "Saved 746 news items for FDS to sp500_news_data/FDS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 67/503: GPN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GPN from 2019-01-01\n",
      "Company GPN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 863 news items for GPN. Total for this company: 863\n",
      "Reached the end of available news for GPN at offset 0.\n",
      "Saved 863 news items for GPN to sp500_news_data/GPN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 68/503: CMG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CMG from 2019-01-01\n",
      "Company CMG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CMG. Total for this company: 1000\n",
      "Company CMG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CMG. Total for this company: 2000\n",
      "Company CMG - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CMG. Total for this company: 3000\n",
      "Company CMG - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 759 news items for CMG. Total for this company: 3759\n",
      "Reached the end of available news for CMG at offset 3000.\n",
      "Saved 3759 news items for CMG to sp500_news_data/CMG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 69/503: TEL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TEL from 2019-01-01\n",
      "Company TEL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 611 news items for TEL. Total for this company: 611\n",
      "Reached the end of available news for TEL at offset 0.\n",
      "Saved 611 news items for TEL to sp500_news_data/TEL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 70/503: MSCI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MSCI from 2019-01-01\n",
      "Company MSCI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MSCI. Total for this company: 1000\n",
      "Company MSCI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 351 news items for MSCI. Total for this company: 1351\n",
      "Reached the end of available news for MSCI at offset 1000.\n",
      "Saved 1351 news items for MSCI to sp500_news_data/MSCI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 71/503: CF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CF from 2019-01-01\n",
      "Company CF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CF. Total for this company: 1000\n",
      "Company CF - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 24 news items for CF. Total for this company: 1024\n",
      "Reached the end of available news for CF at offset 1000.\n",
      "Saved 1024 news items for CF to sp500_news_data/CF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 72/503: TJX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TJX from 2019-01-01\n",
      "Company TJX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TJX. Total for this company: 1000\n",
      "Company TJX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 702 news items for TJX. Total for this company: 1702\n",
      "Reached the end of available news for TJX at offset 1000.\n",
      "Saved 1702 news items for TJX to sp500_news_data/TJX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 73/503: WRB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WRB from 2019-01-01\n",
      "Company WRB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 787 news items for WRB. Total for this company: 787\n",
      "Reached the end of available news for WRB at offset 0.\n",
      "Saved 787 news items for WRB to sp500_news_data/WRB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 74/503: DLTR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DLTR from 2019-01-01\n",
      "Company DLTR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DLTR. Total for this company: 1000\n",
      "Company DLTR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 920 news items for DLTR. Total for this company: 1920\n",
      "Reached the end of available news for DLTR at offset 1000.\n",
      "Saved 1920 news items for DLTR to sp500_news_data/DLTR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 75/503: DRI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DRI from 2019-01-01\n",
      "Company DRI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DRI. Total for this company: 1000\n",
      "Company DRI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 280 news items for DRI. Total for this company: 1280\n",
      "Reached the end of available news for DRI at offset 1000.\n",
      "Saved 1280 news items for DRI to sp500_news_data/DRI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 76/503: JPM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JPM from 2019-01-01\n",
      "Company JPM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 1000\n",
      "Company JPM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 2000\n",
      "Company JPM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 3000\n",
      "Company JPM - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 4000\n",
      "Company JPM - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 5000\n",
      "Company JPM - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 6000\n",
      "Company JPM - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 7000\n",
      "Company JPM - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for JPM. Total for this company: 8000\n",
      "Company JPM - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 799 news items for JPM. Total for this company: 8799\n",
      "Reached the end of available news for JPM at offset 8000.\n",
      "Saved 8799 news items for JPM to sp500_news_data/JPM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 77/503: CB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CB from 2019-01-01\n",
      "Company CB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CB. Total for this company: 1000\n",
      "Company CB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 279 news items for CB. Total for this company: 1279\n",
      "Reached the end of available news for CB at offset 1000.\n",
      "Saved 1279 news items for CB to sp500_news_data/CB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 78/503: KEY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KEY from 2019-01-01\n",
      "Company KEY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KEY. Total for this company: 1000\n",
      "Company KEY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for KEY. Total for this company: 2000\n",
      "Company KEY - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 392 news items for KEY. Total for this company: 2392\n",
      "Reached the end of available news for KEY at offset 2000.\n",
      "Saved 2392 news items for KEY to sp500_news_data/KEY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 79/503: GD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GD from 2019-01-01\n",
      "Company GD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GD. Total for this company: 1000\n",
      "Company GD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 510 news items for GD. Total for this company: 1510\n",
      "Reached the end of available news for GD at offset 1000.\n",
      "Saved 1510 news items for GD to sp500_news_data/GD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 80/503: TGT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TGT from 2019-01-01\n",
      "Company TGT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TGT. Total for this company: 1000\n",
      "Company TGT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for TGT. Total for this company: 2000\n",
      "Company TGT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for TGT. Total for this company: 3000\n",
      "Company TGT - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for TGT. Total for this company: 4000\n",
      "Company TGT - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for TGT. Total for this company: 5000\n",
      "Company TGT - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 596 news items for TGT. Total for this company: 5596\n",
      "Reached the end of available news for TGT at offset 5000.\n",
      "Saved 5596 news items for TGT to sp500_news_data/TGT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 81/503: EQR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EQR from 2019-01-01\n",
      "Company EQR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 640 news items for EQR. Total for this company: 640\n",
      "Reached the end of available news for EQR at offset 0.\n",
      "Saved 640 news items for EQR to sp500_news_data/EQR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 82/503: RJF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RJF from 2019-01-01\n",
      "Company RJF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 666 news items for RJF. Total for this company: 666\n",
      "Reached the end of available news for RJF at offset 0.\n",
      "Saved 666 news items for RJF to sp500_news_data/RJF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 83/503: BLDR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BLDR from 2019-01-01\n",
      "Company BLDR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 583 news items for BLDR. Total for this company: 583\n",
      "Reached the end of available news for BLDR at offset 0.\n",
      "Saved 583 news items for BLDR to sp500_news_data/BLDR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 84/503: SWKS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SWKS from 2019-01-01\n",
      "Company SWKS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SWKS. Total for this company: 1000\n",
      "Company SWKS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 62 news items for SWKS. Total for this company: 1062\n",
      "Reached the end of available news for SWKS at offset 1000.\n",
      "Saved 1062 news items for SWKS to sp500_news_data/SWKS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 85/503: MS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MS from 2019-01-01\n",
      "Company MS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MS. Total for this company: 1000\n",
      "Company MS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MS. Total for this company: 2000\n",
      "Company MS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MS. Total for this company: 3000\n",
      "Company MS - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MS. Total for this company: 4000\n",
      "Company MS - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 483 news items for MS. Total for this company: 4483\n",
      "Reached the end of available news for MS at offset 4000.\n",
      "Saved 4483 news items for MS to sp500_news_data/MS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 86/503: RF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RF from 2019-01-01\n",
      "Company RF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for RF. Total for this company: 1000\n",
      "Company RF - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 211 news items for RF. Total for this company: 1211\n",
      "Reached the end of available news for RF at offset 1000.\n",
      "Saved 1211 news items for RF to sp500_news_data/RF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 87/503: PANW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PANW from 2019-01-01\n",
      "Company PANW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PANW. Total for this company: 1000\n",
      "Company PANW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PANW. Total for this company: 2000\n",
      "Company PANW - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for PANW. Total for this company: 3000\n",
      "Company PANW - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 193 news items for PANW. Total for this company: 3193\n",
      "Reached the end of available news for PANW at offset 3000.\n",
      "Saved 3193 news items for PANW to sp500_news_data/PANW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 88/503: ERIE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ERIE from 2019-01-01\n",
      "Company ERIE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 358 news items for ERIE. Total for this company: 358\n",
      "Reached the end of available news for ERIE at offset 0.\n",
      "Saved 358 news items for ERIE to sp500_news_data/ERIE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 89/503: AEP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AEP from 2019-01-01\n",
      "Company AEP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 595 news items for AEP. Total for this company: 595\n",
      "Reached the end of available news for AEP at offset 0.\n",
      "Saved 595 news items for AEP to sp500_news_data/AEP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 90/503: CE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CE from 2019-01-01\n",
      "Company CE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 886 news items for CE. Total for this company: 886\n",
      "Reached the end of available news for CE at offset 0.\n",
      "Saved 886 news items for CE to sp500_news_data/CE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 91/503: AMAT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMAT from 2019-01-01\n",
      "Company AMAT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AMAT. Total for this company: 1000\n",
      "Company AMAT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AMAT. Total for this company: 2000\n",
      "Company AMAT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 523 news items for AMAT. Total for this company: 2523\n",
      "Reached the end of available news for AMAT at offset 2000.\n",
      "Saved 2523 news items for AMAT to sp500_news_data/AMAT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 92/503: CCI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CCI from 2019-01-01\n",
      "Company CCI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CCI. Total for this company: 1000\n",
      "Company CCI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 204 news items for CCI. Total for this company: 1204\n",
      "Reached the end of available news for CCI at offset 1000.\n",
      "Saved 1204 news items for CCI to sp500_news_data/CCI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 93/503: LULU\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LULU from 2019-01-01\n",
      "Company LULU - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LULU. Total for this company: 1000\n",
      "Company LULU - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for LULU. Total for this company: 2000\n",
      "Company LULU - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 858 news items for LULU. Total for this company: 2858\n",
      "Reached the end of available news for LULU at offset 2000.\n",
      "Saved 2858 news items for LULU to sp500_news_data/LULU_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 94/503: VTR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VTR from 2019-01-01\n",
      "Company VTR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 616 news items for VTR. Total for this company: 616\n",
      "Reached the end of available news for VTR at offset 0.\n",
      "Saved 616 news items for VTR to sp500_news_data/VTR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 95/503: PPG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PPG from 2019-01-01\n",
      "Company PPG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PPG. Total for this company: 1000\n",
      "Company PPG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 255 news items for PPG. Total for this company: 1255\n",
      "Reached the end of available news for PPG at offset 1000.\n",
      "Saved 1255 news items for PPG to sp500_news_data/PPG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 96/503: INTU\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for INTU from 2019-01-01\n",
      "Company INTU - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for INTU. Total for this company: 1000\n",
      "Company INTU - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 875 news items for INTU. Total for this company: 1875\n",
      "Reached the end of available news for INTU at offset 1000.\n",
      "Saved 1875 news items for INTU to sp500_news_data/INTU_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 97/503: IPG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IPG from 2019-01-01\n",
      "Company IPG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for IPG. Total for this company: 1000\n",
      "Company IPG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 357 news items for IPG. Total for this company: 1357\n",
      "Reached the end of available news for IPG at offset 1000.\n",
      "Saved 1357 news items for IPG to sp500_news_data/IPG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 98/503: A\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for A from 2019-01-01\n",
      "Company A - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for A. Total for this company: 1000\n",
      "Company A - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for A. Total for this company: 2000\n",
      "Company A - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for A. Total for this company: 3000\n",
      "Company A - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for A. Total for this company: 4000\n",
      "Company A - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 363 news items for A. Total for this company: 4363\n",
      "Reached the end of available news for A at offset 4000.\n",
      "Saved 4363 news items for A to sp500_news_data/A_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 99/503: IFF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IFF from 2019-01-01\n",
      "Company IFF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 742 news items for IFF. Total for this company: 742\n",
      "Reached the end of available news for IFF at offset 0.\n",
      "Saved 742 news items for IFF to sp500_news_data/IFF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 100/503: EL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EL from 2019-01-01\n",
      "Company EL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EL. Total for this company: 1000\n",
      "Company EL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 611 news items for EL. Total for this company: 1611\n",
      "Reached the end of available news for EL at offset 1000.\n",
      "Saved 1611 news items for EL to sp500_news_data/EL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 101/503: CNP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CNP from 2019-01-01\n",
      "Company CNP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 700 news items for CNP. Total for this company: 700\n",
      "Reached the end of available news for CNP at offset 0.\n",
      "Saved 700 news items for CNP to sp500_news_data/CNP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 102/503: AVY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AVY from 2019-01-01\n",
      "Company AVY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 472 news items for AVY. Total for this company: 472\n",
      "Reached the end of available news for AVY at offset 0.\n",
      "Saved 472 news items for AVY to sp500_news_data/AVY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 103/503: UNP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UNP from 2019-01-01\n",
      "Company UNP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for UNP. Total for this company: 1000\n",
      "Company UNP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 814 news items for UNP. Total for this company: 1814\n",
      "Reached the end of available news for UNP at offset 1000.\n",
      "Saved 1814 news items for UNP to sp500_news_data/UNP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 104/503: MAS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MAS from 2019-01-01\n",
      "Company MAS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 613 news items for MAS. Total for this company: 613\n",
      "Reached the end of available news for MAS at offset 0.\n",
      "Saved 613 news items for MAS to sp500_news_data/MAS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 105/503: PSX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PSX from 2019-01-01\n",
      "Company PSX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PSX. Total for this company: 1000\n",
      "Company PSX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 658 news items for PSX. Total for this company: 1658\n",
      "Reached the end of available news for PSX at offset 1000.\n",
      "Saved 1658 news items for PSX to sp500_news_data/PSX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 106/503: GLW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GLW from 2019-01-01\n",
      "Company GLW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 840 news items for GLW. Total for this company: 840\n",
      "Reached the end of available news for GLW at offset 0.\n",
      "Saved 840 news items for GLW to sp500_news_data/GLW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 107/503: CME\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CME from 2019-01-01\n",
      "Company CME - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CME. Total for this company: 1000\n",
      "Company CME - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 345 news items for CME. Total for this company: 1345\n",
      "Reached the end of available news for CME at offset 1000.\n",
      "Saved 1345 news items for CME to sp500_news_data/CME_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 108/503: NCLH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NCLH from 2019-01-01\n",
      "Company NCLH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NCLH. Total for this company: 1000\n",
      "Company NCLH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NCLH. Total for this company: 2000\n",
      "Company NCLH - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 16 news items for NCLH. Total for this company: 2016\n",
      "Reached the end of available news for NCLH at offset 2000.\n",
      "Saved 2016 news items for NCLH to sp500_news_data/NCLH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 109/503: WDAY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WDAY from 2019-01-01\n",
      "Company WDAY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WDAY. Total for this company: 1000\n",
      "Company WDAY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 637 news items for WDAY. Total for this company: 1637\n",
      "Reached the end of available news for WDAY at offset 1000.\n",
      "Saved 1637 news items for WDAY to sp500_news_data/WDAY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 110/503: SBUX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SBUX from 2019-01-01\n",
      "Company SBUX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SBUX. Total for this company: 1000\n",
      "Company SBUX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for SBUX. Total for this company: 2000\n",
      "Company SBUX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for SBUX. Total for this company: 3000\n",
      "Company SBUX - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for SBUX. Total for this company: 4000\n",
      "Company SBUX - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for SBUX. Total for this company: 5000\n",
      "Company SBUX - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 608 news items for SBUX. Total for this company: 5608\n",
      "Reached the end of available news for SBUX at offset 5000.\n",
      "Saved 5608 news items for SBUX to sp500_news_data/SBUX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 111/503: STE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for STE from 2019-01-01\n",
      "Company STE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 541 news items for STE. Total for this company: 541\n",
      "Reached the end of available news for STE at offset 0.\n",
      "Saved 541 news items for STE to sp500_news_data/STE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 112/503: CAG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CAG from 2019-01-01\n",
      "Company CAG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CAG. Total for this company: 1000\n",
      "Company CAG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 125 news items for CAG. Total for this company: 1125\n",
      "Reached the end of available news for CAG at offset 1000.\n",
      "Saved 1125 news items for CAG to sp500_news_data/CAG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 113/503: PODD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PODD from 2019-01-01\n",
      "Company PODD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 772 news items for PODD. Total for this company: 772\n",
      "Reached the end of available news for PODD at offset 0.\n",
      "Saved 772 news items for PODD to sp500_news_data/PODD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 114/503: CLX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CLX from 2019-01-01\n",
      "Company CLX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CLX. Total for this company: 1000\n",
      "Company CLX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 387 news items for CLX. Total for this company: 1387\n",
      "Reached the end of available news for CLX at offset 1000.\n",
      "Saved 1387 news items for CLX to sp500_news_data/CLX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 115/503: UHS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UHS from 2019-01-01\n",
      "Company UHS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 783 news items for UHS. Total for this company: 783\n",
      "Reached the end of available news for UHS at offset 0.\n",
      "Saved 783 news items for UHS to sp500_news_data/UHS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 116/503: POOL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for POOL from 2019-01-01\n",
      "Company POOL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 854 news items for POOL. Total for this company: 854\n",
      "Reached the end of available news for POOL at offset 0.\n",
      "Saved 854 news items for POOL to sp500_news_data/POOL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 117/503: ODFL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ODFL from 2019-01-01\n",
      "Company ODFL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 856 news items for ODFL. Total for this company: 856\n",
      "Reached the end of available news for ODFL at offset 0.\n",
      "Saved 856 news items for ODFL to sp500_news_data/ODFL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 118/503: MRNA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MRNA from 2019-01-01\n",
      "Company MRNA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 1000\n",
      "Company MRNA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 2000\n",
      "Company MRNA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 3000\n",
      "Company MRNA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 4000\n",
      "Company MRNA - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 5000\n",
      "Company MRNA - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 6000\n",
      "Company MRNA - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 7000\n",
      "Company MRNA - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for MRNA. Total for this company: 8000\n",
      "Company MRNA - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 357 news items for MRNA. Total for this company: 8357\n",
      "Reached the end of available news for MRNA at offset 8000.\n",
      "Saved 8357 news items for MRNA to sp500_news_data/MRNA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 119/503: LUV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LUV from 2019-01-01\n",
      "Company LUV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LUV. Total for this company: 1000\n",
      "Company LUV - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for LUV. Total for this company: 2000\n",
      "Company LUV - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for LUV. Total for this company: 3000\n",
      "Company LUV - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 986 news items for LUV. Total for this company: 3986\n",
      "Reached the end of available news for LUV at offset 3000.\n",
      "Saved 3986 news items for LUV to sp500_news_data/LUV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 120/503: ZBRA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ZBRA from 2019-01-01\n",
      "Company ZBRA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 852 news items for ZBRA. Total for this company: 852\n",
      "Reached the end of available news for ZBRA at offset 0.\n",
      "Saved 852 news items for ZBRA to sp500_news_data/ZBRA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 121/503: ROST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ROST from 2019-01-01\n",
      "Company ROST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ROST. Total for this company: 1000\n",
      "Company ROST - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 150 news items for ROST. Total for this company: 1150\n",
      "Reached the end of available news for ROST at offset 1000.\n",
      "Saved 1150 news items for ROST to sp500_news_data/ROST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 122/503: FFIV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FFIV from 2019-01-01\n",
      "Company FFIV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 657 news items for FFIV. Total for this company: 657\n",
      "Reached the end of available news for FFIV at offset 0.\n",
      "Saved 657 news items for FFIV to sp500_news_data/FFIV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 123/503: HRL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HRL from 2019-01-01\n",
      "Company HRL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HRL. Total for this company: 1000\n",
      "Company HRL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 386 news items for HRL. Total for this company: 1386\n",
      "Reached the end of available news for HRL at offset 1000.\n",
      "Saved 1386 news items for HRL to sp500_news_data/HRL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 124/503: TSCO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TSCO from 2019-01-01\n",
      "Company TSCO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TSCO. Total for this company: 1000\n",
      "Company TSCO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 423 news items for TSCO. Total for this company: 1423\n",
      "Reached the end of available news for TSCO at offset 1000.\n",
      "Saved 1423 news items for TSCO to sp500_news_data/TSCO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 125/503: COP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for COP from 2019-01-01\n",
      "Company COP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for COP. Total for this company: 1000\n",
      "Company COP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for COP. Total for this company: 2000\n",
      "Company COP - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 788 news items for COP. Total for this company: 2788\n",
      "Reached the end of available news for COP at offset 2000.\n",
      "Saved 2788 news items for COP to sp500_news_data/COP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 126/503: CSCO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CSCO from 2019-01-01\n",
      "Company CSCO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CSCO. Total for this company: 1000\n",
      "Company CSCO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CSCO. Total for this company: 2000\n",
      "Company CSCO - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CSCO. Total for this company: 3000\n",
      "Company CSCO - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 972 news items for CSCO. Total for this company: 3972\n",
      "Reached the end of available news for CSCO at offset 3000.\n",
      "Saved 3972 news items for CSCO to sp500_news_data/CSCO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 127/503: AEE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AEE from 2019-01-01\n",
      "Company AEE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 631 news items for AEE. Total for this company: 631\n",
      "Reached the end of available news for AEE at offset 0.\n",
      "Saved 631 news items for AEE to sp500_news_data/AEE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 128/503: CL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CL from 2019-01-01\n",
      "Company CL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CL. Total for this company: 1000\n",
      "Company CL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 564 news items for CL. Total for this company: 1564\n",
      "Reached the end of available news for CL at offset 1000.\n",
      "Saved 1564 news items for CL to sp500_news_data/CL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 129/503: DGX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DGX from 2019-01-01\n",
      "Company DGX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DGX. Total for this company: 1000\n",
      "Company DGX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 361 news items for DGX. Total for this company: 1361\n",
      "Reached the end of available news for DGX at offset 1000.\n",
      "Saved 1361 news items for DGX to sp500_news_data/DGX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 130/503: AME\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AME from 2019-01-01\n",
      "Company AME - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 748 news items for AME. Total for this company: 748\n",
      "Reached the end of available news for AME at offset 0.\n",
      "Saved 748 news items for AME to sp500_news_data/AME_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 131/503: AOS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AOS from 2019-01-01\n",
      "Company AOS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 629 news items for AOS. Total for this company: 629\n",
      "Reached the end of available news for AOS at offset 0.\n",
      "Saved 629 news items for AOS to sp500_news_data/AOS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 132/503: BIIB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BIIB from 2019-01-01\n",
      "Company BIIB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BIIB. Total for this company: 1000\n",
      "Company BIIB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BIIB. Total for this company: 2000\n",
      "Company BIIB - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 998 news items for BIIB. Total for this company: 2998\n",
      "Reached the end of available news for BIIB at offset 2000.\n",
      "Saved 2998 news items for BIIB to sp500_news_data/BIIB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 133/503: BRO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BRO from 2019-01-01\n",
      "Company BRO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 921 news items for BRO. Total for this company: 921\n",
      "Reached the end of available news for BRO at offset 0.\n",
      "Saved 921 news items for BRO to sp500_news_data/BRO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 134/503: MSI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MSI from 2019-01-01\n",
      "Company MSI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MSI. Total for this company: 1000\n",
      "Company MSI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 72 news items for MSI. Total for this company: 1072\n",
      "Reached the end of available news for MSI at offset 1000.\n",
      "Saved 1072 news items for MSI to sp500_news_data/MSI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 135/503: ESS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ESS from 2019-01-01\n",
      "Company ESS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 505 news items for ESS. Total for this company: 505\n",
      "Reached the end of available news for ESS at offset 0.\n",
      "Saved 505 news items for ESS to sp500_news_data/ESS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 136/503: HIG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HIG from 2019-01-01\n",
      "Company HIG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 618 news items for HIG. Total for this company: 618\n",
      "Reached the end of available news for HIG at offset 0.\n",
      "Saved 618 news items for HIG to sp500_news_data/HIG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 137/503: CDNS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CDNS from 2019-01-01\n",
      "Company CDNS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CDNS. Total for this company: 1000\n",
      "Company CDNS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 534 news items for CDNS. Total for this company: 1534\n",
      "Reached the end of available news for CDNS at offset 1000.\n",
      "Saved 1534 news items for CDNS to sp500_news_data/CDNS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 138/503: EQIX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EQIX from 2019-01-01\n",
      "Company EQIX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 936 news items for EQIX. Total for this company: 936\n",
      "Reached the end of available news for EQIX at offset 0.\n",
      "Saved 936 news items for EQIX to sp500_news_data/EQIX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 139/503: EXR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EXR from 2019-01-01\n",
      "Company EXR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 771 news items for EXR. Total for this company: 771\n",
      "Reached the end of available news for EXR at offset 0.\n",
      "Saved 771 news items for EXR to sp500_news_data/EXR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 140/503: CVX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CVX from 2019-01-01\n",
      "Company CVX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 1000\n",
      "Company CVX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 2000\n",
      "Company CVX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 3000\n",
      "Company CVX - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 4000\n",
      "Company CVX - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 5000\n",
      "Company CVX - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 6000\n",
      "Company CVX - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 7000\n",
      "Company CVX - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for CVX. Total for this company: 8000\n",
      "Company CVX - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 170 news items for CVX. Total for this company: 8170\n",
      "Reached the end of available news for CVX at offset 8000.\n",
      "Saved 8170 news items for CVX to sp500_news_data/CVX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 141/503: HUM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HUM from 2019-01-01\n",
      "Company HUM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HUM. Total for this company: 1000\n",
      "Company HUM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 531 news items for HUM. Total for this company: 1531\n",
      "Reached the end of available news for HUM at offset 1000.\n",
      "Saved 1531 news items for HUM to sp500_news_data/HUM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 142/503: BBY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BBY from 2019-01-01\n",
      "Company BBY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BBY. Total for this company: 1000\n",
      "Company BBY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 729 news items for BBY. Total for this company: 1729\n",
      "Reached the end of available news for BBY at offset 1000.\n",
      "Saved 1729 news items for BBY to sp500_news_data/BBY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 143/503: PLD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PLD from 2019-01-01\n",
      "Company PLD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PLD. Total for this company: 1000\n",
      "Company PLD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 664 news items for PLD. Total for this company: 1664\n",
      "Reached the end of available news for PLD at offset 1000.\n",
      "Saved 1664 news items for PLD to sp500_news_data/PLD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 144/503: OXY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for OXY from 2019-01-01\n",
      "Company OXY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for OXY. Total for this company: 1000\n",
      "Company OXY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for OXY. Total for this company: 2000\n",
      "Company OXY - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for OXY. Total for this company: 3000\n",
      "Company OXY - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 821 news items for OXY. Total for this company: 3821\n",
      "Reached the end of available news for OXY at offset 3000.\n",
      "Saved 3821 news items for OXY to sp500_news_data/OXY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 145/503: T\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for T from 2019-01-01\n",
      "Company T - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for T. Total for this company: 1000\n",
      "Company T - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for T. Total for this company: 2000\n",
      "Company T - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for T. Total for this company: 3000\n",
      "Company T - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for T. Total for this company: 4000\n",
      "Company T - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for T. Total for this company: 5000\n",
      "Company T - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for T. Total for this company: 6000\n",
      "Company T - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 298 news items for T. Total for this company: 6298\n",
      "Reached the end of available news for T at offset 6000.\n",
      "Saved 6298 news items for T to sp500_news_data/T_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 146/503: KLAC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KLAC from 2019-01-01\n",
      "Company KLAC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 584 news items for KLAC. Total for this company: 584\n",
      "Reached the end of available news for KLAC at offset 0.\n",
      "Saved 584 news items for KLAC to sp500_news_data/KLAC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 147/503: LLY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LLY from 2019-01-01\n",
      "Company LLY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LLY. Total for this company: 1000\n",
      "Company LLY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for LLY. Total for this company: 2000\n",
      "Company LLY - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for LLY. Total for this company: 3000\n",
      "Company LLY - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for LLY. Total for this company: 4000\n",
      "Company LLY - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for LLY. Total for this company: 5000\n",
      "Company LLY - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 695 news items for LLY. Total for this company: 5695\n",
      "Reached the end of available news for LLY at offset 5000.\n",
      "Saved 5695 news items for LLY to sp500_news_data/LLY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 148/503: APH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for APH from 2019-01-01\n",
      "Company APH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 625 news items for APH. Total for this company: 625\n",
      "Reached the end of available news for APH at offset 0.\n",
      "Saved 625 news items for APH to sp500_news_data/APH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 149/503: PRU\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PRU from 2019-01-01\n",
      "Company PRU - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PRU. Total for this company: 1000\n",
      "Company PRU - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 102 news items for PRU. Total for this company: 1102\n",
      "Reached the end of available news for PRU at offset 1000.\n",
      "Saved 1102 news items for PRU to sp500_news_data/PRU_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 150/503: EMN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EMN from 2019-01-01\n",
      "Company EMN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 761 news items for EMN. Total for this company: 761\n",
      "Reached the end of available news for EMN at offset 0.\n",
      "Saved 761 news items for EMN to sp500_news_data/EMN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 151/503: IP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IP from 2019-01-01\n",
      "Company IP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for IP. Total for this company: 1000\n",
      "Company IP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 284 news items for IP. Total for this company: 1284\n",
      "Reached the end of available news for IP at offset 1000.\n",
      "Saved 1284 news items for IP to sp500_news_data/IP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 152/503: SPG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SPG from 2019-01-01\n",
      "Company SPG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SPG. Total for this company: 1000\n",
      "Company SPG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 161 news items for SPG. Total for this company: 1161\n",
      "Reached the end of available news for SPG at offset 1000.\n",
      "Saved 1161 news items for SPG to sp500_news_data/SPG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 153/503: FICO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FICO from 2019-01-01\n",
      "Company FICO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 936 news items for FICO. Total for this company: 936\n",
      "Reached the end of available news for FICO at offset 0.\n",
      "Saved 936 news items for FICO to sp500_news_data/FICO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 154/503: COF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for COF from 2019-01-01\n",
      "Company COF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for COF. Total for this company: 1000\n",
      "Company COF - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 241 news items for COF. Total for this company: 1241\n",
      "Reached the end of available news for COF at offset 1000.\n",
      "Saved 1241 news items for COF to sp500_news_data/COF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 155/503: CHD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CHD from 2019-01-01\n",
      "Company CHD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 738 news items for CHD. Total for this company: 738\n",
      "Reached the end of available news for CHD at offset 0.\n",
      "Saved 738 news items for CHD to sp500_news_data/CHD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 156/503: PCAR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PCAR from 2019-01-01\n",
      "Company PCAR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 901 news items for PCAR. Total for this company: 901\n",
      "Reached the end of available news for PCAR at offset 0.\n",
      "Saved 901 news items for PCAR to sp500_news_data/PCAR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 157/503: ORCL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ORCL from 2019-01-01\n",
      "Company ORCL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ORCL. Total for this company: 1000\n",
      "Company ORCL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ORCL. Total for this company: 2000\n",
      "Company ORCL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for ORCL. Total for this company: 3000\n",
      "Company ORCL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for ORCL. Total for this company: 4000\n",
      "Company ORCL - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 337 news items for ORCL. Total for this company: 4337\n",
      "Reached the end of available news for ORCL at offset 4000.\n",
      "Saved 4337 news items for ORCL to sp500_news_data/ORCL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 158/503: FRT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FRT from 2019-01-01\n",
      "Company FRT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 726 news items for FRT. Total for this company: 726\n",
      "Reached the end of available news for FRT at offset 0.\n",
      "Saved 726 news items for FRT to sp500_news_data/FRT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 159/503: PNW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PNW from 2019-01-01\n",
      "Company PNW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 491 news items for PNW. Total for this company: 491\n",
      "Reached the end of available news for PNW at offset 0.\n",
      "Saved 491 news items for PNW to sp500_news_data/PNW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 160/503: RL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RL from 2019-01-01\n",
      "Company RL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for RL. Total for this company: 1000\n",
      "Company RL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 143 news items for RL. Total for this company: 1143\n",
      "Reached the end of available news for RL at offset 1000.\n",
      "Saved 1143 news items for RL to sp500_news_data/RL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 161/503: HCA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HCA from 2019-01-01\n",
      "Company HCA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HCA. Total for this company: 1000\n",
      "Company HCA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 599 news items for HCA. Total for this company: 1599\n",
      "Reached the end of available news for HCA at offset 1000.\n",
      "Saved 1599 news items for HCA to sp500_news_data/HCA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 162/503: FIS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FIS from 2019-01-01\n",
      "Company FIS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FIS. Total for this company: 1000\n",
      "Company FIS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 144 news items for FIS. Total for this company: 1144\n",
      "Reached the end of available news for FIS at offset 1000.\n",
      "Saved 1144 news items for FIS to sp500_news_data/FIS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 163/503: ZTS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ZTS from 2019-01-01\n",
      "Company ZTS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 952 news items for ZTS. Total for this company: 952\n",
      "Reached the end of available news for ZTS at offset 0.\n",
      "Saved 952 news items for ZTS to sp500_news_data/ZTS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 164/503: CDW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CDW from 2019-01-01\n",
      "Company CDW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 594 news items for CDW. Total for this company: 594\n",
      "Reached the end of available news for CDW at offset 0.\n",
      "Saved 594 news items for CDW to sp500_news_data/CDW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 165/503: URI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for URI from 2019-01-01\n",
      "Company URI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for URI. Total for this company: 1000\n",
      "Company URI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 312 news items for URI. Total for this company: 1312\n",
      "Reached the end of available news for URI at offset 1000.\n",
      "Saved 1312 news items for URI to sp500_news_data/URI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 166/503: COST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for COST from 2019-01-01\n",
      "Company COST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for COST. Total for this company: 1000\n",
      "Company COST - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for COST. Total for this company: 2000\n",
      "Company COST - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for COST. Total for this company: 3000\n",
      "Company COST - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for COST. Total for this company: 4000\n",
      "Company COST - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for COST. Total for this company: 5000\n",
      "Company COST - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for COST. Total for this company: 6000\n",
      "Company COST - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for COST. Total for this company: 7000\n",
      "Company COST - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 566 news items for COST. Total for this company: 7566\n",
      "Reached the end of available news for COST at offset 7000.\n",
      "Saved 7566 news items for COST to sp500_news_data/COST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 167/503: AAPL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AAPL from 2019-01-01\n",
      "Company AAPL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 1000\n",
      "Company AAPL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 2000\n",
      "Company AAPL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 3000\n",
      "Company AAPL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 4000\n",
      "Company AAPL - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 5000\n",
      "Company AAPL - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 6000\n",
      "Company AAPL - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 7000\n",
      "Company AAPL - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 8000\n",
      "Company AAPL - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 9000\n",
      "Company AAPL - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 10000\n",
      "Company AAPL - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 11000\n",
      "Company AAPL - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 12000\n",
      "Company AAPL - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 13000\n",
      "Company AAPL - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 14000\n",
      "Company AAPL - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 15000\n",
      "Company AAPL - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 16000\n",
      "Company AAPL - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 17000\n",
      "Company AAPL - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 18000\n",
      "Company AAPL - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 19000\n",
      "Company AAPL - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 20000\n",
      "Company AAPL - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 21000\n",
      "Company AAPL - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 22000\n",
      "Company AAPL - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 23000\n",
      "Company AAPL - Batch 24/25: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 24000\n",
      "Company AAPL - Batch 25/25: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for AAPL. Total for this company: 25000\n",
      "Saved 25000 news items for AAPL to sp500_news_data/AAPL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 168/503: BA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BA from 2019-01-01\n",
      "Company BA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BA. Total for this company: 1000\n",
      "Company BA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 2000\n",
      "Company BA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 3000\n",
      "Company BA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 4000\n",
      "Company BA - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 5000\n",
      "Company BA - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 6000\n",
      "Company BA - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 7000\n",
      "Company BA - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 8000\n",
      "Company BA - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 9000\n",
      "Company BA - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 10000\n",
      "Company BA - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for BA. Total for this company: 11000\n",
      "Company BA - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 11 news items for BA. Total for this company: 11011\n",
      "Reached the end of available news for BA at offset 11000.\n",
      "Saved 11011 news items for BA to sp500_news_data/BA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 169/503: DUK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DUK from 2019-01-01\n",
      "Company DUK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DUK. Total for this company: 1000\n",
      "Company DUK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DUK. Total for this company: 2000\n",
      "Company DUK - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 505 news items for DUK. Total for this company: 2505\n",
      "Reached the end of available news for DUK at offset 2000.\n",
      "Saved 2505 news items for DUK to sp500_news_data/DUK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 170/503: BDX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BDX from 2019-01-01\n",
      "Company BDX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BDX. Total for this company: 1000\n",
      "Company BDX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 101 news items for BDX. Total for this company: 1101\n",
      "Reached the end of available news for BDX at offset 1000.\n",
      "Saved 1101 news items for BDX to sp500_news_data/BDX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 171/503: PNR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PNR from 2019-01-01\n",
      "Company PNR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 586 news items for PNR. Total for this company: 586\n",
      "Reached the end of available news for PNR at offset 0.\n",
      "Saved 586 news items for PNR to sp500_news_data/PNR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 172/503: K\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for K from 2019-01-01\n",
      "Company K - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for K. Total for this company: 1000\n",
      "Company K - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 567 news items for K. Total for this company: 1567\n",
      "Reached the end of available news for K at offset 1000.\n",
      "Saved 1567 news items for K to sp500_news_data/K_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 173/503: PAYX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PAYX from 2019-01-01\n",
      "Company PAYX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 986 news items for PAYX. Total for this company: 986\n",
      "Reached the end of available news for PAYX at offset 0.\n",
      "Saved 986 news items for PAYX to sp500_news_data/PAYX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 174/503: CAH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CAH from 2019-01-01\n",
      "Company CAH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CAH. Total for this company: 1000\n",
      "Company CAH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 812 news items for CAH. Total for this company: 1812\n",
      "Reached the end of available news for CAH at offset 1000.\n",
      "Saved 1812 news items for CAH to sp500_news_data/CAH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 175/503: MKC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MKC from 2019-01-01\n",
      "Company MKC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MKC. Total for this company: 1000\n",
      "Company MKC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 21 news items for MKC. Total for this company: 1021\n",
      "Reached the end of available news for MKC at offset 1000.\n",
      "Saved 1021 news items for MKC to sp500_news_data/MKC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 176/503: PEG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PEG from 2019-01-01\n",
      "Company PEG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 765 news items for PEG. Total for this company: 765\n",
      "Reached the end of available news for PEG at offset 0.\n",
      "Saved 765 news items for PEG to sp500_news_data/PEG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 177/503: UDR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UDR from 2019-01-01\n",
      "Company UDR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 387 news items for UDR. Total for this company: 387\n",
      "Reached the end of available news for UDR at offset 0.\n",
      "Saved 387 news items for UDR to sp500_news_data/UDR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 178/503: MA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MA from 2019-01-01\n",
      "Company MA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MA. Total for this company: 1000\n",
      "Company MA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MA. Total for this company: 2000\n",
      "Company MA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MA. Total for this company: 3000\n",
      "Company MA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MA. Total for this company: 4000\n",
      "Company MA - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 496 news items for MA. Total for this company: 4496\n",
      "Reached the end of available news for MA at offset 4000.\n",
      "Saved 4496 news items for MA to sp500_news_data/MA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 179/503: GOOGL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GOOGL from 2019-01-01\n",
      "Company GOOGL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 1000\n",
      "Company GOOGL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 2000\n",
      "Company GOOGL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 3000\n",
      "Company GOOGL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 4000\n",
      "Company GOOGL - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 5000\n",
      "Company GOOGL - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 6000\n",
      "Company GOOGL - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 7000\n",
      "Company GOOGL - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 8000\n",
      "Company GOOGL - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 9000\n",
      "Company GOOGL - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 10000\n",
      "Company GOOGL - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 11000\n",
      "Company GOOGL - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 12000\n",
      "Company GOOGL - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 13000\n",
      "Company GOOGL - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 14000\n",
      "Company GOOGL - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 15000\n",
      "Company GOOGL - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 16000\n",
      "Company GOOGL - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 17000\n",
      "Company GOOGL - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 18000\n",
      "Company GOOGL - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 19000\n",
      "Company GOOGL - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 20000\n",
      "Company GOOGL - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 21000\n",
      "Company GOOGL - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 22000\n",
      "Company GOOGL - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 23000\n",
      "Company GOOGL - Batch 24/25: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 24000\n",
      "Company GOOGL - Batch 25/25: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for GOOGL. Total for this company: 25000\n",
      "Saved 25000 news items for GOOGL to sp500_news_data/GOOGL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 180/503: DECK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DECK from 2019-01-01\n",
      "Company DECK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DECK. Total for this company: 1000\n",
      "Company DECK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 585 news items for DECK. Total for this company: 1585\n",
      "Reached the end of available news for DECK at offset 1000.\n",
      "Saved 1585 news items for DECK to sp500_news_data/DECK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 181/503: HOLX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HOLX from 2019-01-01\n",
      "Company HOLX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HOLX. Total for this company: 1000\n",
      "Company HOLX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 327 news items for HOLX. Total for this company: 1327\n",
      "Reached the end of available news for HOLX at offset 1000.\n",
      "Saved 1327 news items for HOLX to sp500_news_data/HOLX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 182/503: LVS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LVS from 2019-01-01\n",
      "Company LVS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LVS. Total for this company: 1000\n",
      "Company LVS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 343 news items for LVS. Total for this company: 1343\n",
      "Reached the end of available news for LVS at offset 1000.\n",
      "Saved 1343 news items for LVS to sp500_news_data/LVS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 183/503: EPAM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EPAM from 2019-01-01\n",
      "Company EPAM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 717 news items for EPAM. Total for this company: 717\n",
      "Reached the end of available news for EPAM at offset 0.\n",
      "Saved 717 news items for EPAM to sp500_news_data/EPAM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 184/503: BAC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BAC from 2019-01-01\n",
      "Company BAC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BAC. Total for this company: 1000\n",
      "Company BAC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BAC. Total for this company: 2000\n",
      "Company BAC - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for BAC. Total for this company: 3000\n",
      "Company BAC - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for BAC. Total for this company: 4000\n",
      "Company BAC - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for BAC. Total for this company: 5000\n",
      "Company BAC - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for BAC. Total for this company: 6000\n",
      "Company BAC - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 246 news items for BAC. Total for this company: 6246\n",
      "Reached the end of available news for BAC at offset 6000.\n",
      "Saved 6246 news items for BAC to sp500_news_data/BAC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 185/503: MO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MO from 2019-01-01\n",
      "Company MO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MO. Total for this company: 1000\n",
      "Company MO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MO. Total for this company: 2000\n",
      "Company MO - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 374 news items for MO. Total for this company: 2374\n",
      "Reached the end of available news for MO at offset 2000.\n",
      "Saved 2374 news items for MO to sp500_news_data/MO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 186/503: KMI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KMI from 2019-01-01\n",
      "Company KMI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KMI. Total for this company: 1000\n",
      "Company KMI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 719 news items for KMI. Total for this company: 1719\n",
      "Reached the end of available news for KMI at offset 1000.\n",
      "Saved 1719 news items for KMI to sp500_news_data/KMI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 187/503: FE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FE from 2019-01-01\n",
      "Company FE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FE. Total for this company: 1000\n",
      "Company FE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 306 news items for FE. Total for this company: 1306\n",
      "Reached the end of available news for FE at offset 1000.\n",
      "Saved 1306 news items for FE to sp500_news_data/FE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 188/503: HII\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HII from 2019-01-01\n",
      "Company HII - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HII. Total for this company: 1000\n",
      "Company HII - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 458 news items for HII. Total for this company: 1458\n",
      "Reached the end of available news for HII at offset 1000.\n",
      "Saved 1458 news items for HII to sp500_news_data/HII_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 189/503: NSC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NSC from 2019-01-01\n",
      "Company NSC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NSC. Total for this company: 1000\n",
      "Company NSC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 479 news items for NSC. Total for this company: 1479\n",
      "Reached the end of available news for NSC at offset 1000.\n",
      "Saved 1479 news items for NSC to sp500_news_data/NSC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 190/503: LEN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LEN from 2019-01-01\n",
      "Company LEN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LEN. Total for this company: 1000\n",
      "Company LEN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for LEN. Total for this company: 2000\n",
      "Company LEN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 32 news items for LEN. Total for this company: 2032\n",
      "Reached the end of available news for LEN at offset 2000.\n",
      "Saved 2032 news items for LEN to sp500_news_data/LEN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 191/503: MOH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MOH from 2019-01-01\n",
      "Company MOH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 744 news items for MOH. Total for this company: 744\n",
      "Reached the end of available news for MOH at offset 0.\n",
      "Saved 744 news items for MOH to sp500_news_data/MOH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 192/503: ENPH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ENPH from 2019-01-01\n",
      "Company ENPH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ENPH. Total for this company: 1000\n",
      "Company ENPH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ENPH. Total for this company: 2000\n",
      "Company ENPH - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 972 news items for ENPH. Total for this company: 2972\n",
      "Reached the end of available news for ENPH at offset 2000.\n",
      "Saved 2972 news items for ENPH to sp500_news_data/ENPH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 193/503: ABT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ABT from 2019-01-01\n",
      "Company ABT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ABT. Total for this company: 1000\n",
      "Company ABT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ABT. Total for this company: 2000\n",
      "Company ABT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 808 news items for ABT. Total for this company: 2808\n",
      "Reached the end of available news for ABT at offset 2000.\n",
      "Saved 2808 news items for ABT to sp500_news_data/ABT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 194/503: WMB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WMB from 2019-01-01\n",
      "Company WMB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WMB. Total for this company: 1000\n",
      "Company WMB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 85 news items for WMB. Total for this company: 1085\n",
      "Reached the end of available news for WMB at offset 1000.\n",
      "Saved 1085 news items for WMB to sp500_news_data/WMB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 195/503: TRV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TRV from 2019-01-01\n",
      "Company TRV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 913 news items for TRV. Total for this company: 913\n",
      "Reached the end of available news for TRV at offset 0.\n",
      "Saved 913 news items for TRV to sp500_news_data/TRV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 196/503: VLO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VLO from 2019-01-01\n",
      "Company VLO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for VLO. Total for this company: 1000\n",
      "Company VLO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 597 news items for VLO. Total for this company: 1597\n",
      "Reached the end of available news for VLO at offset 1000.\n",
      "Saved 1597 news items for VLO to sp500_news_data/VLO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 197/503: CRM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CRM from 2019-01-01\n",
      "Company CRM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CRM. Total for this company: 1000\n",
      "Company CRM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CRM. Total for this company: 2000\n",
      "Company CRM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CRM. Total for this company: 3000\n",
      "Company CRM - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for CRM. Total for this company: 4000\n",
      "Company CRM - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 956 news items for CRM. Total for this company: 4956\n",
      "Reached the end of available news for CRM at offset 4000.\n",
      "Saved 4956 news items for CRM to sp500_news_data/CRM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 198/503: SHW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SHW from 2019-01-01\n",
      "Company SHW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 928 news items for SHW. Total for this company: 928\n",
      "Reached the end of available news for SHW at offset 0.\n",
      "Saved 928 news items for SHW to sp500_news_data/SHW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 199/503: WMT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WMT from 2019-01-01\n",
      "Company WMT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 1000\n",
      "Company WMT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 2000\n",
      "Company WMT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 3000\n",
      "Company WMT - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 4000\n",
      "Company WMT - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 5000\n",
      "Company WMT - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 6000\n",
      "Company WMT - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 7000\n",
      "Company WMT - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 8000\n",
      "Company WMT - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 9000\n",
      "Company WMT - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 10000\n",
      "Company WMT - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for WMT. Total for this company: 11000\n",
      "Company WMT - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 6 news items for WMT. Total for this company: 11006\n",
      "Reached the end of available news for WMT at offset 11000.\n",
      "Saved 11006 news items for WMT to sp500_news_data/WMT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 200/503: MMM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MMM from 2019-01-01\n",
      "Company MMM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MMM. Total for this company: 1000\n",
      "Company MMM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MMM. Total for this company: 2000\n",
      "Company MMM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 654 news items for MMM. Total for this company: 2654\n",
      "Reached the end of available news for MMM at offset 2000.\n",
      "Saved 2654 news items for MMM to sp500_news_data/MMM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 201/503: NWS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NWS from 2019-01-01\n",
      "Company NWS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NWS. Total for this company: 1000\n",
      "Company NWS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 69 news items for NWS. Total for this company: 1069\n",
      "Reached the end of available news for NWS at offset 1000.\n",
      "Saved 1069 news items for NWS to sp500_news_data/NWS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 202/503: KMX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KMX from 2019-01-01\n",
      "Company KMX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KMX. Total for this company: 1000\n",
      "Company KMX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 199 news items for KMX. Total for this company: 1199\n",
      "Reached the end of available news for KMX at offset 1000.\n",
      "Saved 1199 news items for KMX to sp500_news_data/KMX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 203/503: AWK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AWK from 2019-01-01\n",
      "Company AWK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AWK. Total for this company: 1000\n",
      "Company AWK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 666 news items for AWK. Total for this company: 1666\n",
      "Reached the end of available news for AWK at offset 1000.\n",
      "Saved 1666 news items for AWK to sp500_news_data/AWK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 204/503: DFS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DFS from 2019-01-01\n",
      "Company DFS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DFS. Total for this company: 1000\n",
      "Company DFS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 109 news items for DFS. Total for this company: 1109\n",
      "Reached the end of available news for DFS at offset 1000.\n",
      "Saved 1109 news items for DFS to sp500_news_data/DFS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 205/503: ALGN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ALGN from 2019-01-01\n",
      "Company ALGN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ALGN. Total for this company: 1000\n",
      "Company ALGN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 279 news items for ALGN. Total for this company: 1279\n",
      "Reached the end of available news for ALGN at offset 1000.\n",
      "Saved 1279 news items for ALGN to sp500_news_data/ALGN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 206/503: NVDA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NVDA from 2019-01-01\n",
      "Company NVDA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 1000\n",
      "Company NVDA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 2000\n",
      "Company NVDA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 3000\n",
      "Company NVDA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 4000\n",
      "Company NVDA - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 5000\n",
      "Company NVDA - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 6000\n",
      "Company NVDA - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 7000\n",
      "Company NVDA - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 8000\n",
      "Company NVDA - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 9000\n",
      "Company NVDA - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 10000\n",
      "Company NVDA - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 11000\n",
      "Company NVDA - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 12000\n",
      "Company NVDA - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 13000\n",
      "Company NVDA - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 14000\n",
      "Company NVDA - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 15000\n",
      "Company NVDA - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 16000\n",
      "Company NVDA - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 17000\n",
      "Company NVDA - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 18000\n",
      "Company NVDA - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 19000\n",
      "Company NVDA - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 20000\n",
      "Company NVDA - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 21000\n",
      "Company NVDA - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 22000\n",
      "Company NVDA - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 23000\n",
      "Company NVDA - Batch 24/25: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 24000\n",
      "Company NVDA - Batch 25/25: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for NVDA. Total for this company: 25000\n",
      "Saved 25000 news items for NVDA to sp500_news_data/NVDA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 207/503: LYB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LYB from 2019-01-01\n",
      "Company LYB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 932 news items for LYB. Total for this company: 932\n",
      "Reached the end of available news for LYB at offset 0.\n",
      "Saved 932 news items for LYB to sp500_news_data/LYB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 208/503: EBAY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EBAY from 2019-01-01\n",
      "Company EBAY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EBAY. Total for this company: 1000\n",
      "Company EBAY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 928 news items for EBAY. Total for this company: 1928\n",
      "Reached the end of available news for EBAY at offset 1000.\n",
      "Saved 1928 news items for EBAY to sp500_news_data/EBAY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 209/503: COO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for COO from 2019-01-01\n",
      "Company COO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 688 news items for COO. Total for this company: 688\n",
      "Reached the end of available news for COO at offset 0.\n",
      "Saved 688 news items for COO to sp500_news_data/COO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 210/503: XOM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for XOM from 2019-01-01\n",
      "Company XOM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 1000\n",
      "Company XOM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 2000\n",
      "Company XOM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 3000\n",
      "Company XOM - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 4000\n",
      "Company XOM - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 5000\n",
      "Company XOM - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 6000\n",
      "Company XOM - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 7000\n",
      "Company XOM - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for XOM. Total for this company: 8000\n",
      "Company XOM - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 431 news items for XOM. Total for this company: 8431\n",
      "Reached the end of available news for XOM at offset 8000.\n",
      "Saved 8431 news items for XOM to sp500_news_data/XOM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 211/503: FOX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FOX from 2019-01-01\n",
      "Company FOX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FOX. Total for this company: 1000\n",
      "Company FOX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 671 news items for FOX. Total for this company: 1671\n",
      "Reached the end of available news for FOX at offset 1000.\n",
      "Saved 1671 news items for FOX to sp500_news_data/FOX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 212/503: UAL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UAL from 2019-01-01\n",
      "Company UAL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for UAL. Total for this company: 1000\n",
      "Company UAL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for UAL. Total for this company: 2000\n",
      "Company UAL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for UAL. Total for this company: 3000\n",
      "Company UAL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for UAL. Total for this company: 4000\n",
      "Company UAL - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 493 news items for UAL. Total for this company: 4493\n",
      "Reached the end of available news for UAL at offset 4000.\n",
      "Saved 4493 news items for UAL to sp500_news_data/UAL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 213/503: DG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DG from 2019-01-01\n",
      "Company DG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DG. Total for this company: 1000\n",
      "Company DG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DG. Total for this company: 2000\n",
      "Company DG - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 303 news items for DG. Total for this company: 2303\n",
      "Reached the end of available news for DG at offset 2000.\n",
      "Saved 2303 news items for DG to sp500_news_data/DG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 214/503: ETN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ETN from 2019-01-01\n",
      "Company ETN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 964 news items for ETN. Total for this company: 964\n",
      "Reached the end of available news for ETN at offset 0.\n",
      "Saved 964 news items for ETN to sp500_news_data/ETN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 215/503: ULTA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ULTA from 2019-01-01\n",
      "Company ULTA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ULTA. Total for this company: 1000\n",
      "Company ULTA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 888 news items for ULTA. Total for this company: 1888\n",
      "Reached the end of available news for ULTA at offset 1000.\n",
      "Saved 1888 news items for ULTA to sp500_news_data/ULTA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 216/503: MPWR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MPWR from 2019-01-01\n",
      "Company MPWR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 942 news items for MPWR. Total for this company: 942\n",
      "Reached the end of available news for MPWR at offset 0.\n",
      "Saved 942 news items for MPWR to sp500_news_data/MPWR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 217/503: TSLA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TSLA from 2019-01-01\n",
      "Company TSLA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 1000\n",
      "Company TSLA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 2000\n",
      "Company TSLA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 3000\n",
      "Company TSLA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 4000\n",
      "Company TSLA - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 5000\n",
      "Company TSLA - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 6000\n",
      "Company TSLA - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 7000\n",
      "Company TSLA - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 8000\n",
      "Company TSLA - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 9000\n",
      "Company TSLA - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 10000\n",
      "Company TSLA - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 11000\n",
      "Company TSLA - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 12000\n",
      "Company TSLA - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 13000\n",
      "Company TSLA - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 14000\n",
      "Company TSLA - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 15000\n",
      "Company TSLA - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 16000\n",
      "Company TSLA - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 17000\n",
      "Company TSLA - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 18000\n",
      "Company TSLA - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 19000\n",
      "Company TSLA - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 20000\n",
      "Company TSLA - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 21000\n",
      "Company TSLA - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 22000\n",
      "Company TSLA - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 23000\n",
      "Company TSLA - Batch 24/25: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 24000\n",
      "Company TSLA - Batch 25/25: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for TSLA. Total for this company: 25000\n",
      "Saved 25000 news items for TSLA to sp500_news_data/TSLA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 218/503: TER\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TER from 2019-01-01\n",
      "Company TER - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 968 news items for TER. Total for this company: 968\n",
      "Reached the end of available news for TER at offset 0.\n",
      "Saved 968 news items for TER to sp500_news_data/TER_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 219/503: LOW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LOW from 2019-01-01\n",
      "Company LOW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LOW. Total for this company: 1000\n",
      "Company LOW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for LOW. Total for this company: 2000\n",
      "Company LOW - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for LOW. Total for this company: 3000\n",
      "Company LOW - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 230 news items for LOW. Total for this company: 3230\n",
      "Reached the end of available news for LOW at offset 3000.\n",
      "Saved 3230 news items for LOW to sp500_news_data/LOW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 220/503: PAYC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PAYC from 2019-01-01\n",
      "Company PAYC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 889 news items for PAYC. Total for this company: 889\n",
      "Reached the end of available news for PAYC at offset 0.\n",
      "Saved 889 news items for PAYC to sp500_news_data/PAYC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 221/503: ADM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ADM from 2019-01-01\n",
      "Company ADM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ADM. Total for this company: 1000\n",
      "Company ADM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 765 news items for ADM. Total for this company: 1765\n",
      "Reached the end of available news for ADM at offset 1000.\n",
      "Saved 1765 news items for ADM to sp500_news_data/ADM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 222/503: NTRS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NTRS from 2019-01-01\n",
      "Company NTRS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 933 news items for NTRS. Total for this company: 933\n",
      "Reached the end of available news for NTRS at offset 0.\n",
      "Saved 933 news items for NTRS to sp500_news_data/NTRS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 223/503: EMR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EMR from 2019-01-01\n",
      "Company EMR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EMR. Total for this company: 1000\n",
      "Company EMR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 475 news items for EMR. Total for this company: 1475\n",
      "Reached the end of available news for EMR at offset 1000.\n",
      "Saved 1475 news items for EMR to sp500_news_data/EMR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 224/503: AMZN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMZN from 2019-01-01\n",
      "Company AMZN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 1000\n",
      "Company AMZN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 2000\n",
      "Company AMZN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 3000\n",
      "Company AMZN - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 4000\n",
      "Company AMZN - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 5000\n",
      "Company AMZN - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 6000\n",
      "Company AMZN - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 7000\n",
      "Company AMZN - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 8000\n",
      "Company AMZN - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 9000\n",
      "Company AMZN - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 10000\n",
      "Company AMZN - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 11000\n",
      "Company AMZN - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 12000\n",
      "Company AMZN - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 13000\n",
      "Company AMZN - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 14000\n",
      "Company AMZN - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 15000\n",
      "Company AMZN - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 16000\n",
      "Company AMZN - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 17000\n",
      "Company AMZN - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 18000\n",
      "Company AMZN - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 19000\n",
      "Company AMZN - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 20000\n",
      "Company AMZN - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 21000\n",
      "Company AMZN - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 22000\n",
      "Company AMZN - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 23000\n",
      "Company AMZN - Batch 24/25: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 24000\n",
      "Company AMZN - Batch 25/25: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for AMZN. Total for this company: 25000\n",
      "Saved 25000 news items for AMZN to sp500_news_data/AMZN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 225/503: ADSK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ADSK from 2019-01-01\n",
      "Company ADSK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ADSK. Total for this company: 1000\n",
      "Company ADSK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 202 news items for ADSK. Total for this company: 1202\n",
      "Reached the end of available news for ADSK at offset 1000.\n",
      "Saved 1202 news items for ADSK to sp500_news_data/ADSK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 226/503: KIM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KIM from 2019-01-01\n",
      "Company KIM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 731 news items for KIM. Total for this company: 731\n",
      "Reached the end of available news for KIM at offset 0.\n",
      "Saved 731 news items for KIM to sp500_news_data/KIM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 227/503: CAT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CAT from 2019-01-01\n",
      "Company CAT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CAT. Total for this company: 1000\n",
      "Company CAT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CAT. Total for this company: 2000\n",
      "Company CAT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CAT. Total for this company: 3000\n",
      "Company CAT - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 21 news items for CAT. Total for this company: 3021\n",
      "Reached the end of available news for CAT at offset 3000.\n",
      "Saved 3021 news items for CAT to sp500_news_data/CAT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 228/503: PM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PM from 2019-01-01\n",
      "Company PM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PM. Total for this company: 1000\n",
      "Company PM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PM. Total for this company: 2000\n",
      "Company PM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 218 news items for PM. Total for this company: 2218\n",
      "Reached the end of available news for PM at offset 2000.\n",
      "Saved 2218 news items for PM to sp500_news_data/PM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 229/503: PNC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PNC from 2019-01-01\n",
      "Company PNC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PNC. Total for this company: 1000\n",
      "Company PNC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 779 news items for PNC. Total for this company: 1779\n",
      "Reached the end of available news for PNC at offset 1000.\n",
      "Saved 1779 news items for PNC to sp500_news_data/PNC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 230/503: JNJ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JNJ from 2019-01-01\n",
      "Company JNJ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 1000\n",
      "Company JNJ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 2000\n",
      "Company JNJ - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 3000\n",
      "Company JNJ - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 4000\n",
      "Company JNJ - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 5000\n",
      "Company JNJ - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 6000\n",
      "Company JNJ - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 7000\n",
      "Company JNJ - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for JNJ. Total for this company: 8000\n",
      "Company JNJ - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 146 news items for JNJ. Total for this company: 8146\n",
      "Reached the end of available news for JNJ at offset 8000.\n",
      "Saved 8146 news items for JNJ to sp500_news_data/JNJ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 231/503: EXPD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EXPD from 2019-01-01\n",
      "Company EXPD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 564 news items for EXPD. Total for this company: 564\n",
      "Reached the end of available news for EXPD at offset 0.\n",
      "Saved 564 news items for EXPD to sp500_news_data/EXPD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 232/503: TECH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TECH from 2019-01-01\n",
      "Company TECH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 872 news items for TECH. Total for this company: 872\n",
      "Reached the end of available news for TECH at offset 0.\n",
      "Saved 872 news items for TECH to sp500_news_data/TECH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 233/503: C\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for C from 2019-01-01\n",
      "Company C - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for C. Total for this company: 1000\n",
      "Company C - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for C. Total for this company: 2000\n",
      "Company C - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for C. Total for this company: 3000\n",
      "Company C - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for C. Total for this company: 4000\n",
      "Company C - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for C. Total for this company: 5000\n",
      "Company C - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 647 news items for C. Total for this company: 5647\n",
      "Reached the end of available news for C at offset 5000.\n",
      "Saved 5647 news items for C to sp500_news_data/C_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 234/503: MDLZ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MDLZ from 2019-01-01\n",
      "Company MDLZ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MDLZ. Total for this company: 1000\n",
      "Company MDLZ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 864 news items for MDLZ. Total for this company: 1864\n",
      "Reached the end of available news for MDLZ at offset 1000.\n",
      "Saved 1864 news items for MDLZ to sp500_news_data/MDLZ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 235/503: TAP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TAP from 2019-01-01\n",
      "Company TAP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TAP. Total for this company: 1000\n",
      "Company TAP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 272 news items for TAP. Total for this company: 1272\n",
      "Reached the end of available news for TAP at offset 1000.\n",
      "Saved 1272 news items for TAP to sp500_news_data/TAP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 236/503: AXP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AXP from 2019-01-01\n",
      "Company AXP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AXP. Total for this company: 1000\n",
      "Company AXP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AXP. Total for this company: 2000\n",
      "Company AXP - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AXP. Total for this company: 3000\n",
      "Company AXP - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 725 news items for AXP. Total for this company: 3725\n",
      "Reached the end of available news for AXP at offset 3000.\n",
      "Saved 3725 news items for AXP to sp500_news_data/AXP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 237/503: ALB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ALB from 2019-01-01\n",
      "Company ALB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ALB. Total for this company: 1000\n",
      "Company ALB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ALB. Total for this company: 2000\n",
      "Company ALB - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 322 news items for ALB. Total for this company: 2322\n",
      "Reached the end of available news for ALB at offset 2000.\n",
      "Saved 2322 news items for ALB to sp500_news_data/ALB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 238/503: AVB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AVB from 2019-01-01\n",
      "Company AVB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 617 news items for AVB. Total for this company: 617\n",
      "Reached the end of available news for AVB at offset 0.\n",
      "Saved 617 news items for AVB to sp500_news_data/AVB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 239/503: MDT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MDT from 2019-01-01\n",
      "Company MDT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MDT. Total for this company: 1000\n",
      "Company MDT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MDT. Total for this company: 2000\n",
      "Company MDT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 474 news items for MDT. Total for this company: 2474\n",
      "Reached the end of available news for MDT at offset 2000.\n",
      "Saved 2474 news items for MDT to sp500_news_data/MDT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 240/503: MHK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MHK from 2019-01-01\n",
      "Company MHK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 791 news items for MHK. Total for this company: 791\n",
      "Reached the end of available news for MHK at offset 0.\n",
      "Saved 791 news items for MHK to sp500_news_data/MHK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 241/503: EA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EA from 2019-01-01\n",
      "Company EA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EA. Total for this company: 1000\n",
      "Company EA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 600 news items for EA. Total for this company: 1600\n",
      "Reached the end of available news for EA at offset 1000.\n",
      "Saved 1600 news items for EA to sp500_news_data/EA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 242/503: NDSN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NDSN from 2019-01-01\n",
      "Company NDSN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 642 news items for NDSN. Total for this company: 642\n",
      "Reached the end of available news for NDSN at offset 0.\n",
      "Saved 642 news items for NDSN to sp500_news_data/NDSN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 243/503: PTC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PTC from 2019-01-01\n",
      "Company PTC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 651 news items for PTC. Total for this company: 651\n",
      "Reached the end of available news for PTC at offset 0.\n",
      "Saved 651 news items for PTC to sp500_news_data/PTC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 244/503: EFX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EFX from 2019-01-01\n",
      "Company EFX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EFX. Total for this company: 1000\n",
      "Company EFX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 172 news items for EFX. Total for this company: 1172\n",
      "Reached the end of available news for EFX at offset 1000.\n",
      "Saved 1172 news items for EFX to sp500_news_data/EFX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 245/503: ADBE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ADBE from 2019-01-01\n",
      "Company ADBE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ADBE. Total for this company: 1000\n",
      "Company ADBE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ADBE. Total for this company: 2000\n",
      "Company ADBE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for ADBE. Total for this company: 3000\n",
      "Company ADBE - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for ADBE. Total for this company: 4000\n",
      "Company ADBE - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 235 news items for ADBE. Total for this company: 4235\n",
      "Reached the end of available news for ADBE at offset 4000.\n",
      "Saved 4235 news items for ADBE to sp500_news_data/ADBE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 246/503: SCHW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SCHW from 2019-01-01\n",
      "Company SCHW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SCHW. Total for this company: 1000\n",
      "Company SCHW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for SCHW. Total for this company: 2000\n",
      "Company SCHW - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for SCHW. Total for this company: 3000\n",
      "Company SCHW - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 124 news items for SCHW. Total for this company: 3124\n",
      "Reached the end of available news for SCHW at offset 3000.\n",
      "Saved 3124 news items for SCHW to sp500_news_data/SCHW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 247/503: RSG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RSG from 2019-01-01\n",
      "Company RSG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 747 news items for RSG. Total for this company: 747\n",
      "Reached the end of available news for RSG at offset 0.\n",
      "Saved 747 news items for RSG to sp500_news_data/RSG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 248/503: PWR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PWR from 2019-01-01\n",
      "Company PWR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 741 news items for PWR. Total for this company: 741\n",
      "Reached the end of available news for PWR at offset 0.\n",
      "Saved 741 news items for PWR to sp500_news_data/PWR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 249/503: MRK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MRK from 2019-01-01\n",
      "Company MRK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MRK. Total for this company: 1000\n",
      "Company MRK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MRK. Total for this company: 2000\n",
      "Company MRK - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MRK. Total for this company: 3000\n",
      "Company MRK - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MRK. Total for this company: 4000\n",
      "Company MRK - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 345 news items for MRK. Total for this company: 4345\n",
      "Reached the end of available news for MRK at offset 4000.\n",
      "Saved 4345 news items for MRK to sp500_news_data/MRK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 250/503: VRSK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VRSK from 2019-01-01\n",
      "Company VRSK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for VRSK. Total for this company: 1000\n",
      "Company VRSK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 185 news items for VRSK. Total for this company: 1185\n",
      "Reached the end of available news for VRSK at offset 1000.\n",
      "Saved 1185 news items for VRSK to sp500_news_data/VRSK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 251/503: NWSA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NWSA from 2019-01-01\n",
      "Company NWSA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NWSA. Total for this company: 1000\n",
      "Company NWSA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 159 news items for NWSA. Total for this company: 1159\n",
      "Reached the end of available news for NWSA at offset 1000.\n",
      "Saved 1159 news items for NWSA to sp500_news_data/NWSA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 252/503: MSFT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MSFT from 2019-01-01\n",
      "Company MSFT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 1000\n",
      "Company MSFT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 2000\n",
      "Company MSFT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 3000\n",
      "Company MSFT - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 4000\n",
      "Company MSFT - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 5000\n",
      "Company MSFT - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 6000\n",
      "Company MSFT - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 7000\n",
      "Company MSFT - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 8000\n",
      "Company MSFT - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 9000\n",
      "Company MSFT - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 10000\n",
      "Company MSFT - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 11000\n",
      "Company MSFT - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 12000\n",
      "Company MSFT - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 13000\n",
      "Company MSFT - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 14000\n",
      "Company MSFT - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 15000\n",
      "Company MSFT - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 16000\n",
      "Company MSFT - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 17000\n",
      "Company MSFT - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 18000\n",
      "Company MSFT - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 19000\n",
      "Company MSFT - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 20000\n",
      "Company MSFT - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 21000\n",
      "Company MSFT - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 22000\n",
      "Company MSFT - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 23000\n",
      "Company MSFT - Batch 24/25: Fetching news with offset 23000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 24000\n",
      "Company MSFT - Batch 25/25: Fetching news with offset 24000...\n",
      "Retrieved 1000 news items for MSFT. Total for this company: 25000\n",
      "Saved 25000 news items for MSFT to sp500_news_data/MSFT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 253/503: TSN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TSN from 2019-01-01\n",
      "Company TSN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TSN. Total for this company: 1000\n",
      "Company TSN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for TSN. Total for this company: 2000\n",
      "Company TSN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 330 news items for TSN. Total for this company: 2330\n",
      "Reached the end of available news for TSN at offset 2000.\n",
      "Saved 2330 news items for TSN to sp500_news_data/TSN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 254/503: EQT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EQT from 2019-01-01\n",
      "Company EQT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EQT. Total for this company: 1000\n",
      "Company EQT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 17 news items for EQT. Total for this company: 1017\n",
      "Reached the end of available news for EQT at offset 1000.\n",
      "Saved 1017 news items for EQT to sp500_news_data/EQT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 255/503: BSX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BSX from 2019-01-01\n",
      "Company BSX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BSX. Total for this company: 1000\n",
      "Company BSX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 801 news items for BSX. Total for this company: 1801\n",
      "Reached the end of available news for BSX at offset 1000.\n",
      "Saved 1801 news items for BSX to sp500_news_data/BSX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 256/503: LKQ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LKQ from 2019-01-01\n",
      "Company LKQ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 648 news items for LKQ. Total for this company: 648\n",
      "Reached the end of available news for LKQ at offset 0.\n",
      "Saved 648 news items for LKQ to sp500_news_data/LKQ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 257/503: IEX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IEX from 2019-01-01\n",
      "Company IEX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 541 news items for IEX. Total for this company: 541\n",
      "Reached the end of available news for IEX at offset 0.\n",
      "Saved 541 news items for IEX to sp500_news_data/IEX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 258/503: DE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DE from 2019-01-01\n",
      "Company DE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DE. Total for this company: 1000\n",
      "Company DE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DE. Total for this company: 2000\n",
      "Company DE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 894 news items for DE. Total for this company: 2894\n",
      "Reached the end of available news for DE at offset 2000.\n",
      "Saved 2894 news items for DE to sp500_news_data/DE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 259/503: TRGP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TRGP from 2019-01-01\n",
      "Company TRGP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 750 news items for TRGP. Total for this company: 750\n",
      "Reached the end of available news for TRGP at offset 0.\n",
      "Saved 750 news items for TRGP to sp500_news_data/TRGP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 260/503: ROK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ROK from 2019-01-01\n",
      "Company ROK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ROK. Total for this company: 1000\n",
      "Company ROK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 153 news items for ROK. Total for this company: 1153\n",
      "Reached the end of available news for ROK at offset 1000.\n",
      "Saved 1153 news items for ROK to sp500_news_data/ROK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 261/503: NOC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NOC from 2019-01-01\n",
      "Company NOC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NOC. Total for this company: 1000\n",
      "Company NOC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NOC. Total for this company: 2000\n",
      "Company NOC - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 327 news items for NOC. Total for this company: 2327\n",
      "Reached the end of available news for NOC at offset 2000.\n",
      "Saved 2327 news items for NOC to sp500_news_data/NOC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 262/503: PFG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PFG from 2019-01-01\n",
      "Company PFG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 670 news items for PFG. Total for this company: 670\n",
      "Reached the end of available news for PFG at offset 0.\n",
      "Saved 670 news items for PFG to sp500_news_data/PFG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 263/503: WDC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WDC from 2019-01-01\n",
      "Company WDC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WDC. Total for this company: 1000\n",
      "Company WDC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 161 news items for WDC. Total for this company: 1161\n",
      "Reached the end of available news for WDC at offset 1000.\n",
      "Saved 1161 news items for WDC to sp500_news_data/WDC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 264/503: IDXX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IDXX from 2019-01-01\n",
      "Company IDXX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 823 news items for IDXX. Total for this company: 823\n",
      "Reached the end of available news for IDXX at offset 0.\n",
      "Saved 823 news items for IDXX to sp500_news_data/IDXX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 265/503: AKAM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AKAM from 2019-01-01\n",
      "Company AKAM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 868 news items for AKAM. Total for this company: 868\n",
      "Reached the end of available news for AKAM at offset 0.\n",
      "Saved 868 news items for AKAM to sp500_news_data/AKAM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 266/503: NXPI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NXPI from 2019-01-01\n",
      "Company NXPI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NXPI. Total for this company: 1000\n",
      "Company NXPI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 453 news items for NXPI. Total for this company: 1453\n",
      "Reached the end of available news for NXPI at offset 1000.\n",
      "Saved 1453 news items for NXPI to sp500_news_data/NXPI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 267/503: WFC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WFC from 2019-01-01\n",
      "Company WFC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WFC. Total for this company: 1000\n",
      "Company WFC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for WFC. Total for this company: 2000\n",
      "Company WFC - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for WFC. Total for this company: 3000\n",
      "Company WFC - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for WFC. Total for this company: 4000\n",
      "Company WFC - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 399 news items for WFC. Total for this company: 4399\n",
      "Reached the end of available news for WFC at offset 4000.\n",
      "Saved 4399 news items for WFC to sp500_news_data/WFC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 268/503: JNPR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JNPR from 2019-01-01\n",
      "Company JNPR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for JNPR. Total for this company: 1000\n",
      "Company JNPR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 104 news items for JNPR. Total for this company: 1104\n",
      "Reached the end of available news for JNPR at offset 1000.\n",
      "Saved 1104 news items for JNPR to sp500_news_data/JNPR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 269/503: CCL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CCL from 2019-01-01\n",
      "Company CCL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CCL. Total for this company: 1000\n",
      "Company CCL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CCL. Total for this company: 2000\n",
      "Company CCL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CCL. Total for this company: 3000\n",
      "Company CCL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 95 news items for CCL. Total for this company: 3095\n",
      "Reached the end of available news for CCL at offset 3000.\n",
      "Saved 3095 news items for CCL to sp500_news_data/CCL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 270/503: AZO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AZO from 2019-01-01\n",
      "Company AZO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AZO. Total for this company: 1000\n",
      "Company AZO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 293 news items for AZO. Total for this company: 1293\n",
      "Reached the end of available news for AZO at offset 1000.\n",
      "Saved 1293 news items for AZO to sp500_news_data/AZO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 271/503: HLT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HLT from 2019-01-01\n",
      "Company HLT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HLT. Total for this company: 1000\n",
      "Company HLT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 327 news items for HLT. Total for this company: 1327\n",
      "Reached the end of available news for HLT at offset 1000.\n",
      "Saved 1327 news items for HLT to sp500_news_data/HLT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 272/503: SBAC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SBAC from 2019-01-01\n",
      "Company SBAC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 461 news items for SBAC. Total for this company: 461\n",
      "Reached the end of available news for SBAC at offset 0.\n",
      "Saved 461 news items for SBAC to sp500_news_data/SBAC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 273/503: GOOG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GOOG from 2019-01-01\n",
      "Company GOOG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 1000\n",
      "Company GOOG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 2000\n",
      "Company GOOG - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 3000\n",
      "Company GOOG - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 4000\n",
      "Company GOOG - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 5000\n",
      "Company GOOG - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 6000\n",
      "Company GOOG - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 7000\n",
      "Company GOOG - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 8000\n",
      "Company GOOG - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 9000\n",
      "Company GOOG - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 10000\n",
      "Company GOOG - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 11000\n",
      "Company GOOG - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 12000\n",
      "Company GOOG - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 13000\n",
      "Company GOOG - Batch 14/25: Fetching news with offset 13000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 14000\n",
      "Company GOOG - Batch 15/25: Fetching news with offset 14000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 15000\n",
      "Company GOOG - Batch 16/25: Fetching news with offset 15000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 16000\n",
      "Company GOOG - Batch 17/25: Fetching news with offset 16000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 17000\n",
      "Company GOOG - Batch 18/25: Fetching news with offset 17000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 18000\n",
      "Company GOOG - Batch 19/25: Fetching news with offset 18000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 19000\n",
      "Company GOOG - Batch 20/25: Fetching news with offset 19000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 20000\n",
      "Company GOOG - Batch 21/25: Fetching news with offset 20000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 21000\n",
      "Company GOOG - Batch 22/25: Fetching news with offset 21000...\n",
      "Retrieved 1000 news items for GOOG. Total for this company: 22000\n",
      "Company GOOG - Batch 23/25: Fetching news with offset 22000...\n",
      "Retrieved 164 news items for GOOG. Total for this company: 22164\n",
      "Reached the end of available news for GOOG at offset 22000.\n",
      "Saved 22164 news items for GOOG to sp500_news_data/GOOG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 274/503: FOXA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FOXA from 2019-01-01\n",
      "Company FOXA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FOXA. Total for this company: 1000\n",
      "Company FOXA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 676 news items for FOXA. Total for this company: 1676\n",
      "Reached the end of available news for FOXA at offset 1000.\n",
      "Saved 1676 news items for FOXA to sp500_news_data/FOXA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 275/503: ECL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ECL from 2019-01-01\n",
      "Company ECL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ECL. Total for this company: 1000\n",
      "Company ECL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 63 news items for ECL. Total for this company: 1063\n",
      "Reached the end of available news for ECL at offset 1000.\n",
      "Saved 1063 news items for ECL to sp500_news_data/ECL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 276/503: HST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HST from 2019-01-01\n",
      "Company HST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 608 news items for HST. Total for this company: 608\n",
      "Reached the end of available news for HST at offset 0.\n",
      "Saved 608 news items for HST to sp500_news_data/HST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 277/503: CRL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CRL from 2019-01-01\n",
      "Company CRL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 787 news items for CRL. Total for this company: 787\n",
      "Reached the end of available news for CRL at offset 0.\n",
      "Saved 787 news items for CRL to sp500_news_data/CRL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 278/503: IBM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IBM from 2019-01-01\n",
      "Company IBM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for IBM. Total for this company: 1000\n",
      "Company IBM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for IBM. Total for this company: 2000\n",
      "Company IBM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for IBM. Total for this company: 3000\n",
      "Company IBM - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for IBM. Total for this company: 4000\n",
      "Company IBM - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 976 news items for IBM. Total for this company: 4976\n",
      "Reached the end of available news for IBM at offset 4000.\n",
      "Saved 4976 news items for IBM to sp500_news_data/IBM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 279/503: ISRG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ISRG from 2019-01-01\n",
      "Company ISRG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ISRG. Total for this company: 1000\n",
      "Company ISRG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 960 news items for ISRG. Total for this company: 1960\n",
      "Reached the end of available news for ISRG at offset 1000.\n",
      "Saved 1960 news items for ISRG to sp500_news_data/ISRG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 280/503: CPRT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CPRT from 2019-01-01\n",
      "Company CPRT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 638 news items for CPRT. Total for this company: 638\n",
      "Reached the end of available news for CPRT at offset 0.\n",
      "Saved 638 news items for CPRT to sp500_news_data/CPRT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 281/503: DLR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DLR from 2019-01-01\n",
      "Company DLR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 982 news items for DLR. Total for this company: 982\n",
      "Reached the end of available news for DLR at offset 0.\n",
      "Saved 982 news items for DLR to sp500_news_data/DLR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 282/503: TDG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TDG from 2019-01-01\n",
      "Company TDG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 703 news items for TDG. Total for this company: 703\n",
      "Reached the end of available news for TDG at offset 0.\n",
      "Saved 703 news items for TDG to sp500_news_data/TDG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 283/503: AES\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AES from 2019-01-01\n",
      "Company AES - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 727 news items for AES. Total for this company: 727\n",
      "Reached the end of available news for AES at offset 0.\n",
      "Saved 727 news items for AES to sp500_news_data/AES_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 284/503: ED\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ED from 2019-01-01\n",
      "Company ED - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 812 news items for ED. Total for this company: 812\n",
      "Reached the end of available news for ED at offset 0.\n",
      "Saved 812 news items for ED to sp500_news_data/ED_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 285/503: ETR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ETR from 2019-01-01\n",
      "Company ETR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 972 news items for ETR. Total for this company: 972\n",
      "Reached the end of available news for ETR at offset 0.\n",
      "Saved 972 news items for ETR to sp500_news_data/ETR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 286/503: L\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for L from 2019-01-01\n",
      "Company L - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 286 news items for L. Total for this company: 286\n",
      "Reached the end of available news for L at offset 0.\n",
      "Saved 286 news items for L to sp500_news_data/L_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 287/503: HAL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HAL from 2019-01-01\n",
      "Company HAL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HAL. Total for this company: 1000\n",
      "Company HAL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 937 news items for HAL. Total for this company: 1937\n",
      "Reached the end of available news for HAL at offset 1000.\n",
      "Saved 1937 news items for HAL to sp500_news_data/HAL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 288/503: MCK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MCK from 2019-01-01\n",
      "Company MCK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MCK. Total for this company: 1000\n",
      "Company MCK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 917 news items for MCK. Total for this company: 1917\n",
      "Reached the end of available news for MCK at offset 1000.\n",
      "Saved 1917 news items for MCK to sp500_news_data/MCK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 289/503: BG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BG from 2019-01-01\n",
      "Company BG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 997 news items for BG. Total for this company: 997\n",
      "Reached the end of available news for BG at offset 0.\n",
      "Saved 997 news items for BG to sp500_news_data/BG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 290/503: BAX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BAX from 2019-01-01\n",
      "Company BAX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BAX. Total for this company: 1000\n",
      "Company BAX - Batch 2/25: Fetching news with offset 1000...\n",
      "No more news items found for BAX after offset 1000.\n",
      "Saved 1000 news items for BAX to sp500_news_data/BAX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 291/503: GRMN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GRMN from 2019-01-01\n",
      "Company GRMN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 830 news items for GRMN. Total for this company: 830\n",
      "Reached the end of available news for GRMN at offset 0.\n",
      "Saved 830 news items for GRMN to sp500_news_data/GRMN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 292/503: TROW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TROW from 2019-01-01\n",
      "Company TROW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TROW. Total for this company: 1000\n",
      "Company TROW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 196 news items for TROW. Total for this company: 1196\n",
      "Reached the end of available news for TROW at offset 1000.\n",
      "Saved 1196 news items for TROW to sp500_news_data/TROW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 293/503: HSY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HSY from 2019-01-01\n",
      "Company HSY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HSY. Total for this company: 1000\n",
      "Company HSY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 389 news items for HSY. Total for this company: 1389\n",
      "Reached the end of available news for HSY at offset 1000.\n",
      "Saved 1389 news items for HSY to sp500_news_data/HSY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 294/503: DHI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DHI from 2019-01-01\n",
      "Company DHI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DHI. Total for this company: 1000\n",
      "Company DHI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 767 news items for DHI. Total for this company: 1767\n",
      "Reached the end of available news for DHI at offset 1000.\n",
      "Saved 1767 news items for DHI to sp500_news_data/DHI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 295/503: BLK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BLK from 2019-01-01\n",
      "Company BLK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BLK. Total for this company: 1000\n",
      "Company BLK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BLK. Total for this company: 2000\n",
      "Company BLK - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for BLK. Total for this company: 3000\n",
      "Company BLK - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for BLK. Total for this company: 4000\n",
      "Company BLK - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for BLK. Total for this company: 5000\n",
      "Company BLK - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 921 news items for BLK. Total for this company: 5921\n",
      "Reached the end of available news for BLK at offset 5000.\n",
      "Saved 5921 news items for BLK to sp500_news_data/BLK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 296/503: F\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for F from 2019-01-01\n",
      "Company F - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for F. Total for this company: 1000\n",
      "Company F - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for F. Total for this company: 2000\n",
      "Company F - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for F. Total for this company: 3000\n",
      "Company F - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for F. Total for this company: 4000\n",
      "Company F - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for F. Total for this company: 5000\n",
      "Company F - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for F. Total for this company: 6000\n",
      "Company F - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for F. Total for this company: 7000\n",
      "Company F - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for F. Total for this company: 8000\n",
      "Company F - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for F. Total for this company: 9000\n",
      "Company F - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for F. Total for this company: 10000\n",
      "Company F - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 125 news items for F. Total for this company: 10125\n",
      "Reached the end of available news for F at offset 10000.\n",
      "Saved 10125 news items for F to sp500_news_data/F_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 297/503: DAL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DAL from 2019-01-01\n",
      "Company DAL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DAL. Total for this company: 1000\n",
      "Company DAL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DAL. Total for this company: 2000\n",
      "Company DAL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for DAL. Total for this company: 3000\n",
      "Company DAL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for DAL. Total for this company: 4000\n",
      "Company DAL - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for DAL. Total for this company: 5000\n",
      "Company DAL - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 460 news items for DAL. Total for this company: 5460\n",
      "Reached the end of available news for DAL at offset 5000.\n",
      "Saved 5460 news items for DAL to sp500_news_data/DAL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 298/503: WST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WST from 2019-01-01\n",
      "Company WST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 757 news items for WST. Total for this company: 757\n",
      "Reached the end of available news for WST at offset 0.\n",
      "Saved 757 news items for WST to sp500_news_data/WST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 299/503: LRCX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LRCX from 2019-01-01\n",
      "Company LRCX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LRCX. Total for this company: 1000\n",
      "Company LRCX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 844 news items for LRCX. Total for this company: 1844\n",
      "Reached the end of available news for LRCX at offset 1000.\n",
      "Saved 1844 news items for LRCX to sp500_news_data/LRCX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 300/503: HSIC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HSIC from 2019-01-01\n",
      "Company HSIC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HSIC. Total for this company: 1000\n",
      "Company HSIC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 113 news items for HSIC. Total for this company: 1113\n",
      "Reached the end of available news for HSIC at offset 1000.\n",
      "Saved 1113 news items for HSIC to sp500_news_data/HSIC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 301/503: WYNN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WYNN from 2019-01-01\n",
      "Company WYNN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WYNN. Total for this company: 1000\n",
      "Company WYNN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 265 news items for WYNN. Total for this company: 1265\n",
      "Reached the end of available news for WYNN at offset 1000.\n",
      "Saved 1265 news items for WYNN to sp500_news_data/WYNN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 302/503: ADI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ADI from 2019-01-01\n",
      "Company ADI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ADI. Total for this company: 1000\n",
      "Company ADI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 689 news items for ADI. Total for this company: 1689\n",
      "Reached the end of available news for ADI at offset 1000.\n",
      "Saved 1689 news items for ADI to sp500_news_data/ADI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 303/503: LNT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LNT from 2019-01-01\n",
      "Company LNT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 573 news items for LNT. Total for this company: 573\n",
      "Reached the end of available news for LNT at offset 0.\n",
      "Saved 573 news items for LNT to sp500_news_data/LNT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 304/503: INCY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for INCY from 2019-01-01\n",
      "Company INCY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 879 news items for INCY. Total for this company: 879\n",
      "Reached the end of available news for INCY at offset 0.\n",
      "Saved 879 news items for INCY to sp500_news_data/INCY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 305/503: HBAN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HBAN from 2019-01-01\n",
      "Company HBAN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 727 news items for HBAN. Total for this company: 727\n",
      "Reached the end of available news for HBAN at offset 0.\n",
      "Saved 727 news items for HBAN to sp500_news_data/HBAN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 306/503: META\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for META from 2019-01-01\n",
      "Company META - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for META. Total for this company: 1000\n",
      "Company META - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for META. Total for this company: 2000\n",
      "Company META - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for META. Total for this company: 3000\n",
      "Company META - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for META. Total for this company: 4000\n",
      "Company META - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for META. Total for this company: 5000\n",
      "Company META - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for META. Total for this company: 6000\n",
      "Company META - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for META. Total for this company: 7000\n",
      "Company META - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for META. Total for this company: 8000\n",
      "Company META - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for META. Total for this company: 9000\n",
      "Company META - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 911 news items for META. Total for this company: 9911\n",
      "Reached the end of available news for META at offset 9000.\n",
      "Saved 9911 news items for META to sp500_news_data/META_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 307/503: AMGN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMGN from 2019-01-01\n",
      "Company AMGN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AMGN. Total for this company: 1000\n",
      "Company AMGN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AMGN. Total for this company: 2000\n",
      "Company AMGN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 745 news items for AMGN. Total for this company: 2745\n",
      "Reached the end of available news for AMGN at offset 2000.\n",
      "Saved 2745 news items for AMGN to sp500_news_data/AMGN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 308/503: AIG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AIG from 2019-01-01\n",
      "Company AIG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AIG. Total for this company: 1000\n",
      "Company AIG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 177 news items for AIG. Total for this company: 1177\n",
      "Reached the end of available news for AIG at offset 1000.\n",
      "Saved 1177 news items for AIG to sp500_news_data/AIG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 309/503: NI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NI from 2019-01-01\n",
      "Company NI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 706 news items for NI. Total for this company: 706\n",
      "Reached the end of available news for NI at offset 0.\n",
      "Saved 706 news items for NI to sp500_news_data/NI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 310/503: DVN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DVN from 2019-01-01\n",
      "Company DVN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DVN. Total for this company: 1000\n",
      "Company DVN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DVN. Total for this company: 2000\n",
      "Company DVN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 349 news items for DVN. Total for this company: 2349\n",
      "Reached the end of available news for DVN at offset 2000.\n",
      "Saved 2349 news items for DVN to sp500_news_data/DVN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 311/503: PEP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PEP from 2019-01-01\n",
      "Company PEP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PEP. Total for this company: 1000\n",
      "Company PEP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PEP. Total for this company: 2000\n",
      "Company PEP - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for PEP. Total for this company: 3000\n",
      "Company PEP - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for PEP. Total for this company: 4000\n",
      "Company PEP - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 427 news items for PEP. Total for this company: 4427\n",
      "Reached the end of available news for PEP at offset 4000.\n",
      "Saved 4427 news items for PEP to sp500_news_data/PEP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 312/503: OMC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for OMC from 2019-01-01\n",
      "Company OMC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for OMC. Total for this company: 1000\n",
      "Company OMC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 112 news items for OMC. Total for this company: 1112\n",
      "Reached the end of available news for OMC at offset 1000.\n",
      "Saved 1112 news items for OMC to sp500_news_data/OMC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 313/503: STLD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for STLD from 2019-01-01\n",
      "Company STLD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for STLD. Total for this company: 1000\n",
      "Company STLD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 448 news items for STLD. Total for this company: 1448\n",
      "Reached the end of available news for STLD at offset 1000.\n",
      "Saved 1448 news items for STLD to sp500_news_data/STLD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 314/503: LDOS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LDOS from 2019-01-01\n",
      "Company LDOS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LDOS. Total for this company: 1000\n",
      "Company LDOS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 604 news items for LDOS. Total for this company: 1604\n",
      "Reached the end of available news for LDOS at offset 1000.\n",
      "Saved 1604 news items for LDOS to sp500_news_data/LDOS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 315/503: TMO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TMO from 2019-01-01\n",
      "Company TMO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TMO. Total for this company: 1000\n",
      "Company TMO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 820 news items for TMO. Total for this company: 1820\n",
      "Reached the end of available news for TMO at offset 1000.\n",
      "Saved 1820 news items for TMO to sp500_news_data/TMO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 316/503: GNRC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GNRC from 2019-01-01\n",
      "Company GNRC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GNRC. Total for this company: 1000\n",
      "Company GNRC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 566 news items for GNRC. Total for this company: 1566\n",
      "Reached the end of available news for GNRC at offset 1000.\n",
      "Saved 1566 news items for GNRC to sp500_news_data/GNRC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 317/503: FI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FI from 2019-01-01\n",
      "Company FI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 603 news items for FI. Total for this company: 603\n",
      "Reached the end of available news for FI at offset 0.\n",
      "Saved 603 news items for FI to sp500_news_data/FI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 318/503: MOS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MOS from 2019-01-01\n",
      "Company MOS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MOS. Total for this company: 1000\n",
      "Company MOS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 103 news items for MOS. Total for this company: 1103\n",
      "Reached the end of available news for MOS at offset 1000.\n",
      "Saved 1103 news items for MOS to sp500_news_data/MOS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 319/503: MPC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MPC from 2019-01-01\n",
      "Company MPC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MPC. Total for this company: 1000\n",
      "Company MPC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 772 news items for MPC. Total for this company: 1772\n",
      "Reached the end of available news for MPC at offset 1000.\n",
      "Saved 1772 news items for MPC to sp500_news_data/MPC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 320/503: DIS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DIS from 2019-01-01\n",
      "Company DIS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 1000\n",
      "Company DIS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 2000\n",
      "Company DIS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 3000\n",
      "Company DIS - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 4000\n",
      "Company DIS - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 5000\n",
      "Company DIS - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 6000\n",
      "Company DIS - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 7000\n",
      "Company DIS - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 8000\n",
      "Company DIS - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 9000\n",
      "Company DIS - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 10000\n",
      "Company DIS - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 11000\n",
      "Company DIS - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for DIS. Total for this company: 12000\n",
      "Company DIS - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 636 news items for DIS. Total for this company: 12636\n",
      "Reached the end of available news for DIS at offset 12000.\n",
      "Saved 12636 news items for DIS to sp500_news_data/DIS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 321/503: ATO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ATO from 2019-01-01\n",
      "Company ATO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 873 news items for ATO. Total for this company: 873\n",
      "Reached the end of available news for ATO at offset 0.\n",
      "Saved 873 news items for ATO to sp500_news_data/ATO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 322/503: CMS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CMS from 2019-01-01\n",
      "Company CMS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 677 news items for CMS. Total for this company: 677\n",
      "Reached the end of available news for CMS at offset 0.\n",
      "Saved 677 news items for CMS to sp500_news_data/CMS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 323/503: DD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DD from 2019-01-01\n",
      "Company DD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DD. Total for this company: 1000\n",
      "Company DD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 287 news items for DD. Total for this company: 1287\n",
      "Reached the end of available news for DD at offset 1000.\n",
      "Saved 1287 news items for DD to sp500_news_data/DD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 324/503: ORLY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ORLY from 2019-01-01\n",
      "Company ORLY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 833 news items for ORLY. Total for this company: 833\n",
      "Reached the end of available news for ORLY at offset 0.\n",
      "Saved 833 news items for ORLY to sp500_news_data/ORLY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 325/503: CMCSA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CMCSA from 2019-01-01\n",
      "Company CMCSA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CMCSA. Total for this company: 1000\n",
      "Company CMCSA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CMCSA. Total for this company: 2000\n",
      "Company CMCSA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CMCSA. Total for this company: 3000\n",
      "Company CMCSA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for CMCSA. Total for this company: 4000\n",
      "Company CMCSA - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 72 news items for CMCSA. Total for this company: 4072\n",
      "Reached the end of available news for CMCSA at offset 4000.\n",
      "Saved 4072 news items for CMCSA to sp500_news_data/CMCSA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 326/503: STZ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for STZ from 2019-01-01\n",
      "Company STZ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for STZ. Total for this company: 1000\n",
      "Company STZ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 680 news items for STZ. Total for this company: 1680\n",
      "Reached the end of available news for STZ at offset 1000.\n",
      "Saved 1680 news items for STZ to sp500_news_data/STZ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 327/503: NFLX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NFLX from 2019-01-01\n",
      "Company NFLX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 1000\n",
      "Company NFLX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 2000\n",
      "Company NFLX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 3000\n",
      "Company NFLX - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 4000\n",
      "Company NFLX - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 5000\n",
      "Company NFLX - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 6000\n",
      "Company NFLX - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 7000\n",
      "Company NFLX - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 8000\n",
      "Company NFLX - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 9000\n",
      "Company NFLX - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 10000\n",
      "Company NFLX - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for NFLX. Total for this company: 11000\n",
      "Company NFLX - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 881 news items for NFLX. Total for this company: 11881\n",
      "Reached the end of available news for NFLX at offset 11000.\n",
      "Saved 11881 news items for NFLX to sp500_news_data/NFLX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 328/503: FANG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FANG from 2019-01-01\n",
      "Company FANG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FANG. Total for this company: 1000\n",
      "Company FANG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 952 news items for FANG. Total for this company: 1952\n",
      "Reached the end of available news for FANG at offset 1000.\n",
      "Saved 1952 news items for FANG to sp500_news_data/FANG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 329/503: FTNT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FTNT from 2019-01-01\n",
      "Company FTNT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FTNT. Total for this company: 1000\n",
      "Company FTNT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for FTNT. Total for this company: 2000\n",
      "Company FTNT - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 232 news items for FTNT. Total for this company: 2232\n",
      "Reached the end of available news for FTNT at offset 2000.\n",
      "Saved 2232 news items for FTNT to sp500_news_data/FTNT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 330/503: GM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GM from 2019-01-01\n",
      "Company GM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GM. Total for this company: 1000\n",
      "Company GM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 2000\n",
      "Company GM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 3000\n",
      "Company GM - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 4000\n",
      "Company GM - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 5000\n",
      "Company GM - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 6000\n",
      "Company GM - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 7000\n",
      "Company GM - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for GM. Total for this company: 8000\n",
      "Company GM - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 23 news items for GM. Total for this company: 8023\n",
      "Reached the end of available news for GM at offset 8000.\n",
      "Saved 8023 news items for GM to sp500_news_data/GM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 331/503: V\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for V from 2019-01-01\n",
      "Company V - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for V. Total for this company: 1000\n",
      "Company V - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for V. Total for this company: 2000\n",
      "Company V - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for V. Total for this company: 3000\n",
      "Company V - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for V. Total for this company: 4000\n",
      "Company V - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 675 news items for V. Total for this company: 4675\n",
      "Reached the end of available news for V at offset 4000.\n",
      "Saved 4675 news items for V to sp500_news_data/V_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 332/503: SWK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SWK from 2019-01-01\n",
      "Company SWK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SWK. Total for this company: 1000\n",
      "Company SWK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 236 news items for SWK. Total for this company: 1236\n",
      "Reached the end of available news for SWK at offset 1000.\n",
      "Saved 1236 news items for SWK to sp500_news_data/SWK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 333/503: GE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GE from 2019-01-01\n",
      "Company GE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GE. Total for this company: 1000\n",
      "Company GE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GE. Total for this company: 2000\n",
      "Company GE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for GE. Total for this company: 3000\n",
      "Company GE - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 783 news items for GE. Total for this company: 3783\n",
      "Reached the end of available news for GE at offset 3000.\n",
      "Saved 3783 news items for GE to sp500_news_data/GE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 334/503: TRMB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TRMB from 2019-01-01\n",
      "Company TRMB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 819 news items for TRMB. Total for this company: 819\n",
      "Reached the end of available news for TRMB at offset 0.\n",
      "Saved 819 news items for TRMB to sp500_news_data/TRMB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 335/503: JBHT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JBHT from 2019-01-01\n",
      "Company JBHT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 968 news items for JBHT. Total for this company: 968\n",
      "Reached the end of available news for JBHT at offset 0.\n",
      "Saved 968 news items for JBHT to sp500_news_data/JBHT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 336/503: MET\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MET from 2019-01-01\n",
      "Company MET - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MET. Total for this company: 1000\n",
      "Company MET - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 383 news items for MET. Total for this company: 1383\n",
      "Reached the end of available news for MET at offset 1000.\n",
      "Saved 1383 news items for MET to sp500_news_data/MET_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 337/503: GPC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GPC from 2019-01-01\n",
      "Company GPC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 723 news items for GPC. Total for this company: 723\n",
      "Reached the end of available news for GPC at offset 0.\n",
      "Saved 723 news items for GPC to sp500_news_data/GPC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 338/503: MAR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MAR from 2019-01-01\n",
      "Company MAR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MAR. Total for this company: 1000\n",
      "Company MAR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MAR. Total for this company: 2000\n",
      "Company MAR - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 200 news items for MAR. Total for this company: 2200\n",
      "Reached the end of available news for MAR at offset 2000.\n",
      "Saved 2200 news items for MAR to sp500_news_data/MAR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 339/503: O\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for O from 2019-01-01\n",
      "Company O - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for O. Total for this company: 1000\n",
      "Company O - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for O. Total for this company: 2000\n",
      "Company O - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 511 news items for O. Total for this company: 2511\n",
      "Reached the end of available news for O at offset 2000.\n",
      "Saved 2511 news items for O to sp500_news_data/O_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 340/503: UPS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UPS from 2019-01-01\n",
      "Company UPS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for UPS. Total for this company: 1000\n",
      "Company UPS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for UPS. Total for this company: 2000\n",
      "Company UPS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for UPS. Total for this company: 3000\n",
      "Company UPS - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 411 news items for UPS. Total for this company: 3411\n",
      "Reached the end of available news for UPS at offset 3000.\n",
      "Saved 3411 news items for UPS to sp500_news_data/UPS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 341/503: BK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BK from 2019-01-01\n",
      "Company BK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BK. Total for this company: 1000\n",
      "Company BK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 358 news items for BK. Total for this company: 1358\n",
      "Reached the end of available news for BK at offset 1000.\n",
      "Saved 1358 news items for BK to sp500_news_data/BK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 342/503: OKE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for OKE from 2019-01-01\n",
      "Company OKE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 978 news items for OKE. Total for this company: 978\n",
      "Reached the end of available news for OKE at offset 0.\n",
      "Saved 978 news items for OKE to sp500_news_data/OKE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 343/503: MKTX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MKTX from 2019-01-01\n",
      "Company MKTX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 797 news items for MKTX. Total for this company: 797\n",
      "Reached the end of available news for MKTX at offset 0.\n",
      "Saved 797 news items for MKTX to sp500_news_data/MKTX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 344/503: VRTX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VRTX from 2019-01-01\n",
      "Company VRTX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for VRTX. Total for this company: 1000\n",
      "Company VRTX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for VRTX. Total for this company: 2000\n",
      "Company VRTX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for VRTX. Total for this company: 3000\n",
      "Company VRTX - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 62 news items for VRTX. Total for this company: 3062\n",
      "Reached the end of available news for VRTX at offset 3000.\n",
      "Saved 3062 news items for VRTX to sp500_news_data/VRTX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 345/503: CHTR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CHTR from 2019-01-01\n",
      "Company CHTR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CHTR. Total for this company: 1000\n",
      "Company CHTR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 245 news items for CHTR. Total for this company: 1245\n",
      "Reached the end of available news for CHTR at offset 1000.\n",
      "Saved 1245 news items for CHTR to sp500_news_data/CHTR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 346/503: MU\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MU from 2019-01-01\n",
      "Company MU - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MU. Total for this company: 1000\n",
      "Company MU - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MU. Total for this company: 2000\n",
      "Company MU - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for MU. Total for this company: 3000\n",
      "Company MU - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for MU. Total for this company: 4000\n",
      "Company MU - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 932 news items for MU. Total for this company: 4932\n",
      "Reached the end of available news for MU at offset 4000.\n",
      "Saved 4932 news items for MU to sp500_news_data/MU_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 347/503: SMCI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SMCI from 2019-01-01\n",
      "Company SMCI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SMCI. Total for this company: 1000\n",
      "Company SMCI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for SMCI. Total for this company: 2000\n",
      "Company SMCI - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for SMCI. Total for this company: 3000\n",
      "Company SMCI - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 162 news items for SMCI. Total for this company: 3162\n",
      "Reached the end of available news for SMCI at offset 3000.\n",
      "Saved 3162 news items for SMCI to sp500_news_data/SMCI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 348/503: DVA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DVA from 2019-01-01\n",
      "Company DVA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DVA. Total for this company: 1000\n",
      "Company DVA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 402 news items for DVA. Total for this company: 1402\n",
      "Reached the end of available news for DVA at offset 1000.\n",
      "Saved 1402 news items for DVA to sp500_news_data/DVA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 349/503: XEL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for XEL from 2019-01-01\n",
      "Company XEL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 746 news items for XEL. Total for this company: 746\n",
      "Reached the end of available news for XEL at offset 0.\n",
      "Saved 746 news items for XEL to sp500_news_data/XEL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 350/503: LYV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LYV from 2019-01-01\n",
      "Company LYV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LYV. Total for this company: 1000\n",
      "Company LYV - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 43 news items for LYV. Total for this company: 1043\n",
      "Reached the end of available news for LYV at offset 1000.\n",
      "Saved 1043 news items for LYV to sp500_news_data/LYV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 351/503: DTE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DTE from 2019-01-01\n",
      "Company DTE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 975 news items for DTE. Total for this company: 975\n",
      "Reached the end of available news for DTE at offset 0.\n",
      "Saved 975 news items for DTE to sp500_news_data/DTE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 352/503: CPT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CPT from 2019-01-01\n",
      "Company CPT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 429 news items for CPT. Total for this company: 429\n",
      "Reached the end of available news for CPT at offset 0.\n",
      "Saved 429 news items for CPT to sp500_news_data/CPT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 353/503: IVZ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IVZ from 2019-01-01\n",
      "Company IVZ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for IVZ. Total for this company: 1000\n",
      "Company IVZ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for IVZ. Total for this company: 2000\n",
      "Company IVZ - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for IVZ. Total for this company: 3000\n",
      "Company IVZ - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 185 news items for IVZ. Total for this company: 3185\n",
      "Reached the end of available news for IVZ at offset 3000.\n",
      "Saved 3185 news items for IVZ to sp500_news_data/IVZ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 354/503: DPZ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DPZ from 2019-01-01\n",
      "Company DPZ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DPZ. Total for this company: 1000\n",
      "Company DPZ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 314 news items for DPZ. Total for this company: 1314\n",
      "Reached the end of available news for DPZ at offset 1000.\n",
      "Saved 1314 news items for DPZ to sp500_news_data/DPZ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 355/503: PH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PH from 2019-01-01\n",
      "Company PH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PH. Total for this company: 1000\n",
      "Company PH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 42 news items for PH. Total for this company: 1042\n",
      "Reached the end of available news for PH at offset 1000.\n",
      "Saved 1042 news items for PH to sp500_news_data/PH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 356/503: VRSN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VRSN from 2019-01-01\n",
      "Company VRSN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 512 news items for VRSN. Total for this company: 512\n",
      "Reached the end of available news for VRSN at offset 0.\n",
      "Saved 512 news items for VRSN to sp500_news_data/VRSN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 357/503: GILD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GILD from 2019-01-01\n",
      "Company GILD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GILD. Total for this company: 1000\n",
      "Company GILD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for GILD. Total for this company: 2000\n",
      "Company GILD - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 603 news items for GILD. Total for this company: 2603\n",
      "Reached the end of available news for GILD at offset 2000.\n",
      "Saved 2603 news items for GILD to sp500_news_data/GILD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 358/503: JBL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JBL from 2019-01-01\n",
      "Company JBL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for JBL. Total for this company: 1000\n",
      "Company JBL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 340 news items for JBL. Total for this company: 1340\n",
      "Reached the end of available news for JBL at offset 1000.\n",
      "Saved 1340 news items for JBL to sp500_news_data/JBL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 359/503: APA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for APA from 2019-01-01\n",
      "Company APA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for APA. Total for this company: 1000\n",
      "Company APA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 5 news items for APA. Total for this company: 1005\n",
      "Reached the end of available news for APA at offset 1000.\n",
      "Saved 1005 news items for APA to sp500_news_data/APA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 360/503: PSA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PSA from 2019-01-01\n",
      "Company PSA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 726 news items for PSA. Total for this company: 726\n",
      "Reached the end of available news for PSA at offset 0.\n",
      "Saved 726 news items for PSA to sp500_news_data/PSA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 361/503: JCI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JCI from 2019-01-01\n",
      "Company JCI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 991 news items for JCI. Total for this company: 991\n",
      "Reached the end of available news for JCI at offset 0.\n",
      "Saved 991 news items for JCI to sp500_news_data/JCI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 362/503: EXPE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EXPE from 2019-01-01\n",
      "Company EXPE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EXPE. Total for this company: 1000\n",
      "Company EXPE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 687 news items for EXPE. Total for this company: 1687\n",
      "Reached the end of available news for EXPE at offset 1000.\n",
      "Saved 1687 news items for EXPE to sp500_news_data/EXPE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 363/503: SJM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SJM from 2019-01-01\n",
      "Company SJM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SJM. Total for this company: 1000\n",
      "Company SJM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 130 news items for SJM. Total for this company: 1130\n",
      "Reached the end of available news for SJM at offset 1000.\n",
      "Saved 1130 news items for SJM to sp500_news_data/SJM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 364/503: MTB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MTB from 2019-01-01\n",
      "Company MTB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 745 news items for MTB. Total for this company: 745\n",
      "Reached the end of available news for MTB at offset 0.\n",
      "Saved 745 news items for MTB to sp500_news_data/MTB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 365/503: CVS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CVS from 2019-01-01\n",
      "Company CVS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CVS. Total for this company: 1000\n",
      "Company CVS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CVS. Total for this company: 2000\n",
      "Company CVS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CVS. Total for this company: 3000\n",
      "Company CVS - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 296 news items for CVS. Total for this company: 3296\n",
      "Reached the end of available news for CVS at offset 3000.\n",
      "Saved 3296 news items for CVS to sp500_news_data/CVS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 366/503: D\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for D from 2019-01-01\n",
      "Company D - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for D. Total for this company: 1000\n",
      "Company D - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 125 news items for D. Total for this company: 1125\n",
      "Reached the end of available news for D at offset 1000.\n",
      "Saved 1125 news items for D to sp500_news_data/D_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 367/503: XYL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for XYL from 2019-01-01\n",
      "Company XYL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 727 news items for XYL. Total for this company: 727\n",
      "Reached the end of available news for XYL at offset 0.\n",
      "Saved 727 news items for XYL to sp500_news_data/XYL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 368/503: BEN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BEN from 2019-01-01\n",
      "Company BEN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BEN. Total for this company: 1000\n",
      "Company BEN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 584 news items for BEN. Total for this company: 1584\n",
      "Reached the end of available news for BEN at offset 1000.\n",
      "Saved 1584 news items for BEN to sp500_news_data/BEN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 369/503: ROP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ROP from 2019-01-01\n",
      "Company ROP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 888 news items for ROP. Total for this company: 888\n",
      "Reached the end of available news for ROP at offset 0.\n",
      "Saved 888 news items for ROP to sp500_news_data/ROP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 370/503: SYK\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SYK from 2019-01-01\n",
      "Company SYK - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SYK. Total for this company: 1000\n",
      "Company SYK - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 186 news items for SYK. Total for this company: 1186\n",
      "Reached the end of available news for SYK at offset 1000.\n",
      "Saved 1186 news items for SYK to sp500_news_data/SYK_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 371/503: DHR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DHR from 2019-01-01\n",
      "Company DHR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DHR. Total for this company: 1000\n",
      "Company DHR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 180 news items for DHR. Total for this company: 1180\n",
      "Reached the end of available news for DHR at offset 1000.\n",
      "Saved 1180 news items for DHR to sp500_news_data/DHR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 372/503: TXT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TXT from 2019-01-01\n",
      "Company TXT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TXT. Total for this company: 1000\n",
      "Company TXT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 383 news items for TXT. Total for this company: 1383\n",
      "Reached the end of available news for TXT at offset 1000.\n",
      "Saved 1383 news items for TXT to sp500_news_data/TXT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 373/503: ACGL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ACGL from 2019-01-01\n",
      "Company ACGL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 825 news items for ACGL. Total for this company: 825\n",
      "Reached the end of available news for ACGL at offset 0.\n",
      "Saved 825 news items for ACGL to sp500_news_data/ACGL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 374/503: ITW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ITW from 2019-01-01\n",
      "Company ITW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 862 news items for ITW. Total for this company: 862\n",
      "Reached the end of available news for ITW at offset 0.\n",
      "Saved 862 news items for ITW to sp500_news_data/ITW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 375/503: JKHY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for JKHY from 2019-01-01\n",
      "Company JKHY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 576 news items for JKHY. Total for this company: 576\n",
      "Reached the end of available news for JKHY at offset 0.\n",
      "Saved 576 news items for JKHY to sp500_news_data/JKHY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 376/503: NUE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NUE from 2019-01-01\n",
      "Company NUE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NUE. Total for this company: 1000\n",
      "Company NUE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NUE. Total for this company: 2000\n",
      "Company NUE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 231 news items for NUE. Total for this company: 2231\n",
      "Reached the end of available news for NUE at offset 2000.\n",
      "Saved 2231 news items for NUE to sp500_news_data/NUE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 377/503: BWA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BWA from 2019-01-01\n",
      "Company BWA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 914 news items for BWA. Total for this company: 914\n",
      "Reached the end of available news for BWA at offset 0.\n",
      "Saved 914 news items for BWA to sp500_news_data/BWA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 378/503: VZ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VZ from 2019-01-01\n",
      "Company VZ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 1000\n",
      "Company VZ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 2000\n",
      "Company VZ - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 3000\n",
      "Company VZ - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 4000\n",
      "Company VZ - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 5000\n",
      "Company VZ - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 6000\n",
      "Company VZ - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for VZ. Total for this company: 7000\n",
      "Company VZ - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 463 news items for VZ. Total for this company: 7463\n",
      "Reached the end of available news for VZ at offset 7000.\n",
      "Saved 7463 news items for VZ to sp500_news_data/VZ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 379/503: AMP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMP from 2019-01-01\n",
      "Company AMP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 917 news items for AMP. Total for this company: 917\n",
      "Reached the end of available news for AMP at offset 0.\n",
      "Saved 917 news items for AMP to sp500_news_data/AMP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 380/503: MCO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MCO from 2019-01-01\n",
      "Company MCO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 815 news items for MCO. Total for this company: 815\n",
      "Reached the end of available news for MCO at offset 0.\n",
      "Saved 815 news items for MCO to sp500_news_data/MCO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 381/503: YUM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for YUM from 2019-01-01\n",
      "Company YUM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for YUM. Total for this company: 1000\n",
      "Company YUM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 684 news items for YUM. Total for this company: 1684\n",
      "Reached the end of available news for YUM at offset 1000.\n",
      "Saved 1684 news items for YUM to sp500_news_data/YUM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 382/503: HAS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HAS from 2019-01-01\n",
      "Company HAS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HAS. Total for this company: 1000\n",
      "Company HAS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for HAS. Total for this company: 2000\n",
      "Company HAS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 878 news items for HAS. Total for this company: 2878\n",
      "Reached the end of available news for HAS at offset 2000.\n",
      "Saved 2878 news items for HAS to sp500_news_data/HAS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 383/503: RMD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RMD from 2019-01-01\n",
      "Company RMD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 937 news items for RMD. Total for this company: 937\n",
      "Reached the end of available news for RMD at offset 0.\n",
      "Saved 937 news items for RMD to sp500_news_data/RMD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 384/503: UNH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UNH from 2019-01-01\n",
      "Company UNH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for UNH. Total for this company: 1000\n",
      "Company UNH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for UNH. Total for this company: 2000\n",
      "Company UNH - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for UNH. Total for this company: 3000\n",
      "Company UNH - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for UNH. Total for this company: 4000\n",
      "Company UNH - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 141 news items for UNH. Total for this company: 4141\n",
      "Reached the end of available news for UNH at offset 4000.\n",
      "Saved 4141 news items for UNH to sp500_news_data/UNH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 385/503: CI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CI from 2019-01-01\n",
      "Company CI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CI. Total for this company: 1000\n",
      "Company CI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 771 news items for CI. Total for this company: 1771\n",
      "Reached the end of available news for CI at offset 1000.\n",
      "Saved 1771 news items for CI to sp500_news_data/CI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 386/503: WY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WY from 2019-01-01\n",
      "Company WY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 679 news items for WY. Total for this company: 679\n",
      "Reached the end of available news for WY at offset 0.\n",
      "Saved 679 news items for WY to sp500_news_data/WY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 387/503: MMC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MMC from 2019-01-01\n",
      "Company MMC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 937 news items for MMC. Total for this company: 937\n",
      "Reached the end of available news for MMC at offset 0.\n",
      "Saved 937 news items for MMC to sp500_news_data/MMC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 388/503: IR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IR from 2019-01-01\n",
      "Company IR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 955 news items for IR. Total for this company: 955\n",
      "Reached the end of available news for IR at offset 0.\n",
      "Saved 955 news items for IR to sp500_news_data/IR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 389/503: AMD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMD from 2019-01-01\n",
      "Company AMD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 1000\n",
      "Company AMD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 2000\n",
      "Company AMD - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 3000\n",
      "Company AMD - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 4000\n",
      "Company AMD - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 5000\n",
      "Company AMD - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 6000\n",
      "Company AMD - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 7000\n",
      "Company AMD - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 8000\n",
      "Company AMD - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 9000\n",
      "Company AMD - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for AMD. Total for this company: 10000\n",
      "Company AMD - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 307 news items for AMD. Total for this company: 10307\n",
      "Reached the end of available news for AMD at offset 10000.\n",
      "Saved 10307 news items for AMD to sp500_news_data/AMD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 390/503: ALLE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ALLE from 2019-01-01\n",
      "Company ALLE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 740 news items for ALLE. Total for this company: 740\n",
      "Reached the end of available news for ALLE at offset 0.\n",
      "Saved 740 news items for ALLE to sp500_news_data/ALLE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 391/503: PCG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PCG from 2019-01-01\n",
      "Company PCG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PCG. Total for this company: 1000\n",
      "Company PCG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 325 news items for PCG. Total for this company: 1325\n",
      "Reached the end of available news for PCG at offset 1000.\n",
      "Saved 1325 news items for PCG to sp500_news_data/PCG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 392/503: ARE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ARE from 2019-01-01\n",
      "Company ARE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ARE. Total for this company: 1000\n",
      "Company ARE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ARE. Total for this company: 2000\n",
      "Company ARE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 190 news items for ARE. Total for this company: 2190\n",
      "Reached the end of available news for ARE at offset 2000.\n",
      "Saved 2190 news items for ARE to sp500_news_data/ARE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 393/503: CZR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CZR from 2019-01-01\n",
      "Company CZR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CZR. Total for this company: 1000\n",
      "Company CZR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 759 news items for CZR. Total for this company: 1759\n",
      "Reached the end of available news for CZR at offset 1000.\n",
      "Saved 1759 news items for CZR to sp500_news_data/CZR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 394/503: KR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KR from 2019-01-01\n",
      "Company KR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KR. Total for this company: 1000\n",
      "Company KR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for KR. Total for this company: 2000\n",
      "Company KR - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for KR. Total for this company: 3000\n",
      "Company KR - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 109 news items for KR. Total for this company: 3109\n",
      "Reached the end of available news for KR at offset 3000.\n",
      "Saved 3109 news items for KR to sp500_news_data/KR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 395/503: MGM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MGM from 2019-01-01\n",
      "Company MGM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MGM. Total for this company: 1000\n",
      "Company MGM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for MGM. Total for this company: 2000\n",
      "Company MGM - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 413 news items for MGM. Total for this company: 2413\n",
      "Reached the end of available news for MGM at offset 2000.\n",
      "Saved 2413 news items for MGM to sp500_news_data/MGM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 396/503: CINF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CINF from 2019-01-01\n",
      "Company CINF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 765 news items for CINF. Total for this company: 765\n",
      "Reached the end of available news for CINF at offset 0.\n",
      "Saved 765 news items for CINF to sp500_news_data/CINF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 397/503: CMI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CMI from 2019-01-01\n",
      "Company CMI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CMI. Total for this company: 1000\n",
      "Company CMI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 372 news items for CMI. Total for this company: 1372\n",
      "Reached the end of available news for CMI at offset 1000.\n",
      "Saved 1372 news items for CMI to sp500_news_data/CMI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 398/503: DOV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DOV from 2019-01-01\n",
      "Company DOV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 975 news items for DOV. Total for this company: 975\n",
      "Reached the end of available news for DOV at offset 0.\n",
      "Saved 975 news items for DOV to sp500_news_data/DOV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 399/503: SYY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SYY from 2019-01-01\n",
      "Company SYY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SYY. Total for this company: 1000\n",
      "Company SYY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 321 news items for SYY. Total for this company: 1321\n",
      "Reached the end of available news for SYY at offset 1000.\n",
      "Saved 1321 news items for SYY to sp500_news_data/SYY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 400/503: BXP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BXP from 2019-01-01\n",
      "Company BXP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 594 news items for BXP. Total for this company: 594\n",
      "Reached the end of available news for BXP at offset 0.\n",
      "Saved 594 news items for BXP to sp500_news_data/BXP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 401/503: EG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EG from 2019-01-01\n",
      "Company EG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 99 news items for EG. Total for this company: 99\n",
      "Reached the end of available news for EG at offset 0.\n",
      "Saved 99 news items for EG to sp500_news_data/EG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 402/503: WAB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WAB from 2019-01-01\n",
      "Company WAB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 859 news items for WAB. Total for this company: 859\n",
      "Reached the end of available news for WAB at offset 0.\n",
      "Saved 859 news items for WAB to sp500_news_data/WAB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 403/503: LII\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LII from 2019-01-01\n",
      "Company LII - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 512 news items for LII. Total for this company: 512\n",
      "Reached the end of available news for LII at offset 0.\n",
      "Saved 512 news items for LII to sp500_news_data/LII_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 404/503: TMUS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TMUS from 2019-01-01\n",
      "Company TMUS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TMUS. Total for this company: 1000\n",
      "Company TMUS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for TMUS. Total for this company: 2000\n",
      "Company TMUS - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 949 news items for TMUS. Total for this company: 2949\n",
      "Reached the end of available news for TMUS at offset 2000.\n",
      "Saved 2949 news items for TMUS to sp500_news_data/TMUS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 405/503: USB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for USB from 2019-01-01\n",
      "Company USB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for USB. Total for this company: 1000\n",
      "Company USB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 692 news items for USB. Total for this company: 1692\n",
      "Reached the end of available news for USB at offset 1000.\n",
      "Saved 1692 news items for USB to sp500_news_data/USB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 406/503: WM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WM from 2019-01-01\n",
      "Company WM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WM. Total for this company: 1000\n",
      "Company WM - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 104 news items for WM. Total for this company: 1104\n",
      "Reached the end of available news for WM at offset 1000.\n",
      "Saved 1104 news items for WM to sp500_news_data/WM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 407/503: ICE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ICE from 2019-01-01\n",
      "Company ICE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ICE. Total for this company: 1000\n",
      "Company ICE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 542 news items for ICE. Total for this company: 1542\n",
      "Reached the end of available news for ICE at offset 1000.\n",
      "Saved 1542 news items for ICE to sp500_news_data/ICE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 408/503: FDX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FDX from 2019-01-01\n",
      "Company FDX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FDX. Total for this company: 1000\n",
      "Company FDX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for FDX. Total for this company: 2000\n",
      "Company FDX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for FDX. Total for this company: 3000\n",
      "Company FDX - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for FDX. Total for this company: 4000\n",
      "Company FDX - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 395 news items for FDX. Total for this company: 4395\n",
      "Reached the end of available news for FDX at offset 4000.\n",
      "Saved 4395 news items for FDX to sp500_news_data/FDX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 409/503: HPQ\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HPQ from 2019-01-01\n",
      "Company HPQ - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HPQ. Total for this company: 1000\n",
      "Company HPQ - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for HPQ. Total for this company: 2000\n",
      "Company HPQ - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 464 news items for HPQ. Total for this company: 2464\n",
      "Reached the end of available news for HPQ at offset 2000.\n",
      "Saved 2464 news items for HPQ to sp500_news_data/HPQ_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 410/503: PFE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PFE from 2019-01-01\n",
      "Company PFE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 1000\n",
      "Company PFE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 2000\n",
      "Company PFE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 3000\n",
      "Company PFE - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 4000\n",
      "Company PFE - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 5000\n",
      "Company PFE - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 6000\n",
      "Company PFE - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 7000\n",
      "Company PFE - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 8000\n",
      "Company PFE - Batch 9/25: Fetching news with offset 8000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 9000\n",
      "Company PFE - Batch 10/25: Fetching news with offset 9000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 10000\n",
      "Company PFE - Batch 11/25: Fetching news with offset 10000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 11000\n",
      "Company PFE - Batch 12/25: Fetching news with offset 11000...\n",
      "Retrieved 1000 news items for PFE. Total for this company: 12000\n",
      "Company PFE - Batch 13/25: Fetching news with offset 12000...\n",
      "Retrieved 926 news items for PFE. Total for this company: 12926\n",
      "Reached the end of available news for PFE at offset 12000.\n",
      "Saved 12926 news items for PFE to sp500_news_data/PFE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 411/503: DOW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DOW from 2019-01-01\n",
      "Company DOW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DOW. Total for this company: 1000\n",
      "Company DOW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 902 news items for DOW. Total for this company: 1902\n",
      "Reached the end of available news for DOW at offset 1000.\n",
      "Saved 1902 news items for DOW to sp500_news_data/DOW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 412/503: SRE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SRE from 2019-01-01\n",
      "Company SRE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SRE. Total for this company: 1000\n",
      "Company SRE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 230 news items for SRE. Total for this company: 1230\n",
      "Reached the end of available news for SRE at offset 1000.\n",
      "Saved 1230 news items for SRE to sp500_news_data/SRE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 413/503: REGN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for REGN from 2019-01-01\n",
      "Company REGN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for REGN. Total for this company: 1000\n",
      "Company REGN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for REGN. Total for this company: 2000\n",
      "Company REGN - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 820 news items for REGN. Total for this company: 2820\n",
      "Reached the end of available news for REGN at offset 2000.\n",
      "Saved 2820 news items for REGN to sp500_news_data/REGN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 414/503: STX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for STX from 2019-01-01\n",
      "Company STX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for STX. Total for this company: 1000\n",
      "Company STX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 51 news items for STX. Total for this company: 1051\n",
      "Reached the end of available news for STX at offset 1000.\n",
      "Saved 1051 news items for STX to sp500_news_data/STX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 415/503: TTWO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TTWO from 2019-01-01\n",
      "Company TTWO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TTWO. Total for this company: 1000\n",
      "Company TTWO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 511 news items for TTWO. Total for this company: 1511\n",
      "Reached the end of available news for TTWO at offset 1000.\n",
      "Saved 1511 news items for TTWO to sp500_news_data/TTWO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 416/503: NOW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NOW from 2019-01-01\n",
      "Company NOW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NOW. Total for this company: 1000\n",
      "Company NOW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NOW. Total for this company: 2000\n",
      "Company NOW - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for NOW. Total for this company: 3000\n",
      "Company NOW - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 947 news items for NOW. Total for this company: 3947\n",
      "Reached the end of available news for NOW at offset 3000.\n",
      "Saved 3947 news items for NOW to sp500_news_data/NOW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 417/503: NVR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NVR from 2019-01-01\n",
      "Company NVR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 510 news items for NVR. Total for this company: 510\n",
      "Reached the end of available news for NVR at offset 0.\n",
      "Saved 510 news items for NVR to sp500_news_data/NVR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 418/503: STT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for STT from 2019-01-01\n",
      "Company STT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for STT. Total for this company: 1000\n",
      "Company STT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 186 news items for STT. Total for this company: 1186\n",
      "Reached the end of available news for STT at offset 1000.\n",
      "Saved 1186 news items for STT to sp500_news_data/STT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 419/503: TFX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TFX from 2019-01-01\n",
      "Company TFX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 755 news items for TFX. Total for this company: 755\n",
      "Reached the end of available news for TFX at offset 0.\n",
      "Saved 755 news items for TFX to sp500_news_data/TFX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 420/503: ABBV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ABBV from 2019-01-01\n",
      "Company ABBV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ABBV. Total for this company: 1000\n",
      "Company ABBV - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ABBV. Total for this company: 2000\n",
      "Company ABBV - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for ABBV. Total for this company: 3000\n",
      "Company ABBV - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 985 news items for ABBV. Total for this company: 3985\n",
      "Reached the end of available news for ABBV at offset 3000.\n",
      "Saved 3985 news items for ABBV to sp500_news_data/ABBV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 421/503: BR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BR from 2019-01-01\n",
      "Company BR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 899 news items for BR. Total for this company: 899\n",
      "Reached the end of available news for BR at offset 0.\n",
      "Saved 899 news items for BR to sp500_news_data/BR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 422/503: FSLR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FSLR from 2019-01-01\n",
      "Company FSLR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for FSLR. Total for this company: 1000\n",
      "Company FSLR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for FSLR. Total for this company: 2000\n",
      "Company FSLR - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 97 news items for FSLR. Total for this company: 2097\n",
      "Reached the end of available news for FSLR at offset 2000.\n",
      "Saved 2097 news items for FSLR to sp500_news_data/FSLR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 423/503: NEE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for NEE from 2019-01-01\n",
      "Company NEE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for NEE. Total for this company: 1000\n",
      "Company NEE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for NEE. Total for this company: 2000\n",
      "Company NEE - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for NEE. Total for this company: 3000\n",
      "Company NEE - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 289 news items for NEE. Total for this company: 3289\n",
      "Reached the end of available news for NEE at offset 3000.\n",
      "Saved 3289 news items for NEE to sp500_news_data/NEE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 424/503: MCHP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MCHP from 2019-01-01\n",
      "Company MCHP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for MCHP. Total for this company: 1000\n",
      "Company MCHP - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 575 news items for MCHP. Total for this company: 1575\n",
      "Reached the end of available news for MCHP at offset 1000.\n",
      "Saved 1575 news items for MCHP to sp500_news_data/MCHP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 425/503: TYL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TYL from 2019-01-01\n",
      "Company TYL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 769 news items for TYL. Total for this company: 769\n",
      "Reached the end of available news for TYL at offset 0.\n",
      "Saved 769 news items for TYL to sp500_news_data/TYL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 426/503: PYPL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PYPL from 2019-01-01\n",
      "Company PYPL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 1000\n",
      "Company PYPL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 2000\n",
      "Company PYPL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 3000\n",
      "Company PYPL - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 4000\n",
      "Company PYPL - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 5000\n",
      "Company PYPL - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 6000\n",
      "Company PYPL - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 1000 news items for PYPL. Total for this company: 7000\n",
      "Company PYPL - Batch 8/25: Fetching news with offset 7000...\n",
      "Retrieved 221 news items for PYPL. Total for this company: 7221\n",
      "Reached the end of available news for PYPL at offset 7000.\n",
      "Saved 7221 news items for PYPL to sp500_news_data/PYPL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 427/503: KKR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KKR from 2019-01-01\n",
      "Company KKR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KKR. Total for this company: 1000\n",
      "Company KKR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for KKR. Total for this company: 2000\n",
      "Company KKR - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 341 news items for KKR. Total for this company: 2341\n",
      "Reached the end of available news for KKR at offset 2000.\n",
      "Saved 2341 news items for KKR to sp500_news_data/KKR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 428/503: BX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BX from 2019-01-01\n",
      "Company BX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BX. Total for this company: 1000\n",
      "Company BX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BX. Total for this company: 2000\n",
      "Company BX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 724 news items for BX. Total for this company: 2724\n",
      "Reached the end of available news for BX at offset 2000.\n",
      "Saved 2724 news items for BX to sp500_news_data/BX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 429/503: BF-B\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BF-B from 2019-01-01\n",
      "Company BF-B - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 540 news items for BF-B. Total for this company: 540\n",
      "Reached the end of available news for BF-B at offset 0.\n",
      "Saved 540 news items for BF-B to sp500_news_data/BF-B_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 430/503: SYF\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SYF from 2019-01-01\n",
      "Company SYF - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 842 news items for SYF. Total for this company: 842\n",
      "Reached the end of available news for SYF at offset 0.\n",
      "Saved 842 news items for SYF to sp500_news_data/SYF_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 431/503: ANET\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ANET from 2019-01-01\n",
      "Company ANET - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ANET. Total for this company: 1000\n",
      "Company ANET - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ANET. Total for this company: 2000\n",
      "Company ANET - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for ANET. Total for this company: 3000\n",
      "Company ANET - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 230 news items for ANET. Total for this company: 3230\n",
      "Reached the end of available news for ANET at offset 3000.\n",
      "Saved 3230 news items for ANET to sp500_news_data/ANET_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 432/503: APO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for APO from 2019-01-01\n",
      "Company APO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for APO. Total for this company: 1000\n",
      "Company APO - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for APO. Total for this company: 2000\n",
      "Company APO - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 453 news items for APO. Total for this company: 2453\n",
      "Reached the end of available news for APO at offset 2000.\n",
      "Saved 2453 news items for APO to sp500_news_data/APO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 433/503: ELV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ELV from 2019-01-01\n",
      "Company ELV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 730 news items for ELV. Total for this company: 730\n",
      "Reached the end of available news for ELV at offset 0.\n",
      "Saved 730 news items for ELV to sp500_news_data/ELV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 434/503: TPL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TPL from 2019-01-01\n",
      "Company TPL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 354 news items for TPL. Total for this company: 354\n",
      "Reached the end of available news for TPL at offset 0.\n",
      "Saved 354 news items for TPL to sp500_news_data/TPL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 435/503: MAA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MAA from 2019-01-01\n",
      "Company MAA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 577 news items for MAA. Total for this company: 577\n",
      "Reached the end of available news for MAA at offset 0.\n",
      "Saved 577 news items for MAA to sp500_news_data/MAA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 436/503: KEYS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KEYS from 2019-01-01\n",
      "Company KEYS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KEYS. Total for this company: 1000\n",
      "Company KEYS - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 435 news items for KEYS. Total for this company: 1435\n",
      "Reached the end of available news for KEYS at offset 1000.\n",
      "Saved 1435 news items for KEYS to sp500_news_data/KEYS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 437/503: BRK-B\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BRK-B from 2019-01-01\n",
      "Company BRK-B - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BRK-B. Total for this company: 1000\n",
      "Company BRK-B - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BRK-B. Total for this company: 2000\n",
      "Company BRK-B - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for BRK-B. Total for this company: 3000\n",
      "Company BRK-B - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for BRK-B. Total for this company: 4000\n",
      "Company BRK-B - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 941 news items for BRK-B. Total for this company: 4941\n",
      "Reached the end of available news for BRK-B at offset 4000.\n",
      "Saved 4941 news items for BRK-B to sp500_news_data/BRK-B_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 438/503: CFG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CFG from 2019-01-01\n",
      "Company CFG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CFG. Total for this company: 1000\n",
      "Company CFG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 164 news items for CFG. Total for this company: 1164\n",
      "Reached the end of available news for CFG at offset 1000.\n",
      "Saved 1164 news items for CFG to sp500_news_data/CFG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 439/503: KHC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KHC from 2019-01-01\n",
      "Company KHC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for KHC. Total for this company: 1000\n",
      "Company KHC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for KHC. Total for this company: 2000\n",
      "Company KHC - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 200 news items for KHC. Total for this company: 2200\n",
      "Reached the end of available news for KHC at offset 2000.\n",
      "Saved 2200 news items for KHC to sp500_news_data/KHC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 440/503: HPE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HPE from 2019-01-01\n",
      "Company HPE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HPE. Total for this company: 1000\n",
      "Company HPE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 689 news items for HPE. Total for this company: 1689\n",
      "Reached the end of available news for HPE at offset 1000.\n",
      "Saved 1689 news items for HPE to sp500_news_data/HPE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 441/503: WBA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WBA from 2019-01-01\n",
      "Company WBA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WBA. Total for this company: 1000\n",
      "Company WBA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for WBA. Total for this company: 2000\n",
      "Company WBA - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for WBA. Total for this company: 3000\n",
      "Company WBA - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 389 news items for WBA. Total for this company: 3389\n",
      "Reached the end of available news for WBA at offset 3000.\n",
      "Saved 3389 news items for WBA to sp500_news_data/WBA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 442/503: ES\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ES from 2019-01-01\n",
      "Company ES - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 574 news items for ES. Total for this company: 574\n",
      "Reached the end of available news for ES at offset 0.\n",
      "Saved 574 news items for ES to sp500_news_data/ES_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 443/503: ZBH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ZBH from 2019-01-01\n",
      "Company ZBH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 779 news items for ZBH. Total for this company: 779\n",
      "Reached the end of available news for ZBH at offset 0.\n",
      "Saved 779 news items for ZBH to sp500_news_data/ZBH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 444/503: HUBB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HUBB from 2019-01-01\n",
      "Company HUBB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 694 news items for HUBB. Total for this company: 694\n",
      "Reached the end of available news for HUBB at offset 0.\n",
      "Saved 694 news items for HUBB to sp500_news_data/HUBB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 445/503: ON\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ON from 2019-01-01\n",
      "Company ON - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ON. Total for this company: 1000\n",
      "Company ON - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ON. Total for this company: 2000\n",
      "Company ON - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for ON. Total for this company: 3000\n",
      "Company ON - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 296 news items for ON. Total for this company: 3296\n",
      "Reached the end of available news for ON at offset 3000.\n",
      "Saved 3296 news items for ON to sp500_news_data/ON_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 446/503: SPGI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SPGI from 2019-01-01\n",
      "Company SPGI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SPGI. Total for this company: 1000\n",
      "Company SPGI - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for SPGI. Total for this company: 2000\n",
      "Company SPGI - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for SPGI. Total for this company: 3000\n",
      "Company SPGI - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 113 news items for SPGI. Total for this company: 3113\n",
      "Reached the end of available news for SPGI at offset 3000.\n",
      "Saved 3113 news items for SPGI to sp500_news_data/SPGI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 447/503: FTV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for FTV from 2019-01-01\n",
      "Company FTV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 488 news items for FTV. Total for this company: 488\n",
      "Reached the end of available news for FTV at offset 0.\n",
      "Saved 488 news items for FTV to sp500_news_data/FTV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 448/503: GDDY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GDDY from 2019-01-01\n",
      "Company GDDY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for GDDY. Total for this company: 1000\n",
      "Company GDDY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 109 news items for GDDY. Total for this company: 1109\n",
      "Reached the end of available news for GDDY at offset 1000.\n",
      "Saved 1109 news items for GDDY to sp500_news_data/GDDY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 449/503: LW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LW from 2019-01-01\n",
      "Company LW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LW. Total for this company: 1000\n",
      "Company LW - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 310 news items for LW. Total for this company: 1310\n",
      "Reached the end of available news for LW at offset 1000.\n",
      "Saved 1310 news items for LW to sp500_news_data/LW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 450/503: AXON\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AXON from 2019-01-01\n",
      "Company AXON - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 831 news items for AXON. Total for this company: 831\n",
      "Reached the end of available news for AXON at offset 0.\n",
      "Saved 831 news items for AXON to sp500_news_data/AXON_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 451/503: VST\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VST from 2019-01-01\n",
      "Company VST - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 899 news items for VST. Total for this company: 899\n",
      "Reached the end of available news for VST at offset 0.\n",
      "Saved 899 news items for VST to sp500_news_data/VST_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 452/503: INVH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for INVH from 2019-01-01\n",
      "Company INVH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 539 news items for INVH. Total for this company: 539\n",
      "Reached the end of available news for INVH at offset 0.\n",
      "Saved 539 news items for INVH to sp500_news_data/INVH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 453/503: DELL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DELL from 2019-01-01\n",
      "Company DELL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DELL. Total for this company: 1000\n",
      "Company DELL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for DELL. Total for this company: 2000\n",
      "Company DELL - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 556 news items for DELL. Total for this company: 2556\n",
      "Reached the end of available news for DELL at offset 2000.\n",
      "Saved 2556 news items for DELL to sp500_news_data/DELL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 454/503: HD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HD from 2019-01-01\n",
      "Company HD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for HD. Total for this company: 1000\n",
      "Company HD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for HD. Total for this company: 2000\n",
      "Company HD - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for HD. Total for this company: 3000\n",
      "Company HD - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for HD. Total for this company: 4000\n",
      "Company HD - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 756 news items for HD. Total for this company: 4756\n",
      "Reached the end of available news for HD at offset 4000.\n",
      "Saved 4756 news items for HD to sp500_news_data/HD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 455/503: EXC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EXC from 2019-01-01\n",
      "Company EXC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for EXC. Total for this company: 1000\n",
      "Company EXC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 141 news items for EXC. Total for this company: 1141\n",
      "Reached the end of available news for EXC at offset 1000.\n",
      "Saved 1141 news items for EXC to sp500_news_data/EXC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 456/503: LH\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LH from 2019-01-01\n",
      "Company LH - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LH. Total for this company: 1000\n",
      "Company LH - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 152 news items for LH. Total for this company: 1152\n",
      "Reached the end of available news for LH at offset 1000.\n",
      "Saved 1152 news items for LH to sp500_news_data/LH_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 457/503: MTD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for MTD from 2019-01-01\n",
      "Company MTD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 471 news items for MTD. Total for this company: 471\n",
      "Reached the end of available news for MTD at offset 0.\n",
      "Saved 471 news items for MTD to sp500_news_data/MTD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 458/503: SLB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SLB from 2019-01-01\n",
      "Company SLB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for SLB. Total for this company: 1000\n",
      "Company SLB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 386 news items for SLB. Total for this company: 1386\n",
      "Reached the end of available news for SLB at offset 1000.\n",
      "Saved 1386 news items for SLB to sp500_news_data/SLB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 459/503: CBRE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CBRE from 2019-01-01\n",
      "Company CBRE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CBRE. Total for this company: 1000\n",
      "Company CBRE - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 197 news items for CBRE. Total for this company: 1197\n",
      "Reached the end of available news for CBRE at offset 1000.\n",
      "Saved 1197 news items for CBRE to sp500_news_data/CBRE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 460/503: TPR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TPR from 2019-01-01\n",
      "Company TPR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TPR. Total for this company: 1000\n",
      "Company TPR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 340 news items for TPR. Total for this company: 1340\n",
      "Reached the end of available news for TPR at offset 1000.\n",
      "Saved 1340 news items for TPR to sp500_news_data/TPR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 461/503: IQV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for IQV from 2019-01-01\n",
      "Company IQV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 753 news items for IQV. Total for this company: 753\n",
      "Reached the end of available news for IQV at offset 0.\n",
      "Saved 753 news items for IQV to sp500_news_data/IQV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 462/503: APTV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for APTV from 2019-01-01\n",
      "Company APTV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 819 news items for APTV. Total for this company: 819\n",
      "Reached the end of available news for APTV at offset 0.\n",
      "Saved 819 news items for APTV to sp500_news_data/APTV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 463/503: VICI\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VICI from 2019-01-01\n",
      "Company VICI - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 957 news items for VICI. Total for this company: 957\n",
      "Reached the end of available news for VICI at offset 0.\n",
      "Saved 957 news items for VICI to sp500_news_data/VICI_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 464/503: BKNG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BKNG from 2019-01-01\n",
      "Company BKNG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BKNG. Total for this company: 1000\n",
      "Company BKNG - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for BKNG. Total for this company: 2000\n",
      "Company BKNG - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 129 news items for BKNG. Total for this company: 2129\n",
      "Reached the end of available news for BKNG at offset 2000.\n",
      "Saved 2129 news items for BKNG to sp500_news_data/BKNG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 465/503: WELL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WELL from 2019-01-01\n",
      "Company WELL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WELL. Total for this company: 1000\n",
      "Company WELL - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 764 news items for WELL. Total for this company: 1764\n",
      "Reached the end of available news for WELL at offset 1000.\n",
      "Saved 1764 news items for WELL to sp500_news_data/WELL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 466/503: DAY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DAY from 2019-01-01\n",
      "Company DAY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for DAY. Total for this company: 1000\n",
      "Company DAY - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 446 news items for DAY. Total for this company: 1446\n",
      "Reached the end of available news for DAY at offset 1000.\n",
      "Saved 1446 news items for DAY to sp500_news_data/DAY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 467/503: EVRG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for EVRG from 2019-01-01\n",
      "Company EVRG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 345 news items for EVRG. Total for this company: 345\n",
      "Reached the end of available news for EVRG at offset 0.\n",
      "Saved 345 news items for EVRG to sp500_news_data/EVRG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 468/503: KDP\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KDP from 2019-01-01\n",
      "Company KDP - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 888 news items for KDP. Total for this company: 888\n",
      "Reached the end of available news for KDP at offset 0.\n",
      "Saved 888 news items for KDP to sp500_news_data/KDP_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 469/503: LIN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LIN from 2019-01-01\n",
      "Company LIN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LIN. Total for this company: 1000\n",
      "Company LIN - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 33 news items for LIN. Total for this company: 1033\n",
      "Reached the end of available news for LIN at offset 1000.\n",
      "Saved 1033 news items for LIN to sp500_news_data/LIN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 470/503: UBER\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for UBER from 2019-01-01\n",
      "Company UBER - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for UBER. Total for this company: 1000\n",
      "Company UBER - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for UBER. Total for this company: 2000\n",
      "Company UBER - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for UBER. Total for this company: 3000\n",
      "Company UBER - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for UBER. Total for this company: 4000\n",
      "Company UBER - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for UBER. Total for this company: 5000\n",
      "Company UBER - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 1000 news items for UBER. Total for this company: 6000\n",
      "Company UBER - Batch 7/25: Fetching news with offset 6000...\n",
      "Retrieved 546 news items for UBER. Total for this company: 6546\n",
      "Reached the end of available news for UBER at offset 6000.\n",
      "Saved 6546 news items for UBER to sp500_news_data/UBER_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 471/503: BKR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BKR from 2019-01-01\n",
      "Company BKR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for BKR. Total for this company: 1000\n",
      "Company BKR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 813 news items for BKR. Total for this company: 1813\n",
      "Reached the end of available news for BKR at offset 1000.\n",
      "Saved 1813 news items for BKR to sp500_news_data/BKR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 472/503: GL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GL from 2019-01-01\n",
      "Company GL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 492 news items for GL. Total for this company: 492\n",
      "Reached the end of available news for GL at offset 0.\n",
      "Saved 492 news items for GL to sp500_news_data/GL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 473/503: HWM\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for HWM from 2019-01-01\n",
      "Company HWM - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 738 news items for HWM. Total for this company: 738\n",
      "Reached the end of available news for HWM at offset 0.\n",
      "Saved 738 news items for HWM to sp500_news_data/HWM_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 474/503: DOC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for DOC from 2019-01-01\n",
      "Company DOC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 331 news items for DOC. Total for this company: 331\n",
      "Reached the end of available news for DOC at offset 0.\n",
      "Saved 331 news items for DOC to sp500_news_data/DOC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 475/503: TT\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TT from 2019-01-01\n",
      "Company TT - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TT. Total for this company: 1000\n",
      "Company TT - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 212 news items for TT. Total for this company: 1212\n",
      "Reached the end of available news for TT at offset 1000.\n",
      "Saved 1212 news items for TT to sp500_news_data/TT_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 476/503: PARA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PARA from 2019-01-01\n",
      "Company PARA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PARA. Total for this company: 1000\n",
      "Company PARA - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 444 news items for PARA. Total for this company: 1444\n",
      "Reached the end of available news for PARA at offset 1000.\n",
      "Saved 1444 news items for PARA to sp500_news_data/PARA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 477/503: TFC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for TFC from 2019-01-01\n",
      "Company TFC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for TFC. Total for this company: 1000\n",
      "Company TFC - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 447 news items for TFC. Total for this company: 1447\n",
      "Reached the end of available news for TFC at offset 1000.\n",
      "Saved 1447 news items for TFC to sp500_news_data/TFC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 478/503: CRWD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CRWD from 2019-01-01\n",
      "Company CRWD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for CRWD. Total for this company: 1000\n",
      "Company CRWD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for CRWD. Total for this company: 2000\n",
      "Company CRWD - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for CRWD. Total for this company: 3000\n",
      "Company CRWD - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for CRWD. Total for this company: 4000\n",
      "Company CRWD - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 436 news items for CRWD. Total for this company: 4436\n",
      "Reached the end of available news for CRWD at offset 4000.\n",
      "Saved 4436 news items for CRWD to sp500_news_data/CRWD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 479/503: CTVA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CTVA from 2019-01-01\n",
      "Company CTVA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 860 news items for CTVA. Total for this company: 860\n",
      "Reached the end of available news for CTVA at offset 0.\n",
      "Saved 860 news items for CTVA to sp500_news_data/CTVA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 480/503: AMCR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for AMCR from 2019-01-01\n",
      "Company AMCR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 603 news items for AMCR. Total for this company: 603\n",
      "Reached the end of available news for AMCR at offset 0.\n",
      "Saved 603 news items for AMCR to sp500_news_data/AMCR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 481/503: LHX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for LHX from 2019-01-01\n",
      "Company LHX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for LHX. Total for this company: 1000\n",
      "Company LHX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 78 news items for LHX. Total for this company: 1078\n",
      "Reached the end of available news for LHX at offset 1000.\n",
      "Saved 1078 news items for LHX to sp500_news_data/LHX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 482/503: J\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for J from 2019-01-01\n",
      "Company J - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 557 news items for J. Total for this company: 557\n",
      "Reached the end of available news for J at offset 0.\n",
      "Saved 557 news items for J to sp500_news_data/J_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 483/503: CARR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CARR from 2019-01-01\n",
      "Company CARR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 908 news items for CARR. Total for this company: 908\n",
      "Reached the end of available news for CARR at offset 0.\n",
      "Saved 908 news items for CARR to sp500_news_data/CARR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 484/503: OTIS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for OTIS from 2019-01-01\n",
      "Company OTIS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 689 news items for OTIS. Total for this company: 689\n",
      "Reached the end of available news for OTIS at offset 0.\n",
      "Saved 689 news items for OTIS to sp500_news_data/OTIS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 485/503: RTX\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RTX from 2019-01-01\n",
      "Company RTX - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for RTX. Total for this company: 1000\n",
      "Company RTX - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for RTX. Total for this company: 2000\n",
      "Company RTX - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 645 news items for RTX. Total for this company: 2645\n",
      "Reached the end of available news for RTX at offset 2000.\n",
      "Saved 2645 news items for RTX to sp500_news_data/RTX_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 486/503: PLTR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for PLTR from 2019-01-01\n",
      "Company PLTR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for PLTR. Total for this company: 1000\n",
      "Company PLTR - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for PLTR. Total for this company: 2000\n",
      "Company PLTR - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for PLTR. Total for this company: 3000\n",
      "Company PLTR - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for PLTR. Total for this company: 4000\n",
      "Company PLTR - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 1000 news items for PLTR. Total for this company: 5000\n",
      "Company PLTR - Batch 6/25: Fetching news with offset 5000...\n",
      "Retrieved 309 news items for PLTR. Total for this company: 5309\n",
      "Reached the end of available news for PLTR at offset 5000.\n",
      "Saved 5309 news items for PLTR to sp500_news_data/PLTR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 487/503: VTRS\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VTRS from 2019-01-01\n",
      "Company VTRS - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 999 news items for VTRS. Total for this company: 999\n",
      "Reached the end of available news for VTRS at offset 0.\n",
      "Saved 999 news items for VTRS to sp500_news_data/VTRS_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 488/503: ABNB\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for ABNB from 2019-01-01\n",
      "Company ABNB - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for ABNB. Total for this company: 1000\n",
      "Company ABNB - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 1000 news items for ABNB. Total for this company: 2000\n",
      "Company ABNB - Batch 3/25: Fetching news with offset 2000...\n",
      "Retrieved 1000 news items for ABNB. Total for this company: 3000\n",
      "Company ABNB - Batch 4/25: Fetching news with offset 3000...\n",
      "Retrieved 1000 news items for ABNB. Total for this company: 4000\n",
      "Company ABNB - Batch 5/25: Fetching news with offset 4000...\n",
      "Retrieved 703 news items for ABNB. Total for this company: 4703\n",
      "Reached the end of available news for ABNB at offset 4000.\n",
      "Saved 4703 news items for ABNB to sp500_news_data/ABNB_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 489/503: CTRA\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CTRA from 2019-01-01\n",
      "Company CTRA - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 332 news items for CTRA. Total for this company: 332\n",
      "Reached the end of available news for CTRA at offset 0.\n",
      "Saved 332 news items for CTRA to sp500_news_data/CTRA_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 490/503: WTW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WTW from 2019-01-01\n",
      "Company WTW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 541 news items for WTW. Total for this company: 541\n",
      "Reached the end of available news for WTW at offset 0.\n",
      "Saved 541 news items for WTW to sp500_news_data/WTW_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 491/503: CEG\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CEG from 2019-01-01\n",
      "Company CEG - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 312 news items for CEG. Total for this company: 312\n",
      "Reached the end of available news for CEG at offset 0.\n",
      "Saved 312 news items for CEG to sp500_news_data/CEG_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 492/503: WBD\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for WBD from 2019-01-01\n",
      "Company WBD - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 1000 news items for WBD. Total for this company: 1000\n",
      "Company WBD - Batch 2/25: Fetching news with offset 1000...\n",
      "Retrieved 80 news items for WBD. Total for this company: 1080\n",
      "Reached the end of available news for WBD at offset 1000.\n",
      "Saved 1080 news items for WBD to sp500_news_data/WBD_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 493/503: BALL\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for BALL from 2019-01-01\n",
      "Company BALL - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 350 news items for BALL. Total for this company: 350\n",
      "Reached the end of available news for BALL at offset 0.\n",
      "Saved 350 news items for BALL to sp500_news_data/BALL_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 494/503: GEN\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GEN from 2019-01-01\n",
      "Company GEN - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 376 news items for GEN. Total for this company: 376\n",
      "Reached the end of available news for GEN at offset 0.\n",
      "Saved 376 news items for GEN to sp500_news_data/GEN_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 495/503: GEHC\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GEHC from 2019-01-01\n",
      "Company GEHC - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 292 news items for GEHC. Total for this company: 292\n",
      "Reached the end of available news for GEHC at offset 0.\n",
      "Saved 292 news items for GEHC to sp500_news_data/GEHC_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 496/503: KVUE\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for KVUE from 2019-01-01\n",
      "Company KVUE - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 414 news items for KVUE. Total for this company: 414\n",
      "Reached the end of available news for KVUE at offset 0.\n",
      "Saved 414 news items for KVUE to sp500_news_data/KVUE_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 497/503: RVTY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for RVTY from 2019-01-01\n",
      "Company RVTY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 151 news items for RVTY. Total for this company: 151\n",
      "Reached the end of available news for RVTY at offset 0.\n",
      "Saved 151 news items for RVTY to sp500_news_data/RVTY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 498/503: VLTO\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for VLTO from 2019-01-01\n",
      "Company VLTO - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 84 news items for VLTO. Total for this company: 84\n",
      "Reached the end of available news for VLTO at offset 0.\n",
      "Saved 84 news items for VLTO to sp500_news_data/VLTO_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 499/503: COR\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for COR from 2019-01-01\n",
      "Company COR - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 362 news items for COR. Total for this company: 362\n",
      "Reached the end of available news for COR at offset 0.\n",
      "Saved 362 news items for COR to sp500_news_data/COR_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 500/503: CPAY\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for CPAY from 2019-01-01\n",
      "Company CPAY - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 99 news items for CPAY. Total for this company: 99\n",
      "Reached the end of available news for CPAY at offset 0.\n",
      "Saved 99 news items for CPAY to sp500_news_data/CPAY_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 501/503: SOLV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SOLV from 2019-01-01\n",
      "Company SOLV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 97 news items for SOLV. Total for this company: 97\n",
      "Reached the end of available news for SOLV at offset 0.\n",
      "Saved 97 news items for SOLV to sp500_news_data/SOLV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 502/503: GEV\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for GEV from 2019-01-01\n",
      "Company GEV - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 57 news items for GEV. Total for this company: 57\n",
      "Reached the end of available news for GEV at offset 0.\n",
      "Saved 57 news items for GEV to sp500_news_data/GEV_news.json\n",
      "\n",
      "================================================================================\n",
      "Processing company 503/503: SW\n",
      "================================================================================\n",
      "\n",
      "Starting data collection for SW from 2019-01-01\n",
      "Company SW - Batch 1/25: Fetching news with offset 0...\n",
      "Retrieved 27 news items for SW. Total for this company: 27\n",
      "Reached the end of available news for SW at offset 0.\n",
      "Saved 27 news items for SW to sp500_news_data/SW_news.json\n",
      "\n",
      "================================================================================\n",
      "Data collection complete:\n",
      "- Made 1351 API calls\n",
      "- Processed 503 of 503 companies\n",
      "- Collected 1117392 total news items\n",
      "- Total runtime: 4797.28 seconds (1.33 hours)\n",
      "- Summary saved to sp500_news_data/sp500_news_summary.json\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from eodhd import APIClient\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Initialize the API client with API key\n",
    "KEY = \"603eafd117ce29.12741264\"\n",
    "api = APIClient(KEY)  # Assuming KEY is defined elsewhere in your code\n",
    "\n",
    "# Configuration\n",
    "FROM_DATE = \"2019-01-01\"\n",
    "LIMIT = 1000  # Maximum allowed per request\n",
    "MAX_ITERATIONS_PER_COMPANY = 25\n",
    "CALLS_PER_MINUTE_LIMIT = 1000\n",
    "CALLS_PER_DAY_LIMIT = 80000\n",
    "OUTPUT_DIR = \"sp500_news_data\"  # Directory to store output files\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize tracking variables\n",
    "api_calls = 0\n",
    "start_time = time.time()\n",
    "minute_start_time = start_time\n",
    "minute_calls = 0\n",
    "processed_companies = 0\n",
    "total_news_items = 0\n",
    "\n",
    "# Function to enforce rate limits\n",
    "def check_rate_limits():\n",
    "    global minute_calls, minute_start_time, api_calls\n",
    "    \n",
    "    current_time = time.time()\n",
    "    elapsed_minute = current_time - minute_start_time\n",
    "    \n",
    "    # Reset minute counter if a minute has passed\n",
    "    if elapsed_minute >= 60:\n",
    "        minute_calls = 0\n",
    "        minute_start_time = current_time\n",
    "    \n",
    "    # If we're close to the per-minute limit, wait until the next minute\n",
    "    if minute_calls >= CALLS_PER_MINUTE_LIMIT - 5:  # Buffer of 5 calls\n",
    "        wait_time = 60 - elapsed_minute\n",
    "        print(f\"Approaching per-minute rate limit. Waiting {wait_time:.2f} seconds...\")\n",
    "        time.sleep(wait_time + 1)  # Add 1 second buffer\n",
    "        minute_calls = 0\n",
    "        minute_start_time = time.time()\n",
    "    \n",
    "    # Check if we're approaching the daily limit\n",
    "    if api_calls >= CALLS_PER_DAY_LIMIT - 1000:  # Buffer of 1000 calls\n",
    "        print(\"WARNING: Approaching daily API call limit!\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Function to fetch news for a single company\n",
    "def fetch_company_news(symbol):\n",
    "    global api_calls, minute_calls, total_news_items\n",
    "    \n",
    "    company_news = []\n",
    "    \n",
    "    print(f\"\\nStarting data collection for {symbol} from {FROM_DATE}\")\n",
    "    \n",
    "    # Main loop for pagination\n",
    "    for i in range(MAX_ITERATIONS_PER_COMPANY):\n",
    "        offset = i * LIMIT\n",
    "        \n",
    "        # Check rate limits\n",
    "        if not check_rate_limits():\n",
    "            print(f\"Stopping further requests for {symbol} due to API limits.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            print(f\"Company {symbol} - Batch {i+1}/{MAX_ITERATIONS_PER_COMPANY}: Fetching news with offset {offset}...\")\n",
    "            \n",
    "            # Make the API call\n",
    "            news_batch = api.financial_news(\n",
    "                s=symbol, \n",
    "                from_date=FROM_DATE, \n",
    "                offset=str(offset), \n",
    "                limit=str(LIMIT)\n",
    "            )\n",
    "            \n",
    "            # Update counters\n",
    "            api_calls += 1\n",
    "            minute_calls += 1\n",
    "            \n",
    "            # Check if we got any results\n",
    "            if not news_batch:\n",
    "                print(f\"No more news items found for {symbol} after offset {offset}.\")\n",
    "                break\n",
    "            \n",
    "            # Add the batch to our collection\n",
    "            company_news.extend(news_batch)\n",
    "            total_news_items += len(news_batch)\n",
    "            \n",
    "            # Display progress\n",
    "            print(f\"Retrieved {len(news_batch)} news items for {symbol}. Total for this company: {len(company_news)}\")\n",
    "            \n",
    "            # If we got fewer items than requested, we've reached the end\n",
    "            if len(news_batch) < LIMIT:\n",
    "                print(f\"Reached the end of available news for {symbol} at offset {offset}.\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error for {symbol} at offset {offset}: {str(e)}\")\n",
    "            \n",
    "            # If the error might be rate-limit related, pause\n",
    "            if \"rate\" in str(e).lower() or \"limit\" in str(e).lower():\n",
    "                print(\"Possible rate limit reached. Pausing for 60 seconds...\")\n",
    "                time.sleep(60)\n",
    "                minute_calls = 0\n",
    "                minute_start_time = time.time()\n",
    "            else:\n",
    "                # For other errors, add a small delay before continuing\n",
    "                print(\"Continuing to next batch after a short delay...\")\n",
    "                time.sleep(5)\n",
    "        \n",
    "        # Add a small delay between requests to be courteous\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return company_news\n",
    "\n",
    "# Function to get S&P 500 tickers using get_fundamentals_data\n",
    "def get_sp500_tickers():\n",
    "    try:\n",
    "        print(\"Fetching S&P 500 constituent companies via EODHD API...\")\n",
    "        \n",
    "        # Get S&P 500 fundamentals data which includes Components\n",
    "        sp500_data = api.get_fundamentals_data('GSPC.INDX')\n",
    "        global api_calls, minute_calls\n",
    "        api_calls += 1\n",
    "        minute_calls += 1\n",
    "        \n",
    "        # Check if we got valid data with Components\n",
    "        if not sp500_data or 'Components' not in sp500_data:\n",
    "            raise Exception(\"Components data not found in API response\")\n",
    "        \n",
    "        components = sp500_data['Components']\n",
    "        tickers = []\n",
    "        \n",
    "        # Process Components based on its type\n",
    "        if isinstance(components, list):\n",
    "            for component in components:\n",
    "                if isinstance(component, dict) and 'Code' in component:\n",
    "                    tickers.append(component['Code'])\n",
    "                elif isinstance(component, str):\n",
    "                    tickers.append(component)\n",
    "        elif isinstance(components, dict):\n",
    "            for key, value in components.items():\n",
    "                if isinstance(value, dict) and 'Code' in value:\n",
    "                    tickers.append(value['Code'])\n",
    "                else:\n",
    "                    tickers.append(key)\n",
    "        \n",
    "        print(f\"Successfully retrieved {len(tickers)} S&P 500 tickers\")\n",
    "        return tickers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching S&P 500 tickers: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    # Step 1: Get the list of S&P 500 company tickers\n",
    "    sp500_tickers = get_sp500_tickers()\n",
    "    total_companies = len(sp500_tickers)\n",
    "    \n",
    "    # Create a summary log file\n",
    "    summary_file = os.path.join(OUTPUT_DIR, \"sp500_news_summary.json\")\n",
    "    company_summaries = []\n",
    "    \n",
    "    # Step 2: Process each company ticker\n",
    "    for ticker in sp500_tickers:\n",
    "        # Check if we're approaching API limits before starting a new company\n",
    "        if not check_rate_limits():\n",
    "            print(f\"Approaching API limits. Stopping after processing {processed_companies} companies.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing company {processed_companies+1}/{total_companies}: {ticker}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Fetch news for this company\n",
    "        company_news = fetch_company_news(ticker)\n",
    "        \n",
    "        # If we got news, save it to a file\n",
    "        if company_news:\n",
    "            company_filename = f\"{ticker.replace('.', '_')}_news.json\"\n",
    "            company_filepath = os.path.join(OUTPUT_DIR, company_filename)\n",
    "            \n",
    "            with open(company_filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(company_news, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "            print(f\"Saved {len(company_news)} news items for {ticker} to {company_filepath}\")\n",
    "            \n",
    "            # Add to summary\n",
    "            company_summaries.append({\n",
    "                'symbol': ticker,\n",
    "                'news_count': len(company_news),\n",
    "                'file': company_filename\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No news found for {ticker}. Skipping file creation.\")\n",
    "            \n",
    "            # Add to summary\n",
    "            company_summaries.append({\n",
    "                'symbol': ticker,\n",
    "                'news_count': 0,\n",
    "                'file': None\n",
    "            })\n",
    "        \n",
    "        processed_companies += 1\n",
    "        \n",
    "        # Save the summary after each company to keep track of progress\n",
    "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "            summary_data = {\n",
    "                'companies_processed': processed_companies,\n",
    "                'total_companies': total_companies,\n",
    "                'total_news_items': total_news_items,\n",
    "                'api_calls': api_calls,\n",
    "                'company_summaries': company_summaries\n",
    "            }\n",
    "            json.dump(summary_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        # Brief pause between companies\n",
    "        time.sleep(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Critical error in main execution: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    # Final summary\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Data collection complete:\")\n",
    "    print(f\"- Made {api_calls} API calls\")\n",
    "    print(f\"- Processed {processed_companies} of {total_companies} companies\")\n",
    "    print(f\"- Collected {total_news_items} total news items\")\n",
    "    print(f\"- Total runtime: {total_time:.2f} seconds ({total_time/3600:.2f} hours)\")\n",
    "    print(f\"- Summary saved to {summary_file}\")\n",
    "    print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDAS Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
